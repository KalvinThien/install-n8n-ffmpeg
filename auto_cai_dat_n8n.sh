#!/bin/bash

# Hi·ªÉn th·ªã banner
echo "======================================================================"
echo "     Script c√†i ƒë·∫∑t N8N v·ªõi FFmpeg, yt-dlp, Puppeteer, News API     "
echo "           v√† SSL t·ª± ƒë·ªông (Phi√™n b·∫£n c·∫£i ti·∫øn 2025)                 "
echo "                   T√°c gi·∫£: Nguy·ªÖn Ng·ªçc Thi·ªán                       "
echo "======================================================================"

# Ki·ªÉm tra xem script c√≥ ƒë∆∞·ª£c ch·∫°y v·ªõi quy·ªÅn root kh√¥ng
if [[ $EUID -ne 0 ]]; then
   echo "Script n√†y c·∫ßn ƒë∆∞·ª£c ch·∫°y v·ªõi quy·ªÅn root" 
   exit 1
fi

# H√†m thi·∫øt l·∫≠p swap t·ª± ƒë·ªông
setup_swap() {
    echo "Ki·ªÉm tra v√† thi·∫øt l·∫≠p swap t·ª± ƒë·ªông..."
    
    if [ "$(swapon --show | wc -l)" -gt 0 ]; then
        SWAP_SIZE=$(free -h | grep Swap | awk '{print $2}')
        echo "Swap ƒë√£ ƒë∆∞·ª£c b·∫≠t v·ªõi k√≠ch th∆∞·ªõc ${SWAP_SIZE}. B·ªè qua thi·∫øt l·∫≠p."
        return
    fi
    
    RAM_MB=$(free -m | grep Mem | awk '{print $2}')
    
    if [ "$RAM_MB" -le 2048 ]; then
        SWAP_SIZE=$((RAM_MB * 2))
    elif [ "$RAM_MB" -gt 2048 ] && [ "$RAM_MB" -le 8192 ]; then
        SWAP_SIZE=$RAM_MB
    else
        SWAP_SIZE=4096
    fi
    
    SWAP_GB=$(( (SWAP_SIZE + 1023) / 1024 ))
    
    echo "ƒêang thi·∫øt l·∫≠p swap v·ªõi k√≠ch th∆∞·ªõc ${SWAP_GB}GB (${SWAP_SIZE}MB)..."
    
    dd if=/dev/zero of=/swapfile bs=1M count=$SWAP_SIZE status=progress
    chmod 600 /swapfile
    mkswap /swapfile
    swapon /swapfile
    
    if ! grep -q "/swapfile" /etc/fstab; then
        echo '/swapfile none swap sw 0 0' >> /etc/fstab
    fi
    
    sysctl vm.swappiness=10
    sysctl vm.vfs_cache_pressure=50
    
    if ! grep -q "vm.swappiness" /etc/sysctl.conf; then
        echo "vm.swappiness=10" >> /etc/sysctl.conf
    fi
    
    if ! grep -q "vm.vfs_cache_pressure" /etc/sysctl.conf; then
        echo "vm.vfs_cache_pressure=50" >> /etc/sysctl.conf
    fi
    
    echo "ƒê√£ thi·∫øt l·∫≠p swap v·ªõi k√≠ch th∆∞·ªõc ${SWAP_GB}GB th√†nh c√¥ng."
}

# H√†m hi·ªÉn th·ªã tr·ª£ gi√∫p
show_help() {
    echo "C√°ch s·ª≠ d·ª•ng: $0 [t√πy ch·ªçn]"
    echo "T√πy ch·ªçn:"
    echo "  -h, --help      Hi·ªÉn th·ªã tr·ª£ gi√∫p n√†y"
    echo "  -d, --dir DIR   Ch·ªâ ƒë·ªãnh th∆∞ m·ª•c c√†i ƒë·∫∑t n8n (m·∫∑c ƒë·ªãnh: /home/n8n)"
    echo "  -s, --skip-docker B·ªè qua c√†i ƒë·∫∑t Docker (n·∫øu ƒë√£ c√≥)"
    echo "  -c, --clean     X√≥a t·∫•t c·∫£ c√†i ƒë·∫∑t N8N/Docker c≈© v√† c√†i m·ªõi"
    exit 0
}

# X·ª≠ l√Ω tham s·ªë d√≤ng l·ªánh
N8N_DIR="/home/n8n"
SKIP_DOCKER=false
CLEAN_INSTALL=false

while [[ $# -gt 0 ]]; do
    case $1 in
        -h|--help)
            show_help
            ;;
        -d|--dir)
            N8N_DIR="$2"
            shift 2
            ;;
        -s|--skip-docker)
            SKIP_DOCKER=true
            shift
            ;;
        -c|--clean)
            CLEAN_INSTALL=true
            shift
            ;;
        *)
            echo "T√πy ch·ªçn kh√¥ng h·ª£p l·ªá: $1"
            show_help
            ;;
    esac
done

# H√†m cleanup c√†i ƒë·∫∑t c≈©
cleanup_old_installation() {
    echo "======================================================================"
    echo "  C·∫¢NH B√ÅO: B·∫°n s·∫Øp x√≥a to√†n b·ªô c√†i ƒë·∫∑t N8N v√† Docker hi·ªán t·∫°i!"
    echo "  ƒêi·ªÅu n√†y s·∫Ω x√≥a:"
    echo "  - T·∫•t c·∫£ containers Docker"
    echo "  - T·∫•t c·∫£ images Docker"
    echo "  - Th∆∞ m·ª•c $N8N_DIR"
    echo "  - T·∫•t c·∫£ d·ªØ li·ªáu workflows, credentials v√† backup"
    echo "======================================================================"
    read -p "B·∫°n c√≥ ch·∫Øc ch·∫Øn mu·ªën x√≥a t·∫•t c·∫£ v√† c√†i ƒë·∫∑t m·ªõi? (YES ƒë·ªÉ x√°c nh·∫≠n): " CONFIRM_CLEAN
    
    if [ "$CONFIRM_CLEAN" = "YES" ]; then
        echo "ƒêang d·ª´ng t·∫•t c·∫£ containers..."
        docker stop $(docker ps -aq) 2>/dev/null || true
        
        echo "ƒêang x√≥a t·∫•t c·∫£ containers..."
        docker rm $(docker ps -aq) 2>/dev/null || true
        
        echo "ƒêang x√≥a t·∫•t c·∫£ images..."
        docker rmi $(docker images -q) 2>/dev/null || true
        
        echo "ƒêang x√≥a t·∫•t c·∫£ volumes..."
        docker volume prune -f 2>/dev/null || true
        
        echo "ƒêang x√≥a t·∫•t c·∫£ networks..."
        docker network prune -f 2>/dev/null || true
        
        echo "ƒêang x√≥a system cache..."
        docker system prune -af 2>/dev/null || true
        
        if [ -d "$N8N_DIR" ]; then
            echo "ƒêang x√≥a th∆∞ m·ª•c $N8N_DIR..."
            rm -rf "$N8N_DIR"
        fi
        
        # X√≥a cron jobs c≈©
        crontab -l 2>/dev/null | grep -v "update-n8n.sh" | grep -v "backup-workflows.sh" | crontab - 2>/dev/null || true
        
        echo "‚úÖ ƒê√£ x√≥a s·∫°ch t·∫•t c·∫£ c√†i ƒë·∫∑t c≈©. Ti·∫øp t·ª•c c√†i ƒë·∫∑t m·ªõi..."
    else
        echo "‚ùå H·ªßy b·ªè qu√° tr√¨nh cleanup. Ti·∫øp t·ª•c v·ªõi c√†i ƒë·∫∑t th√¥ng th∆∞·ªùng..."
    fi
}

# N·∫øu c√≥ flag clean, th·ª±c hi·ªán cleanup
if [ "$CLEAN_INSTALL" = true ]; then
    cleanup_old_installation
fi

# H√†m ki·ªÉm tra domain
check_domain() {
    local domain=$1
    local server_ip=$(curl -s https://api.ipify.org || curl -s http://ipv4.icanhazip.com || echo "Kh√¥ng th·ªÉ l·∫•y IP server")
    if [ "$server_ip" == "Kh√¥ng th·ªÉ l·∫•y IP server" ]; then return 1; fi
    local domain_ip=$(dig +short $domain A | head -n1)

    if [ "$domain_ip" = "$server_ip" ]; then
        return 0
    else
        return 1
    fi
}

# H√†m ki·ªÉm tra c√°c l·ªánh c·∫ßn thi·∫øt
check_commands() {
    for cmd in dig curl cron jq tar gzip bc python3; do
        if ! command -v $cmd &> /dev/null; then
            echo "L·ªánh '$cmd' kh√¥ng t√¨m th·∫•y. ƒêang c√†i ƒë·∫∑t..."
            apt-get update > /dev/null 2>&1
            if [ "$cmd" == "cron" ]; then
                apt-get install -y cron
            elif [ "$cmd" == "bc" ]; then
                apt-get install -y bc
            elif [ "$cmd" == "python3" ]; then
                apt-get install -y python3 python3-pip python3-venv
            else
                apt-get install -y dnsutils curl jq tar gzip
            fi
            if ! command -v $cmd &> /dev/null; then
                 echo "L·ªói: Kh√¥ng th·ªÉ c√†i ƒë·∫∑t l·ªánh '$cmd'. Vui l√≤ng c√†i ƒë·∫∑t th·ªß c√¥ng v√† ch·∫°y l·∫°i script."
                 exit 1
            fi
        fi
    done
}

# Thi·∫øt l·∫≠p swap
setup_swap

# H√†m c√†i ƒë·∫∑t Docker
install_docker() {
    if $SKIP_DOCKER && command -v docker &> /dev/null; then
        echo "Docker ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t v√† b·ªè qua theo y√™u c·∫ßu..."
        return
    fi
    
    if command -v docker &> /dev/null; then
        echo "Docker ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t."
    else
        echo "C√†i ƒë·∫∑t Docker..."
        apt-get update
        apt-get install -y apt-transport-https ca-certificates curl software-properties-common
        mkdir -p /etc/apt/keyrings
        curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
        echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | \
        tee /etc/apt/sources.list.d/docker.list > /dev/null
        apt-get update
        apt-get install -y docker-ce docker-ce-cli containerd.io
    fi

    # C√†i ƒë·∫∑t Docker Compose
    if command -v docker-compose &> /dev/null || (command -v docker &> /dev/null && docker compose version &> /dev/null); then
        echo "Docker Compose (ho·∫∑c plugin) ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t."
    else 
        echo "C√†i ƒë·∫∑t Docker Compose plugin..."
        apt-get install -y docker-compose-plugin
        if ! (docker compose version &> /dev/null); then 
            echo "Kh√¥ng c√†i ƒë∆∞·ª£c plugin, th·ª≠ c√†i docker-compose b·∫£n c≈©..." 
            apt-get install -y docker-compose 
        fi
    fi
    
    if ! command -v docker &> /dev/null; then
        echo "L·ªói: Docker ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t ƒë√∫ng c√°ch."
        exit 1
    fi

    if ! command -v docker-compose &> /dev/null && ! (command -v docker &> /dev/null && docker compose version &> /dev/null); then
        echo "L·ªói: Docker Compose ch∆∞a ƒë∆∞·ª£c c√†i ƒë·∫∑t ƒë√∫ng c√°ch."
        exit 1
    fi

    if [ "$SUDO_USER" != "" ]; then
        echo "Th√™m user $SUDO_USER v√†o nh√≥m docker..."
        usermod -aG docker $SUDO_USER
        echo "ƒê√£ th√™m. Thay ƒë·ªïi c√≥ hi·ªáu l·ª±c sau khi ƒëƒÉng nh·∫≠p l·∫°i ho·∫∑c ch·∫°y 'newgrp docker'."
    fi
    systemctl enable docker
    systemctl restart docker
    echo "Docker v√† Docker Compose ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t/ki·ªÉm tra th√†nh c√¥ng."
}

# C√†i ƒë·∫∑t c√°c g√≥i c·∫ßn thi·∫øt
echo "ƒêang ki·ªÉm tra v√† c√†i ƒë·∫∑t c√°c c√¥ng c·ª• c·∫ßn thi·∫øt..."
apt-get update > /dev/null
apt-get install -y dnsutils curl cron jq tar gzip python3-full python3-venv python3-pip pipx net-tools bc

# C√†i ƒë·∫∑t yt-dlp
echo "C√†i ƒë·∫∑t yt-dlp..."
if command -v pipx &> /dev/null; then
    pipx install yt-dlp
    pipx ensurepath
else
    python3 -m venv /opt/yt-dlp-venv
    /opt/yt-dlp-venv/bin/pip install -U pip yt-dlp
    ln -sf /opt/yt-dlp-venv/bin/yt-dlp /usr/local/bin/yt-dlp
    chmod +x /usr/local/bin/yt-dlp
fi
export PATH="$PATH:/usr/local/bin:/opt/yt-dlp-venv/bin:$HOME/.local/bin"

# ƒê·∫£m b·∫£o cron service ƒëang ch·∫°y
systemctl enable cron
systemctl start cron

# Ki·ªÉm tra c√°c l·ªánh (bao g·ªìm Docker)
check_commands
install_docker

# Nh·∫≠n input domain t·ª´ ng∆∞·ªùi d√πng
read -p "Nh·∫≠p t√™n mi·ªÅn ch√≠nh c·ªßa b·∫°n (v√≠ d·ª•: n8nkalvinbot.io.vn): " DOMAIN
while ! check_domain $DOMAIN; do
    echo "Domain $DOMAIN ch∆∞a ƒë∆∞·ª£c tr·ªè ƒë√∫ng ƒë·∫øn IP server n√†y ($(curl -s https://api.ipify.org))."
    echo "Vui l√≤ng c·∫≠p nh·∫≠t b·∫£n ghi DNS ƒë·ªÉ tr·ªè $DOMAIN ƒë·∫øn IP $(curl -s https://api.ipify.org)." 
    read -p "Nh·∫•n Enter sau khi c·∫≠p nh·∫≠t DNS, ho·∫∑c nh·∫≠p domain kh√°c: " NEW_DOMAIN
    if [ -n "$NEW_DOMAIN" ]; then
        DOMAIN="$NEW_DOMAIN"
    fi
done
echo "‚úÖ Domain $DOMAIN ƒë√£ ƒë∆∞·ª£c tr·ªè ƒë√∫ng. Ti·∫øp t·ª•c c√†i ƒë·∫∑t."

# H·ªèi v·ªÅ News API
API_DOMAIN=""
INSTALL_NEWS_API=false
read -p "B·∫°n c√≥ mu·ªën c√†i ƒë·∫∑t FastAPI ƒë·ªÉ c√†o n·ªôi dung b√†i vi·∫øt kh√¥ng? (y/n): " INSTALL_API_CHOICE
if [[ "$INSTALL_API_CHOICE" =~ ^[Yy]$ ]]; then
    API_DOMAIN="api.$DOMAIN"
    echo "S·∫Ω t·∫°o API t·∫°i: $API_DOMAIN"
    
    # Ki·ªÉm tra API domain
    echo "Ki·ªÉm tra domain API: $API_DOMAIN"
    if check_domain $API_DOMAIN; then
        echo "‚úÖ Domain API $API_DOMAIN ƒë√£ ƒë∆∞·ª£c tr·ªè ƒë√∫ng."
        INSTALL_NEWS_API=true
    else
        echo "‚ö†Ô∏è  Domain API $API_DOMAIN ch∆∞a ƒë∆∞·ª£c tr·ªè ƒë√∫ng."
        read -p "B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c c√†i ƒë·∫∑t API (c√≥ th·ªÉ c·∫•u h√¨nh DNS sau)? (y/n): " CONTINUE_API
        if [[ "$CONTINUE_API" =~ ^[Yy]$ ]]; then
            INSTALL_NEWS_API=true
            echo "S·∫Ω c√†i ƒë·∫∑t API. H√£y nh·ªõ tr·ªè $API_DOMAIN ƒë·∫øn server n√†y."
        else
            echo "B·ªè qua c√†i ƒë·∫∑t News API."
        fi
    fi
fi

# T·∫°o th∆∞ m·ª•c cho n8n
echo "T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c cho n8n t·∫°i $N8N_DIR..."
mkdir -p $N8N_DIR
mkdir -p $N8N_DIR/files
mkdir -p $N8N_DIR/files/temp
mkdir -p $N8N_DIR/files/youtube_content_anylystic
mkdir -p $N8N_DIR/files/backup_full

# T·∫°o Dockerfile cho N8N
echo "T·∫°o Dockerfile..."
cat << 'EOF' > $N8N_DIR/Dockerfile
FROM n8nio/n8n:latest
USER root
RUN apk update && \
    apk add --no-cache ffmpeg wget zip unzip python3 py3-pip jq tar gzip \
    chromium nss freetype freetype-dev harfbuzz ca-certificates ttf-freefont \
    font-noto font-noto-cjk font-noto-emoji dbus udev
RUN pip3 install --break-system-packages -U yt-dlp && \
    chmod +x /usr/bin/yt-dlp
ENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true \
    PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium-browser
WORKDIR /usr/local/lib/node_modules/n8n
RUN npm install n8n-nodes-puppeteer || echo "C·∫£nh b√°o: Kh√¥ng th·ªÉ c√†i ƒë·∫∑t n8n-nodes-puppeteer, ti·∫øp t·ª•c m√† kh√¥ng c√≥ n√≥"
RUN mkdir -p /files/youtube_content_anylystic /files/backup_full /files/temp && \
    chown -R node:node /files
USER node
WORKDIR /home/node
EOF

# C√†i ƒë·∫∑t News API n·∫øu ƒë∆∞·ª£c ch·ªçn
if [ "$INSTALL_NEWS_API" = true ]; then
    echo "C√†i ƒë·∫∑t News Content API..."
    mkdir -p $N8N_DIR/news_api
    
    # T·∫°o requirements.txt cho News API
    cat << 'EOF' > $N8N_DIR/news_api/requirements.txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
newspaper4k==0.9.2.9
python-multipart==0.0.6
Jinja2==3.1.2
aiofiles==23.2.1
requests==2.31.0
feedparser==6.0.10
beautifulsoup4==4.12.2
lxml==4.9.3
html5lib==1.1
python-dateutil==2.8.2
validators==0.22.0
pydantic==2.5.0
EOF

    # T·∫°o Dockerfile cho News API
    cat << 'EOF' > $N8N_DIR/news_api/Dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libxml2-dev \
    libxslt-dev \
    libjpeg-dev \
    zlib1g-dev \
    libpng-dev \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY . .

# Create non-root user
RUN useradd -m -u 1000 apiuser && chown -R apiuser:apiuser /app
USER apiuser

# Expose port
EXPOSE 8000

# Run the application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]
EOF

    # T·∫°o News API main.py
    cat << 'EOF' > $N8N_DIR/news_api/main.py
from fastapi import FastAPI, HTTPException, Depends, Request
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, HttpUrl, Field, validator
from typing import Optional, List, Dict, Any
import newspaper
from newspaper import Article, Config
import feedparser
import requests
from datetime import datetime, timezone
import logging
import os
import asyncio
import aiofiles
from urllib.parse import urljoin, urlparse
import validators
from bs4 import BeautifulSoup
import json
import re

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# App initialization
app = FastAPI(
    title="News Content API by Kalvin Thien",
    description="API ƒë·ªÉ c√†o n·ªôi dung b√†i vi·∫øt v√† RSS feeds - Ph√°t tri·ªÉn b·ªüi Nguy·ªÖn Ng·ªçc Thi·ªán",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# Security
security = HTTPBearer()
API_TOKEN = os.getenv("NEWS_API_TOKEN", "default_secure_token_2025")

def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    if credentials.credentials != API_TOKEN:
        raise HTTPException(status_code=401, detail="Invalid authentication token")
    return credentials.credentials

# Pydantic models
class ArticleRequest(BaseModel):
    url: HttpUrl
    language: str = Field(default="vi", description="Ng√¥n ng·ªØ b√†i vi·∫øt (vi, en, etc.)")
    extract_images: bool = Field(default=True, description="C√≥ tr√≠ch xu·∫•t h√¨nh ·∫£nh kh√¥ng")
    summarize: bool = Field(default=False, description="C√≥ t√≥m t·∫Øt b√†i vi·∫øt kh√¥ng")

    @validator('language')
    def validate_language(cls, v):
        supported_languages = ['vi', 'en', 'zh', 'ja', 'ko', 'th', 'id', 'ms']
        if v not in supported_languages:
            raise ValueError(f'Ng√¥n ng·ªØ kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£. H·ªó tr·ª£: {supported_languages}')
        return v

class SourceRequest(BaseModel):
    url: HttpUrl
    max_articles: int = Field(default=10, ge=1, le=50, description="S·ªë l∆∞·ª£ng b√†i vi·∫øt t·ªëi ƒëa")
    language: str = Field(default="vi")

class FeedRequest(BaseModel):
    url: HttpUrl
    max_articles: int = Field(default=10, ge=1, le=100)

class ArticleResponse(BaseModel):
    title: Optional[str]
    content: Optional[str]
    summary: Optional[str]
    authors: List[str]
    publish_date: Optional[str]
    url: str
    images: List[str]
    tags: List[str]
    language: str
    word_count: int
    read_time_minutes: int
    extracted_at: str

class HealthResponse(BaseModel):
    status: str
    message: str
    version: str
    timestamp: str
    author: str = "Nguy·ªÖn Ng·ªçc Thi·ªán"
    youtube: str = "https://www.youtube.com/@kalvinthiensocial"

# Utility functions
def calculate_read_time(word_count: int) -> int:
    """T√≠nh th·ªùi gian ƒë·ªçc (gi·∫£ s·ª≠ 200 t·ª´/ph√∫t)"""
    return max(1, word_count // 200)

def clean_text(text: str) -> str:
    """L√†m s·∫°ch vƒÉn b·∫£n"""
    if not text:
        return ""
    # Lo·∫°i b·ªè k√Ω t·ª± th·ª´a v√† chu·∫©n h√≥a kho·∫£ng tr·∫Øng
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'\n+', '\n', text)
    return text.strip()

def summarize_text(text: str, max_sentences: int = 3) -> str:
    """T√≥m t·∫Øt vƒÉn b·∫£n ƒë∆°n gi·∫£n"""
    if not text:
        return ""
    
    sentences = text.split('.')
    # L·ªçc c√¢u c√≥ ƒë·ªô d√†i h·ª£p l√Ω
    good_sentences = [s.strip() for s in sentences if len(s.strip()) > 20 and len(s.strip()) < 200]
    
    if len(good_sentences) <= max_sentences:
        return '. '.join(good_sentences) + '.'
    else:
        return '. '.join(good_sentences[:max_sentences]) + '.'

async def extract_article_content(url: str, language: str = "vi", extract_images: bool = True) -> ArticleResponse:
    """Tr√≠ch xu·∫•t n·ªôi dung b√†i vi·∫øt"""
    try:
        config = Config()
        config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        config.request_timeout = 10
        config.fetch_images = extract_images
        config.language = language
        
        article = Article(url, config=config)
        article.download()
        article.parse()
        
        if extract_images:
            article.nlp()
        
        # T√≠nh word count
        word_count = len(article.text.split()) if article.text else 0
        
        # T·∫°o response
        response = ArticleResponse(
            title=clean_text(article.title) if article.title else "Kh√¥ng c√≥ ti√™u ƒë·ªÅ",
            content=clean_text(article.text) if article.text else "Kh√¥ng th·ªÉ tr√≠ch xu·∫•t n·ªôi dung",
            summary=clean_text(article.summary) if article.summary else None,
            authors=article.authors or [],
            publish_date=article.publish_date.isoformat() if article.publish_date else None,
            url=str(url),
            images=article.images if extract_images else [],
            tags=list(article.tags) if article.tags else [],
            language=language,
            word_count=word_count,
            read_time_minutes=calculate_read_time(word_count),
            extracted_at=datetime.now(timezone.utc).isoformat()
        )
        
        return response
        
    except Exception as e:
        logger.error(f"L·ªói khi tr√≠ch xu·∫•t b√†i vi·∫øt {url}: {str(e)}")
        raise HTTPException(status_code=400, detail=f"Kh√¥ng th·ªÉ tr√≠ch xu·∫•t b√†i vi·∫øt: {str(e)}")

# Routes
@app.get("/", response_class=HTMLResponse)
async def home():
    """Trang ch·ªß v·ªõi giao di·ªán th√¢n thi·ªán"""
    html_content = """
    <!DOCTYPE html>
    <html lang="vi">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>News Content API - Nguy·ªÖn Ng·ªçc Thi·ªán</title>
        <style>
            * { margin: 0; padding: 0; box-sizing: border-box; }
            body { 
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; 
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                min-height: 100vh;
                display: flex;
                align-items: center;
                justify-content: center;
                color: #333;
            }
            .container { 
                background: rgba(255,255,255,0.95);
                padding: 2rem;
                border-radius: 20px;
                box-shadow: 0 15px 35px rgba(0,0,0,0.1);
                text-align: center;
                max-width: 600px;
                width: 90%;
                backdrop-filter: blur(10px);
            }
            h1 { 
                color: #4f46e5;
                margin-bottom: 1rem;
                font-size: 2.5rem;
                font-weight: 700;
            }
            .subtitle {
                color: #6b7280;
                margin-bottom: 2rem;
                font-size: 1.1rem;
            }
            .author {
                background: linear-gradient(45deg, #f59e0b, #ef4444);
                -webkit-background-clip: text;
                background-clip: text;
                -webkit-text-fill-color: transparent;
                font-weight: 600;
                margin-bottom: 2rem;
                font-size: 1.2rem;
            }
            .links {
                display: flex;
                gap: 1rem;
                justify-content: center;
                flex-wrap: wrap;
                margin: 2rem 0;
            }
            .btn {
                padding: 12px 24px;
                border-radius: 50px;
                text-decoration: none;
                font-weight: 600;
                transition: all 0.3s ease;
                display: inline-flex;
                align-items: center;
                gap: 8px;
            }
            .btn-primary {
                background: linear-gradient(45deg, #4f46e5, #7c3aed);
                color: white;
            }
            .btn-secondary {
                background: linear-gradient(45deg, #059669, #0d9488);
                color: white;
            }
            .btn-accent {
                background: linear-gradient(45deg, #dc2626, #ea580c);
                color: white;
            }
            .btn:hover {
                transform: translateY(-2px);
                box-shadow: 0 8px 25px rgba(0,0,0,0.15);
            }
            .features {
                display: grid;
                grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                gap: 1rem;
                margin: 2rem 0;
            }
            .feature {
                background: rgba(255,255,255,0.7);
                padding: 1.5rem;
                border-radius: 15px;
                border: 1px solid rgba(255,255,255,0.3);
            }
            .feature h3 {
                color: #4f46e5;
                margin-bottom: 0.5rem;
            }
            .endpoints {
                text-align: left;
                background: rgba(248,250,252,0.8);
                padding: 1.5rem;
                border-radius: 15px;
                margin: 1rem 0;
                border: 1px solid rgba(226,232,240,0.5);
            }
            .endpoint {
                font-family: 'Courier New', monospace;
                background: rgba(255,255,255,0.9);
                padding: 0.5rem;
                border-radius: 8px;
                margin: 0.5rem 0;
                border-left: 4px solid #4f46e5;
            }
            @media (max-width: 768px) {
                .container { margin: 1rem; padding: 1.5rem; }
                h1 { font-size: 2rem; }
                .links { flex-direction: column; align-items: center; }
                .btn { width: 200px; justify-content: center; }
            }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>üöÄ News Content API</h1>
            <p class="subtitle">API m·∫°nh m·∫Ω ƒë·ªÉ c√†o n·ªôi dung b√†i vi·∫øt v√† RSS feeds</p>
            <p class="author">Ph√°t tri·ªÉn b·ªüi Nguy·ªÖn Ng·ªçc Thi·ªán</p>
            
            <div class="features">
                <div class="feature">
                    <h3>üì∞ Tr√≠ch xu·∫•t b√†i vi·∫øt</h3>
                    <p>L·∫•y n·ªôi dung, ti√™u ƒë·ªÅ, h√¨nh ·∫£nh t·ª´ URL</p>
                </div>
                <div class="feature">
                    <h3>üì° RSS Feeds</h3>
                    <p>Ph√¢n t√≠ch v√† l·∫•y d·ªØ li·ªáu t·ª´ RSS feeds</p>
                </div>
                <div class="feature">
                    <h3>üîê B·∫£o m·∫≠t</h3>
                    <p>Bearer Token authentication</p>
                </div>
                <div class="feature">
                    <h3>üåê ƒêa ng√¥n ng·ªØ</h3>
                    <p>H·ªó tr·ª£ ti·∫øng Vi·ªát v√† nhi·ªÅu ng√¥n ng·ªØ kh√°c</p>
                </div>
            </div>

            <div class="endpoints">
                <h3>üìã API Endpoints:</h3>
                <div class="endpoint">GET /health - Ki·ªÉm tra tr·∫°ng th√°i API</div>
                <div class="endpoint">POST /extract-article - Tr√≠ch xu·∫•t n·ªôi dung b√†i vi·∫øt</div>
                <div class="endpoint">POST /extract-source - C√†o nhi·ªÅu b√†i vi·∫øt t·ª´ trang web</div>
                <div class="endpoint">POST /parse-feed - Ph√¢n t√≠ch RSS feeds</div>
            </div>
            
            <div class="links">
                <a href="/docs" class="btn btn-primary">üìö API Documentation</a>
                <a href="/redoc" class="btn btn-secondary">üìñ ReDoc</a>
                <a href="https://www.youtube.com/@kalvinthiensocial" class="btn btn-accent" target="_blank">üé• YouTube Channel</a>
            </div>
            
            <p style="margin-top: 2rem; color: #6b7280; font-size: 0.9rem;">
                üí° S·ª≠ d·ª•ng Bearer Token trong header Authorization ƒë·ªÉ truy c·∫≠p API<br>
                üìû Li√™n h·ªá: 08.8888.4749 | Facebook: Ban.Thien.Handsome
            </p>
        </div>
    </body>
    </html>
    """
    return HTMLResponse(content=html_content)

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Ki·ªÉm tra tr·∫°ng th√°i API"""
    return HealthResponse(
        status="healthy",
        message="News Content API ƒëang ho·∫°t ƒë·ªông b√¨nh th∆∞·ªùng",
        version="2.0.0",
        timestamp=datetime.now(timezone.utc).isoformat()
    )

@app.post("/extract-article", response_model=ArticleResponse)
async def extract_article(request: ArticleRequest, token: str = Depends(verify_token)):
    """Tr√≠ch xu·∫•t n·ªôi dung t·ª´ m·ªôt b√†i vi·∫øt"""
    return await extract_article_content(
        str(request.url), 
        request.language, 
        request.extract_images
    )

@app.post("/extract-source")
async def extract_from_source(request: SourceRequest, token: str = Depends(verify_token)):
    """C√†o nhi·ªÅu b√†i vi·∫øt t·ª´ m·ªôt trang web"""
    try:
        source = newspaper.build(str(request.url), language=request.language)
        articles = []
        
        for i, article in enumerate(source.articles[:request.max_articles]):
            try:
                article_response = await extract_article_content(
                    article.url, 
                    request.language, 
                    extract_images=False  # ƒê·ªÉ tƒÉng t·ªëc ƒë·ªô
                )
                articles.append(article_response.dict())
            except Exception as e:
                logger.warning(f"Kh√¥ng th·ªÉ tr√≠ch xu·∫•t b√†i vi·∫øt {article.url}: {str(e)}")
                continue
        
        return {
            "source_url": str(request.url),
            "total_found": len(source.articles),
            "extracted_count": len(articles),
            "articles": articles,
            "extracted_at": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"L·ªói khi c√†o t·ª´ source {request.url}: {str(e)}")
        raise HTTPException(status_code=400, detail=f"Kh√¥ng th·ªÉ c√†o t·ª´ source: {str(e)}")

@app.post("/parse-feed")
async def parse_rss_feed(request: FeedRequest, token: str = Depends(verify_token)):
    """Ph√¢n t√≠ch RSS feed v√† tr√≠ch xu·∫•t b√†i vi·∫øt"""
    try:
        feed = feedparser.parse(str(request.url))
        
        if feed.bozo:
            logger.warning(f"RSS feed c√≥ th·ªÉ kh√¥ng h·ª£p l·ªá: {request.url}")
        
        articles = []
        for entry in feed.entries[:request.max_articles]:
            try:
                # L·∫•y URL b√†i vi·∫øt
                article_url = entry.link if hasattr(entry, 'link') else None
                if not article_url:
                    continue
                
                # Tr√≠ch xu·∫•t n·ªôi dung chi ti·∫øt
                article_response = await extract_article_content(article_url, extract_images=False)
                
                # B·ªï sung th√¥ng tin t·ª´ RSS
                article_dict = article_response.dict()
                article_dict.update({
                    "rss_title": getattr(entry, 'title', ''),
                    "rss_summary": getattr(entry, 'summary', ''),
                    "rss_published": getattr(entry, 'published', ''),
                    "rss_categories": [tag.term for tag in getattr(entry, 'tags', [])]
                })
                
                articles.append(article_dict)
                
            except Exception as e:
                logger.warning(f"Kh√¥ng th·ªÉ x·ª≠ l√Ω entry RSS: {str(e)}")
                continue
        
        return {
            "feed_url": str(request.url),
            "feed_title": getattr(feed.feed, 'title', ''),
            "feed_description": getattr(feed.feed, 'description', ''),
            "total_entries": len(feed.entries),
            "extracted_count": len(articles),
            "articles": articles,
            "parsed_at": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"L·ªói khi parse RSS feed {request.url}: {str(e)}")
        raise HTTPException(status_code=400, detail=f"Kh√¥ng th·ªÉ parse RSS feed: {str(e)}")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
EOF

    echo "‚úÖ ƒê√£ t·∫°o News API th√†nh c√¥ng!"
fi

# T·∫°o file docker-compose.yml
echo "T·∫°o file docker-compose.yml..."
COMPOSE_CONTENT="services:
  n8n:
    build:
      context: .
      dockerfile: Dockerfile
    image: n8n-custom-ffmpeg:latest
    restart: always
    ports:
      - \"127.0.0.1:5678:5678\"
    environment:
      - N8N_HOST=${DOMAIN}
      - N8N_PORT=5678
      - N8N_PROTOCOL=https
      - NODE_ENV=production
      - WEBHOOK_URL=https://${DOMAIN}
      - GENERIC_TIMEZONE=Asia/Ho_Chi_Minh
      - N8N_DEFAULT_BINARY_DATA_MODE=filesystem
      - N8N_BINARY_DATA_STORAGE=/files
      - N8N_DEFAULT_BINARY_DATA_FILESYSTEM_DIRECTORY=/files
      - N8N_DEFAULT_BINARY_DATA_TEMP_DIRECTORY=/files/temp
      - NODE_FUNCTION_ALLOW_BUILTIN=child_process,path,fs,util,os
      - N8N_EXECUTIONS_DATA_MAX_SIZE=304857600
      - PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true
      - PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium-browser
    volumes:
      - ${N8N_DIR}:/home/node/.n8n
      - ${N8N_DIR}/files:/files
    user: \"node\"
    cap_add:
      - SYS_ADMIN"

if [ "$INSTALL_NEWS_API" = true ]; then
    # T·∫°o Bearer Token ng·∫´u nhi√™n
    API_TOKEN=$(openssl rand -base64 32 | tr -d "=+/" | cut -c1-32)
    echo "üîë Bearer Token cho News API: $API_TOKEN"
    echo "üìù L∆∞u token n√†y ƒë·ªÉ s·ª≠ d·ª•ng API!"
    echo "$API_TOKEN" > "$N8N_DIR/news_api_token.txt"
    
    COMPOSE_CONTENT="$COMPOSE_CONTENT

  fastapi:
    build:
      context: ./news_api
      dockerfile: Dockerfile
    image: news-api-custom:latest
    restart: always
    ports:
      - \"127.0.0.1:8000:8000\"
    environment:
      - NEWS_API_TOKEN=$API_TOKEN
    volumes:
      - ${N8N_DIR}/news_api:/app
    depends_on:
      - n8n"
fi

COMPOSE_CONTENT="$COMPOSE_CONTENT

  caddy:
    image: caddy:latest
    restart: always
    ports:
      - \"80:80\"
      - \"443:443\"
    volumes:
      - ${N8N_DIR}/Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      - n8n"

if [ "$INSTALL_NEWS_API" = true ]; then
    COMPOSE_CONTENT="$COMPOSE_CONTENT
      - fastapi"
fi

COMPOSE_CONTENT="$COMPOSE_CONTENT

volumes:
  caddy_data:
  caddy_config:"

echo "$COMPOSE_CONTENT" > "$N8N_DIR/docker-compose.yml"

# T·∫°o file Caddyfile
echo "T·∫°o file Caddyfile..."
CADDYFILE_CONTENT="${DOMAIN} {
    reverse_proxy n8n:5678
    tls internal
}"

if [ "$INSTALL_NEWS_API" = true ]; then
    CADDYFILE_CONTENT="$CADDYFILE_CONTENT

${API_DOMAIN} {
    reverse_proxy fastapi:8000
    tls internal
}"
fi

echo "$CADDYFILE_CONTENT" > "$N8N_DIR/Caddyfile"

# C·∫•u h√¨nh g·ª≠i backup qua Telegram
TELEGRAM_CONF_FILE="$N8N_DIR/telegram_config.txt"
read -p "B·∫°n c√≥ mu·ªën c·∫•u h√¨nh g·ª≠i file backup h√†ng ng√†y qua Telegram kh√¥ng? (y/n): " CONFIGURE_TELEGRAM
if [[ "$CONFIGURE_TELEGRAM" =~ ^[Yy]$ ]]; then
    echo "======================================================================"
    echo "üì± H∆Ø·ªöNG D·∫™N L·∫§Y TELEGRAM BOT TOKEN V√Ä CHAT ID:"
    echo "1. Bot Token:"
    echo "   - M·ªü Telegram, t√¨m @BotFather"
    echo "   - G·ª≠i l·ªánh: /newbot"
    echo "   - ƒê·∫∑t t√™n v√† username cho bot"
    echo "   - Copy Bot Token nh·∫≠n ƒë∆∞·ª£c"
    echo ""
    echo "2. Chat ID:"
    echo "   - C√° nh√¢n: T√¨m @userinfobot, g·ª≠i /start ƒë·ªÉ l·∫•y User ID"
    echo "   - Nh√≥m: Th√™m bot v√†o nh√≥m, g·ª≠i tin nh·∫Øn, sau ƒë√≥ truy c·∫≠p:"
    echo "     https://api.telegram.org/bot<BOT_TOKEN>/getUpdates"
    echo "   - Chat ID nh√≥m b·∫Øt ƒë·∫ßu b·∫±ng d·∫•u tr·ª´ (-)"
    echo "======================================================================"
    read -p "Nh·∫≠p Telegram Bot Token c·ªßa b·∫°n: " TELEGRAM_BOT_TOKEN
    read -p "Nh·∫≠p Telegram Chat ID c·ªßa b·∫°n (ho·∫∑c group ID): " TELEGRAM_CHAT_ID
    if [ -n "$TELEGRAM_BOT_TOKEN" ] && [ -n "$TELEGRAM_CHAT_ID" ]; then
        echo "TELEGRAM_BOT_TOKEN=\"$TELEGRAM_BOT_TOKEN\"" > "$TELEGRAM_CONF_FILE"
        echo "TELEGRAM_CHAT_ID=\"$TELEGRAM_CHAT_ID\"" >> "$TELEGRAM_CONF_FILE"
        echo "DOMAIN=\"$DOMAIN\"" >> "$TELEGRAM_CONF_FILE"
        chmod 600 "$TELEGRAM_CONF_FILE"
        echo "‚úÖ ƒê√£ l∆∞u c·∫•u h√¨nh Telegram v√†o $TELEGRAM_CONF_FILE"
        
        # Test g·ª≠i tin nh·∫Øn
        echo "üß™ ƒêang test g·ª≠i tin nh·∫Øn Telegram..."
        TEST_MSG="üéâ Ch√∫c m·ª´ng! Backup t·ª± ƒë·ªông N8N ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh th√†nh c√¥ng cho domain: $DOMAIN"
        curl -s -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendMessage" \
            -d chat_id="${TELEGRAM_CHAT_ID}" \
            -d text="${TEST_MSG}" > /dev/null
        echo "‚úÖ ƒê√£ g·ª≠i tin nh·∫Øn test. Ki·ªÉm tra Telegram c·ªßa b·∫°n!"
    else
        echo "‚ùå Bot Token ho·∫∑c Chat ID kh√¥ng ƒë∆∞·ª£c cung c·∫•p. B·ªè qua c·∫•u h√¨nh Telegram."
    fi
elif [[ "$CONFIGURE_TELEGRAM" =~ ^[Nn]$ ]]; then
    echo "ƒê√£ b·ªè qua c·∫•u h√¨nh g·ª≠i backup qua Telegram."
    if [ -f "$TELEGRAM_CONF_FILE" ]; then
        rm -f "$TELEGRAM_CONF_FILE"
    fi
else
    echo "L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá. M·∫∑c ƒë·ªãnh b·ªè qua c·∫•u h√¨nh Telegram."
fi

# T·∫°o script sao l∆∞u workflow v√† credentials (c·∫£i ti·∫øn)
echo "T·∫°o script sao l∆∞u workflow v√† credentials t·∫°i $N8N_DIR/backup-workflows.sh..."
cat << 'EOF' > $N8N_DIR/backup-workflows.sh
#!/bin/bash

N8N_DIR_VALUE="__N8N_DIR__"
BACKUP_BASE_DIR="${N8N_DIR_VALUE}/files/backup_full"
LOG_FILE="${BACKUP_BASE_DIR}/backup.log"
TELEGRAM_CONF_FILE="${N8N_DIR_VALUE}/telegram_config.txt"
DATE="$(date +"%Y%m%d_%H%M%S")"
BACKUP_FILE_NAME="n8n_backup_${DATE}.tar.gz"
BACKUP_FILE_PATH="${BACKUP_BASE_DIR}/${BACKUP_FILE_NAME}"
TEMP_DIR_HOST="/tmp/n8n_backup_host_${DATE}"
TELEGRAM_FILE_SIZE_LIMIT=20971520 # 20MB

log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "${LOG_FILE}"
}

send_telegram_message() {
    local message="$1"
    if [ -f "${TELEGRAM_CONF_FILE}" ]; then
        source "${TELEGRAM_CONF_FILE}"
        if [ -n "${TELEGRAM_BOT_TOKEN}" ] && [ -n "${TELEGRAM_CHAT_ID}" ]; then
            (curl -s -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendMessage" \
                -d chat_id="${TELEGRAM_CHAT_ID}" \
                -d text="${message}" \
                -d parse_mode="Markdown" > /dev/null 2>&1) &
        fi
    fi
}

send_telegram_document() {
    local file_path="$1"
    local caption="$2"
    if [ -f "${TELEGRAM_CONF_FILE}" ]; then
        source "${TELEGRAM_CONF_FILE}"
        if [ -n "${TELEGRAM_BOT_TOKEN}" ] && [ -n "${TELEGRAM_CHAT_ID}" ]; then
            local file_size="$(du -b "${file_path}" | cut -f1)"
            if [ "${file_size}" -le "${TELEGRAM_FILE_SIZE_LIMIT}" ]; then
                log "ƒêang g·ª≠i file backup qua Telegram: ${file_path}"
                (curl -s -X POST "https://api.telegram.org/bot${TELEGRAM_BOT_TOKEN}/sendDocument" \
                    -F chat_id="${TELEGRAM_CHAT_ID}" \
                    -F document=@"${file_path}" \
                    -F caption="${caption}" > /dev/null 2>&1) &
            else
                local readable_size="$(echo "scale=2; ${file_size} / 1024 / 1024" | bc)"
                log "File backup qu√° l·ªõn (${readable_size} MB) ƒë·ªÉ g·ª≠i qua Telegram."
                send_telegram_message "üì¶ Backup N8N (*__DOMAIN__*) ho√†n t·∫•t!\nüìÅ File: \`${BACKUP_FILE_NAME}\`\nüìè Size: ${readable_size}MB (qu√° l·ªõn ƒë·ªÉ g·ª≠i)\nüìç V·ªã tr√≠: \`${file_path}\`"
            fi
        fi
    fi
}

mkdir -p "${BACKUP_BASE_DIR}"
log "üöÄ B·∫Øt ƒë·∫ßu sao l∆∞u workflows v√† credentials..."
send_telegram_message "üîÑ B·∫Øt ƒë·∫ßu qu√° tr√¨nh backup N8N cho domain: *__DOMAIN__*..."

# T√¨m container N8N
N8N_CONTAINER_ID="$(docker ps -q --filter "name=n8n" --format '{{.ID}}' | head -n 1)"

if [ -z "${N8N_CONTAINER_ID}" ]; then
    log "‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y container n8n ƒëang ch·∫°y."
    send_telegram_message "‚ùå L·ªói backup N8N (*__DOMAIN__*): Kh√¥ng t√¨m th·∫•y container ƒëang ch·∫°y."
    exit 1
fi
log "‚úÖ T√¨m th·∫•y container N8N ID: ${N8N_CONTAINER_ID}"

# T·∫°o th∆∞ m·ª•c backup t·∫°m
mkdir -p "${TEMP_DIR_HOST}/workflows"
mkdir -p "${TEMP_DIR_HOST}/credentials" 
mkdir -p "${TEMP_DIR_HOST}/config"

# Export workflows
log "üìã ƒêang export workflows..."
TEMP_DIR_CONTAINER_UNIQUE="/tmp/n8n_export_${DATE}"
docker exec "${N8N_CONTAINER_ID}" mkdir -p "${TEMP_DIR_CONTAINER_UNIQUE}"

WORKFLOWS_JSON="$(docker exec "${N8N_CONTAINER_ID}" n8n list:workflow --json 2>/dev/null || echo "[]")"

if [ -z "${WORKFLOWS_JSON}" ] || [ "${WORKFLOWS_JSON}" == "[]" ]; then
    log "‚ö†Ô∏è  C·∫£nh b√°o: Kh√¥ng t√¨m th·∫•y workflow n√†o ƒë·ªÉ backup."
    echo "[]" > "${TEMP_DIR_HOST}/workflows/workflows.json"
else
    echo "${WORKFLOWS_JSON}" | jq -c '.[]' 2>/dev/null | while IFS= read -r workflow; do
        id="$(echo "${workflow}" | jq -r '.id' 2>/dev/null || echo "")"
        name="$(echo "${workflow}" | jq -r '.name' 2>/dev/null | tr -dc '[:alnum:][:space:]_-' | tr '[:space:]' '_')"
        safe_name="$(echo "${name}" | sed 's/[^a-zA-Z0-9_-]/_/g' | cut -c1-100)"
        
        if [ -n "${id}" ] && [ "${id}" != "null" ]; then
            output_file_container="${TEMP_DIR_CONTAINER_UNIQUE}/${id}-${safe_name}.json"
            log "üìÑ ƒêang export workflow: '${name}' (ID: ${id})"
            if docker exec "${N8N_CONTAINER_ID}" n8n export:workflow --id="${id}" --output="${output_file_container}" 2>/dev/null; then
                log "‚úÖ ƒê√£ export workflow ID ${id} th√†nh c√¥ng."
            else
                log "‚ùå L·ªói khi export workflow ID ${id}."
            fi
        fi
    done

    # Copy workflows t·ª´ container ra host
    if docker cp "${N8N_CONTAINER_ID}:${TEMP_DIR_CONTAINER_UNIQUE}/." "${TEMP_DIR_HOST}/workflows/" 2>/dev/null; then
        log "‚úÖ Copy workflows t·ª´ container th√†nh c√¥ng."
    else
        log "‚ùå L·ªói khi copy workflows t·ª´ container."
    fi
    
    # Save workflows list
    echo "${WORKFLOWS_JSON}" > "${TEMP_DIR_HOST}/workflows/workflows.json"
fi

# Backup database v√† encryption key
log "üîê ƒêang backup database v√† encryption key..."
DB_PATH_HOST="${N8N_DIR_VALUE}/database.sqlite"
KEY_PATH_HOST="${N8N_DIR_VALUE}/encryptionKey"
CONFIG_PATH_HOST="${N8N_DIR_VALUE}/config"

if [ -f "${DB_PATH_HOST}" ]; then
    cp "${DB_PATH_HOST}" "${TEMP_DIR_HOST}/credentials/database.sqlite"
    log "‚úÖ ƒê√£ backup database.sqlite"
else
    log "‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y database.sqlite t·∫°i ${DB_PATH_HOST}"
fi

if [ -f "${KEY_PATH_HOST}" ]; then
    cp "${KEY_PATH_HOST}" "${TEMP_DIR_HOST}/credentials/encryptionKey"
    log "‚úÖ ƒê√£ backup encryptionKey"
else
    log "‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y encryptionKey t·∫°i ${KEY_PATH_HOST}"
fi

# Backup config n·∫øu c√≥
if [ -d "${CONFIG_PATH_HOST}" ]; then
    cp -r "${CONFIG_PATH_HOST}"/* "${TEMP_DIR_HOST}/config/" 2>/dev/null
    log "‚úÖ ƒê√£ backup config files"
fi

# T·∫°o metadata file
cat << METADATA > "${TEMP_DIR_HOST}/backup_metadata.json"
{
    "backup_date": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "domain": "__DOMAIN__",
    "n8n_version": "$(docker exec "${N8N_CONTAINER_ID}" n8n --version 2>/dev/null || echo 'unknown')",
    "backup_type": "full",
    "backup_size": "to_be_calculated",
    "created_by": "Nguy·ªÖn Ng·ªçc Thi·ªán - Auto Backup Script"
}
METADATA

# T·∫°o file n√©n
log "üì¶ ƒêang t·∫°o file backup: ${BACKUP_FILE_PATH}"
if tar -czf "${BACKUP_FILE_PATH}" -C "${TEMP_DIR_HOST}" . 2>/dev/null; then
    # T√≠nh size v√† c·∫≠p nh·∫≠t metadata
    BACKUP_SIZE=$(du -h "${BACKUP_FILE_PATH}" | cut -f1)
    log "‚úÖ T·∫°o file backup th√†nh c√¥ng. Size: ${BACKUP_SIZE}"
    
    # G·ª≠i qua Telegram
    send_telegram_document "${BACKUP_FILE_PATH}" "üì¶ Backup N8N (*__DOMAIN__*) ng√†y $(date '+%d/%m/%Y %H:%M')
üìÅ Size: ${BACKUP_SIZE}
üéØ Workflows: $(ls -1 "${TEMP_DIR_HOST}/workflows"/*.json 2>/dev/null | wc -l)
‚è∞ Th·ªùi gian: $(date '+%H:%M:%S')"
else
    log "‚ùå L·ªói: Kh√¥ng th·ªÉ t·∫°o file backup ${BACKUP_FILE_PATH}."
    send_telegram_message "‚ùå L·ªói backup N8N (*__DOMAIN__*): Kh√¥ng th·ªÉ t·∫°o file backup."
fi

# Cleanup
log "üßπ D·ªçn d·∫πp th∆∞ m·ª•c t·∫°m..."
rm -rf "${TEMP_DIR_HOST}"
docker exec "${N8N_CONTAINER_ID}" rm -rf "${TEMP_DIR_CONTAINER_UNIQUE}" 2>/dev/null || true

# Cleanup old backups (gi·ªØ 30 b·∫£n g·∫ßn nh·∫•t)
log "üóÇÔ∏è  D·ªçn d·∫πp backup c≈© (gi·ªØ 30 b·∫£n g·∫ßn nh·∫•t)..."
find "${BACKUP_BASE_DIR}" -maxdepth 1 -name 'n8n_backup_*.tar.gz' -type f -printf '%T@ %p\n' 2>/dev/null | \
sort -nr | tail -n +31 | cut -d' ' -f2- | xargs -r rm -f

BACKUP_COUNT=$(find "${BACKUP_BASE_DIR}" -maxdepth 1 -name 'n8n_backup_*.tar.gz' -type f | wc -l)

log "‚úÖ Backup ho√†n t·∫•t: ${BACKUP_FILE_PATH}"
if [ -f "${BACKUP_FILE_PATH}" ]; then
    send_telegram_message "‚úÖ Backup N8N (*__DOMAIN__*) ho√†n t·∫•t!
üìÅ File: \`${BACKUP_FILE_NAME}\`
üìä T·ªïng backup: ${BACKUP_COUNT}/30
üìã Log: \`${LOG_FILE}\`"
else
    send_telegram_message "‚ùå Backup N8N (*__DOMAIN__*) th·∫•t b·∫°i! Ki·ªÉm tra log: \`${LOG_FILE}\`"
fi

exit 0
EOF

# Thay th·∫ø bi·∫øn trong script
sed -i "s|__N8N_DIR__|$N8N_DIR|g" $N8N_DIR/backup-workflows.sh
sed -i "s|__DOMAIN__|$DOMAIN|g" $N8N_DIR/backup-workflows.sh
chmod +x $N8N_DIR/backup-workflows.sh

# T·∫°o script backup th·ªß c√¥ng ƒë·ªÉ test
echo "T·∫°o script backup th·ªß c√¥ng t·∫°i $N8N_DIR/backup-manual.sh..."
cat << 'EOF' > $N8N_DIR/backup-manual.sh
#!/bin/bash

echo "üß™ Ch·∫°y backup th·ªß c√¥ng ƒë·ªÉ test..."
echo "======================================================================"

# Ch·∫°y script backup ch√≠nh
SCRIPT_DIR="$(dirname "$0")"
BACKUP_SCRIPT="$SCRIPT_DIR/backup-workflows.sh"

if [ -f "$BACKUP_SCRIPT" ]; then
    echo "üìç Ch·∫°y: $BACKUP_SCRIPT"
    echo "======================================================================"
    bash "$BACKUP_SCRIPT"
    echo "======================================================================"
    echo "‚úÖ Backup th·ªß c√¥ng ho√†n t·∫•t!"
    echo "üìÅ Ki·ªÉm tra th∆∞ m·ª•c: $SCRIPT_DIR/files/backup_full/"
    echo "üìã Xem log: $SCRIPT_DIR/files/backup_full/backup.log"
else
    echo "‚ùå Kh√¥ng t√¨m th·∫•y script backup: $BACKUP_SCRIPT"
    exit 1
fi
EOF
chmod +x $N8N_DIR/backup-manual.sh

# T·∫°o script troubleshoot
echo "T·∫°o script ch·∫©n ƒëo√°n t·∫°i $N8N_DIR/troubleshoot.sh..."
cat << 'EOF' > $N8N_DIR/troubleshoot.sh
#!/bin/bash

echo "üîç CH·∫®N ƒêO√ÅN H·ªÜ TH·ªêNG N8N"
echo "======================================================================"

# Th√¥ng tin c∆° b·∫£n
echo "üìä TH√îNG TIN H·ªÜ TH·ªêNG:"
echo "- Th·ªùi gian: $(date)"
echo "- Uptime: $(uptime)"
echo "- Disk usage: $(df -h / | tail -1 | awk '{print $5}')"
echo "- Memory: $(free -h | grep Mem | awk '{print $3"/"$2}')"
echo "- Swap: $(free -h | grep Swap | awk '{print $3"/"$2}')"
echo ""

# Docker status
echo "üê≥ DOCKER STATUS:"
if command -v docker &> /dev/null; then
    echo "‚úÖ Docker installed: $(docker --version)"
    echo "üîÑ Docker service: $(systemctl is-active docker)"
    echo "üì¶ Containers:"
    docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
    echo ""
    echo "üíæ Docker disk usage:"
    docker system df
else
    echo "‚ùå Docker not found!"
fi
echo ""

# N8N specific
N8N_DIR_VALUE="__N8N_DIR__"
echo "üöÄ N8N STATUS:"
echo "üìÅ N8N Directory: $N8N_DIR_VALUE"
if [ -d "$N8N_DIR_VALUE" ]; then
    echo "‚úÖ N8N directory exists"
    echo "üìã Files in N8N directory:"
    ls -la "$N8N_DIR_VALUE"
    echo ""
    
    if [ -f "$N8N_DIR_VALUE/docker-compose.yml" ]; then
        echo "‚úÖ docker-compose.yml exists"
        cd "$N8N_DIR_VALUE"
        
        # Container logs
        echo "üìù Recent container logs:"
        if command -v docker-compose &> /dev/null; then
            docker-compose logs --tail=10 n8n
        elif docker compose version &> /dev/null; then
            docker compose logs --tail=10 n8n
        fi
    else
        echo "‚ùå docker-compose.yml not found"
    fi
else
    echo "‚ùå N8N directory not found"
fi
echo ""

# Network checks
echo "üåê NETWORK CHECKS:"
echo "üîç External IP: $(curl -s https://api.ipify.org || echo 'Failed to get IP')"
echo "üîç DNS resolution test:"
nslookup google.com
echo ""

# Backup status
echo "üíæ BACKUP STATUS:"
BACKUP_DIR="$N8N_DIR_VALUE/files/backup_full"
if [ -d "$BACKUP_DIR" ]; then
    echo "‚úÖ Backup directory exists"
    echo "üìä Backup files:"
    ls -lah "$BACKUP_DIR"/*.tar.gz 2>/dev/null | tail -5 || echo "No backup files found"
    
    if [ -f "$BACKUP_DIR/backup.log" ]; then
        echo "üìã Recent backup log:"
        tail -10 "$BACKUP_DIR/backup.log"
    fi
else
    echo "‚ùå Backup directory not found"
fi
echo ""

# Cron status
echo "‚è∞ CRON STATUS:"
echo "üîÑ Cron service: $(systemctl is-active cron)"
echo "üìã Active cron jobs:"
crontab -l | grep -E "(backup|update)" || echo "No N8N related cron jobs found"
echo ""

echo "======================================================================"
echo "‚úÖ Ch·∫©n ƒëo√°n ho√†n t·∫•t!"
echo "üìû N·∫øu c·∫ßn h·ªó tr·ª£, li√™n h·ªá: 08.8888.4749"
EOF

sed -i "s|__N8N_DIR__|$N8N_DIR|g" $N8N_DIR/troubleshoot.sh
chmod +x $N8N_DIR/troubleshoot.sh

# ƒê·∫∑t quy·ªÅn cho th∆∞ m·ª•c n8n
echo "ƒê·∫∑t quy·ªÅn cho th∆∞ m·ª•c n8n t·∫°i $N8N_DIR..."
sudo chown -R 1000:1000 $N8N_DIR 
sudo chmod -R u+rwX,g+rX,o+rX $N8N_DIR
sudo chown -R 1000:1000 $N8N_DIR/files
sudo chmod -R u+rwX,g+rX,o+rX $N8N_DIR/files

# Kh·ªüi ƒë·ªông c√°c container
echo "Kh·ªüi ƒë·ªông c√°c container... Qu√° tr√¨nh build image c√≥ th·ªÉ m·∫•t v√†i ph√∫t..."
cd $N8N_DIR

# X√°c ƒë·ªãnh l·ªánh docker-compose
if command -v docker-compose &> /dev/null; then
    DOCKER_COMPOSE_CMD="docker-compose"
elif command -v docker &> /dev/null && docker compose version &> /dev/null; then
    DOCKER_COMPOSE_CMD="docker compose"
else
    echo "L·ªói: Kh√¥ng t√¨m th·∫•y l·ªánh docker-compose ho·∫∑c docker compose plugin."
    exit 1
fi

echo "ƒêang build Docker images... (c√≥ th·ªÉ m·∫•t v√†i ph√∫t)"
if ! $DOCKER_COMPOSE_CMD build; then
    echo "C·∫£nh b√°o: Build Docker images th·∫•t b·∫°i."
    echo "ƒêang th·ª≠ build l·∫°i v·ªõi c·∫•u h√¨nh ƒë∆°n gi·∫£n h∆°n..."
    
    # T·∫°o Dockerfile ƒë∆°n gi·∫£n h∆°n n·∫øu build ban ƒë·∫ßu th·∫•t b·∫°i
    cat << 'EOF' > $N8N_DIR/Dockerfile.simple
FROM n8nio/n8n:latest
USER root
RUN apk update && \
    apk add --no-cache ffmpeg wget zip unzip python3 py3-pip jq tar gzip \
    chromium nss freetype freetype-dev harfbuzz ca-certificates ttf-freefont \
    font-noto font-noto-cjk font-noto-emoji dbus udev
RUN pip3 install --break-system-packages -U yt-dlp && \
    chmod +x /usr/bin/yt-dlp
ENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true \
    PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium-browser
RUN mkdir -p /files/youtube_content_anylystic /files/backup_full /files/temp && \
    chown -R node:node /files
USER node
WORKDIR /home/node
EOF
    
    # C·∫≠p nh·∫≠t docker-compose.yml ƒë·ªÉ s·ª≠ d·ª•ng Dockerfile ƒë∆°n gi·∫£n
    sed -i 's/dockerfile: Dockerfile/dockerfile: Dockerfile.simple/' $N8N_DIR/docker-compose.yml
    
    if ! $DOCKER_COMPOSE_CMD build; then
        echo "L·ªói: Kh√¥ng th·ªÉ build Docker image th·∫≠m ch√≠ v·ªõi c·∫•u h√¨nh ƒë∆°n gi·∫£n."
        echo "Ki·ªÉm tra k·∫øt n·ªëi m·∫°ng v√† th·ª≠ l·∫°i."
        exit 1
    fi
    echo "Build th√†nh c√¥ng v·ªõi c·∫•u h√¨nh ƒë∆°n gi·∫£n (kh√¥ng c√≥ Puppeteer nodes)."
fi

echo "ƒêang kh·ªüi ƒë·ªông c√°c container..."
if ! $DOCKER_COMPOSE_CMD up -d; then
    echo "L·ªói: Kh·ªüi ƒë·ªông container th·∫•t b·∫°i."
    echo "Ki·ªÉm tra logs: $DOCKER_COMPOSE_CMD logs"
    exit 1
fi

echo "ƒê·ª£i c√°c container kh·ªüi ƒë·ªông (30 gi√¢y)..."
sleep 30

# Ki·ªÉm tra c√°c container ƒë√£ ch·∫°y ch∆∞a
echo "Ki·ªÉm tra tr·∫°ng th√°i c√°c container..."
if $DOCKER_COMPOSE_CMD ps | grep -q "n8n"; then
    echo "‚úÖ Container n8n ƒë√£ ch·∫°y th√†nh c√¥ng."
else
    echo "‚ö†Ô∏è  Container n8n c√≥ th·ªÉ ch∆∞a ch·∫°y. Ki·ªÉm tra logs: $DOCKER_COMPOSE_CMD logs n8n"
fi

if $DOCKER_COMPOSE_CMD ps | grep -q "caddy"; then
    echo "‚úÖ Container caddy ƒë√£ ch·∫°y th√†nh c√¥ng."
else
    echo "‚ö†Ô∏è  Container caddy c√≥ th·ªÉ ch∆∞a ch·∫°y. Ki·ªÉm tra logs: $DOCKER_COMPOSE_CMD logs caddy"
fi

if [ "$INSTALL_NEWS_API" = true ] && $DOCKER_COMPOSE_CMD ps | grep -q "fastapi"; then
    echo "‚úÖ Container News API ƒë√£ ch·∫°y th√†nh c√¥ng."
else
    if [ "$INSTALL_NEWS_API" = true ]; then
        echo "‚ö†Ô∏è  Container News API c√≥ th·ªÉ ch∆∞a ch·∫°y. Ki·ªÉm tra logs: $DOCKER_COMPOSE_CMD logs fastapi"
    fi
fi

# T·∫°o script c·∫≠p nh·∫≠t t·ª± ƒë·ªông (c·∫£i ti·∫øn)
echo "T·∫°o script c·∫≠p nh·∫≠t t·ª± ƒë·ªông t·∫°i $N8N_DIR/update-n8n.sh..."
cat << 'EOF' > $N8N_DIR/update-n8n.sh
#!/bin/bash
N8N_DIR_VALUE="__N8N_DIR__"
LOG_FILE="$N8N_DIR_VALUE/update.log"

log() { 
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" >> "$LOG_FILE"
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# H·ªèi ng∆∞·ªùi d√πng c√≥ mu·ªën c·∫≠p nh·∫≠t kh√¥ng (n·∫øu ch·∫°y th·ªß c√¥ng)
if [ -t 0 ]; then  # Ki·ªÉm tra n·∫øu ch·∫°y interactively
    read -p "üîÑ B·∫°n c√≥ mu·ªën c·∫≠p nh·∫≠t N8N v√† c√°c th√†nh ph·∫ßn kh√¥ng? (y/n): " UPDATE_CHOICE
    if [[ ! "$UPDATE_CHOICE" =~ ^[Yy]$ ]]; then
        log "‚ùå Ng∆∞·ªùi d√πng t·ª´ ch·ªëi c·∫≠p nh·∫≠t."
        exit 0
    fi
fi

log "üöÄ B·∫Øt ƒë·∫ßu ki·ªÉm tra c·∫≠p nh·∫≠t..."
cd "$N8N_DIR_VALUE"

if command -v docker-compose &> /dev/null; then 
    DOCKER_COMPOSE="docker-compose"
elif command -v docker &> /dev/null && docker compose version &> /dev/null; then 
    DOCKER_COMPOSE="docker compose"
else 
    log "‚ùå L·ªói: Docker Compose kh√¥ng t√¨m th·∫•y."
    exit 1
fi

# Backup tr∆∞·ªõc khi c·∫≠p nh·∫≠t
log "üíæ Ch·∫°y backup tr∆∞·ªõc khi c·∫≠p nh·∫≠t..."
if [ -x "$N8N_DIR_VALUE/backup-workflows.sh" ]; then
    "$N8N_DIR_VALUE/backup-workflows.sh"
    log "‚úÖ Backup ho√†n t·∫•t."
else
    log "‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y script backup."
fi

# C·∫≠p nh·∫≠t yt-dlp tr√™n host
log "üé• C·∫≠p nh·∫≠t yt-dlp tr√™n host..."
if command -v pipx &> /dev/null; then 
    pipx upgrade yt-dlp
elif [ -d "/opt/yt-dlp-venv" ]; then 
    /opt/yt-dlp-venv/bin/pip install -U yt-dlp
fi

# K√©o image m·ªõi
log "üê≥ K√©o images m·ªõi nh·∫•t..."
docker pull n8nio/n8n:latest
docker pull caddy:latest

# Ki·ªÉm tra c√≥ c·∫≠p nh·∫≠t kh√¥ng
CURRENT_N8N_IMAGE_ID="$(docker images -q n8n-custom-ffmpeg:latest)"
log "üîß Build l·∫°i images custom..."
if ! $DOCKER_COMPOSE build --no-cache; then 
    log "‚ùå L·ªói build images custom."
    exit 1
fi
NEW_N8N_IMAGE_ID="$(docker images -q n8n-custom-ffmpeg:latest)"

if [ "$CURRENT_N8N_IMAGE_ID" != "$NEW_N8N_IMAGE_ID" ] || [ -z "$CURRENT_N8N_IMAGE_ID" ]; then
    log "üîÑ Ph√°t hi·ªán image m·ªõi, ti·∫øn h√†nh c·∫≠p nh·∫≠t containers..."
    
    log "üõë D·ª´ng containers..."
    $DOCKER_COMPOSE down
    
    log "üöÄ Kh·ªüi ƒë·ªông l·∫°i containers..."
    $DOCKER_COMPOSE up -d
    
    # ƒê·ª£i containers kh·ªüi ƒë·ªông
    sleep 30
    
    log "‚úÖ C·∫≠p nh·∫≠t containers ho√†n t·∫•t."
else
    log "‚ÑπÔ∏è  Kh√¥ng c√≥ c·∫≠p nh·∫≠t m·ªõi cho N8N images."
fi

# C·∫≠p nh·∫≠t yt-dlp trong container
log "üé• C·∫≠p nh·∫≠t yt-dlp trong container n8n..."
N8N_CONTAINER_FOR_UPDATE="$(docker ps -q --filter name=n8n)"
if [ -n "$N8N_CONTAINER_FOR_UPDATE" ]; then
    docker exec -u root $N8N_CONTAINER_FOR_UPDATE pip3 install --break-system-packages -U yt-dlp
    log "‚úÖ yt-dlp trong container ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t."
else
    log "‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y container n8n ƒëang ch·∫°y."
fi

# D·ªçn d·∫πp Docker
log "üßπ D·ªçn d·∫πp Docker images c≈©..."
docker image prune -f

log "‚úÖ Ki·ªÉm tra c·∫≠p nh·∫≠t ho√†n t·∫•t."
EOF

sed -i "s|__N8N_DIR__|$N8N_DIR|g" $N8N_DIR/update-n8n.sh
chmod +x $N8N_DIR/update-n8n.sh

# Thi·∫øt l·∫≠p cron job v·ªõi t√πy ch·ªçn auto-update
read -p "B·∫°n c√≥ mu·ªën b·∫≠t t·ª± ƒë·ªông c·∫≠p nh·∫≠t m·ªói 12 gi·ªù kh√¥ng? (y/n): " ENABLE_AUTO_UPDATE
if [[ "$ENABLE_AUTO_UPDATE" =~ ^[Yy]$ ]]; then
    CRON_USER=$(whoami)
    UPDATE_CRON="0 */12 * * * $N8N_DIR/update-n8n.sh"
    BACKUP_CRON="0 2 * * * $N8N_DIR/backup-workflows.sh"
    (crontab -u $CRON_USER -l 2>/dev/null | grep -v "update-n8n.sh" | grep -v "backup-workflows.sh"; echo "$UPDATE_CRON"; echo "$BACKUP_CRON") | crontab -u $CRON_USER -
    echo "‚úÖ ƒê√£ thi·∫øt l·∫≠p cron job c·∫≠p nh·∫≠t t·ª± ƒë·ªông m·ªói 12 gi·ªù v√† backup h√†ng ng√†y l√∫c 2:00 AM."
else
    CRON_USER=$(whoami)
    BACKUP_CRON="0 2 * * * $N8N_DIR/backup-workflows.sh"
    (crontab -u $CRON_USER -l 2>/dev/null | grep -v "update-n8n.sh" | grep -v "backup-workflows.sh"; echo "$BACKUP_CRON") | crontab -u $CRON_USER -
    echo "‚úÖ ƒê√£ thi·∫øt l·∫≠p ch·ªâ backup h√†ng ng√†y l√∫c 2:00 AM. C·∫≠p nh·∫≠t th·ªß c√¥ng khi c·∫ßn."
fi

echo "======================================================================"
echo "üéâ HO√ÄN T·∫§T C√ÄI ƒê·∫∂T N8N V·ªöI T·∫§T C·∫¢ T√çNH NƒÇNG N√ÇNG CAO!"
echo "======================================================================"
echo ""
echo "üöÄ TRUY C·∫¨P ·ª®NG D·ª§NG:"
echo "   üì± N8N Main: https://${DOMAIN}"

if [ "$INSTALL_NEWS_API" = true ]; then
    echo "   üì∞ News API: https://${API_DOMAIN}"
    echo "   üìö API Docs: https://${API_DOMAIN}/docs"
    echo "   üîë Bearer Token: $(cat $N8N_DIR/news_api_token.txt)"
fi

echo ""
echo "üíæ TH√îNG TIN H·ªÜ TH·ªêNG:"
if [ "$(swapon --show | wc -l)" -gt 0 ]; then
    SWAP_INFO=$(free -h | grep Swap | awk '{print $2}')
    echo "   üíø Swap Memory: $SWAP_INFO"
fi
echo "   üìÅ Th∆∞ m·ª•c c√†i ƒë·∫∑t: $N8N_DIR"
echo "   üé• Video downloads: $N8N_DIR/files/youtube_content_anylystic/"
echo "   üíæ Backup storage: $N8N_DIR/files/backup_full/"

echo ""
echo "üõ†Ô∏è  C√ÅC L·ªÜNH QU·∫¢N L√ù:"
echo "   üîç Ch·∫©n ƒëo√°n h·ªá th·ªëng: $N8N_DIR/troubleshoot.sh"
echo "   üíæ Backup th·ªß c√¥ng: $N8N_DIR/backup-manual.sh"
echo "   üîÑ C·∫≠p nh·∫≠t th·ªß c√¥ng: $N8N_DIR/update-n8n.sh"
echo "   üìã Xem logs: cd $N8N_DIR && docker-compose logs -f"

echo ""
echo "üìä T√çNH NƒÇNG ƒê√É C√ÄI ƒê·∫∂T:"
echo "   ‚úÖ N8N v·ªõi FFmpeg, yt-dlp, Puppeteer"
echo "   ‚úÖ SSL t·ª± ƒë·ªông v·ªõi Caddy"
echo "   ‚úÖ Backup t·ª± ƒë·ªông h√†ng ng√†y (2:00 AM)"

if [ -f "$TELEGRAM_CONF_FILE" ]; then
    echo "   ‚úÖ Telegram notifications"
fi

if [ "$INSTALL_NEWS_API" = true ]; then
    echo "   ‚úÖ News Content API (FastAPI + Newspaper4k)"
fi

if [[ "$ENABLE_AUTO_UPDATE" =~ ^[Yy]$ ]]; then
    echo "   ‚úÖ Auto-update m·ªói 12 gi·ªù"
else
    echo "   üìù Auto-update: T·∫Øt (c·∫≠p nh·∫≠t th·ªß c√¥ng)"
fi

echo ""
echo "üìñ H∆Ø·ªöNG D·∫™N CHI TI·∫æT:"
echo "   üé¨ YouTube: https://www.youtube.com/@kalvinthiensocial"
echo "   üìò Facebook: https://www.facebook.com/Ban.Thien.Handsome/"
echo "   üìû Li√™n h·ªá: 08.8888.4749"

if [ "$INSTALL_NEWS_API" = true ]; then
    echo ""
    echo "üîß S·ª¨ D·ª§NG NEWS API TRONG N8N:"
    echo "   1. T·∫°o HTTP Request node trong N8N"
    echo "   2. Method: POST"
    echo "   3. URL: https://${API_DOMAIN}/extract-article"
    echo "   4. Headers: Authorization: Bearer $(cat $N8N_DIR/news_api_token.txt)"
    echo "   5. Body: {\"url\": \"https://dantri.com.vn/example.htm\"}"
fi

echo ""
echo "======================================================================"
echo "üéâ Ch√∫c b·∫°n s·ª≠ d·ª•ng N8N hi·ªáu qu·∫£! - Nguy·ªÖn Ng·ªçc Thi·ªán"
echo "======================================================================"
