#!/bin/bash

# =============================================================================
# üöÄ SCRIPT C√ÄI ƒê·∫∂T N8N T·ª∞ ƒê·ªòNG V·ªöI FFMPEG, YT-DLP, PUPPETEER V√Ä NEWS API
# =============================================================================
# T√°c gi·∫£: Nguy·ªÖn Ng·ªçc Thi·ªán
# YouTube: https://www.youtube.com/@kalvinthiensocial?sub_confirmation=1
# Zalo: 08.8888.4749
# C·∫≠p nh·∫≠t: 28/06/2025
# =============================================================================

set -e  # Exit on any error

# =============================================================================
# üé® THI·∫æT L·∫¨P M√ÄU S·∫ÆC V√Ä LOGGING
# =============================================================================

# M√†u s·∫Øc d·ªÖ ƒë·ªçc tr√™n n·ªÅn ƒëen
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'      # Thay ƒë·ªïi t·ª´ xanh d∆∞∆°ng sang cyan
MAGENTA='\033[0;35m'
WHITE='\033[1;37m'
BOLD='\033[1m'
NC='\033[0m' # No Color

# Logging functions
log_info() {
    echo -e "${CYAN}‚ÑπÔ∏è $1${NC}"
}

log_success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

log_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è $1${NC}"
}

log_error() {
    echo -e "${RED}‚ùå $1${NC}"
}

log_header() {
    echo ""
    echo -e "${WHITE}========================================================================${NC}"
    echo -e "${WHITE}$1${NC}"
    echo -e "${WHITE}========================================================================${NC}"
    echo ""
}

log_message() {
    echo -e "${WHITE}$1${NC}"
}

# =============================================================================
# üîß BI·∫æN TO√ÄN C·ª§C
# =============================================================================

INSTALL_DIR="/home/n8n"
DOMAIN=""
API_DOMAIN=""
NEWS_API_TOKEN=""
TELEGRAM_BOT_TOKEN=""
TELEGRAM_CHAT_ID=""
AUTO_UPDATE="y"
ENABLE_TELEGRAM="n"
ENABLE_NEWS_API="y"
CLEAN_INSTALL="n"

# =============================================================================
# üõ†Ô∏è H√ÄM TI·ªÜN √çCH
# =============================================================================

# Ki·ªÉm tra quy·ªÅn root
check_root() {
    if [[ $EUID -ne 0 ]]; then
        log_error "Script n√†y c·∫ßn ch·∫°y v·ªõi quy·ªÅn root. Vui l√≤ng s·ª≠ d·ª•ng sudo."
        exit 1
    fi
}

# Ph√°t hi·ªán h·ªá ƒëi·ªÅu h√†nh
detect_os() {
    if [[ -f /etc/os-release ]]; then
        . /etc/os-release
        OS=$NAME
        VER=$VERSION_ID
    else
        log_error "Kh√¥ng th·ªÉ x√°c ƒë·ªãnh h·ªá ƒëi·ªÅu h√†nh"
        exit 1
    fi
    
    if [[ $OS != *"Ubuntu"* ]]; then
        log_warning "Script n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø cho Ubuntu. H·ªá ƒëi·ªÅu h√†nh hi·ªán t·∫°i: $OS"
        read -p "B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c? (y/N): " -r
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            exit 1
        fi
    fi
}

# Ki·ªÉm tra k·∫øt n·ªëi internet
check_internet() {
    if ! ping -c 1 google.com &> /dev/null; then
        log_error "Kh√¥ng c√≥ k·∫øt n·ªëi internet"
        exit 1
    fi
}

# X√°c ƒë·ªãnh Docker Compose command
get_docker_compose_cmd() {
    if command -v docker-compose &> /dev/null; then
        echo "docker-compose"
    elif docker compose version &> /dev/null 2>&1; then
        echo "docker compose"
    else
        log_error "Docker Compose kh√¥ng ƒë∆∞·ª£c t√¨m th·∫•y"
        exit 1
    fi
}

# =============================================================================
# üìã H√ÄM NH·∫¨P TH√îNG TIN
# =============================================================================

# Nh·∫≠p domain
input_domain() {
    log_header "üåê THI·∫æT L·∫¨P DOMAIN"
    
    while true; do
        read -p "$(echo -e "${CYAN}üåê Nh·∫≠p domain cho N8N (v√≠ d·ª•: n8n.yourdomain.com): ${NC}")" DOMAIN
        
        if [[ -z "$DOMAIN" ]]; then
            log_error "Domain kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng!"
            continue
        fi
        
        # Ki·ªÉm tra format domain
        if [[ ! "$DOMAIN" =~ ^[a-zA-Z0-9][a-zA-Z0-9-]{1,61}[a-zA-Z0-9]\.[a-zA-Z]{2,}$ ]] && [[ ! "$DOMAIN" =~ ^[a-zA-Z0-9-]+\.[a-zA-Z0-9-]+\.[a-zA-Z]{2,}$ ]]; then
            log_error "Format domain kh√¥ng h·ª£p l·ªá!"
            continue
        fi
        
        API_DOMAIN="api.$DOMAIN"
        log_info "Domain N8N: $DOMAIN"
        log_info "Domain API: $API_DOMAIN"
        
        read -p "$(echo -e "${CYAN}X√°c nh·∫≠n domain n√†y? (Y/n): ${NC}")" -r
        if [[ $REPLY =~ ^[Nn]$ ]]; then
            continue
        fi
        break
    done
}

# H·ªèi v·ªÅ vi·ªác x√≥a c√†i ƒë·∫∑t c≈©
ask_clean_install() {
    if [[ -d "$INSTALL_DIR" ]]; then
        log_warning "Ph√°t hi·ªán c√†i ƒë·∫∑t N8N c≈© t·∫°i $INSTALL_DIR"
        read -p "$(echo -e "${YELLOW}B·∫°n c√≥ mu·ªën x√≥a c√†i ƒë·∫∑t c≈© v√† c√†i ƒë·∫∑t l·∫°i t·ª´ ƒë·∫ßu? (y/N): ${NC}")" -r
        if [[ $REPLY =~ ^[Yy]$ ]]; then
            CLEAN_INSTALL="y"
        fi
    fi
}

# H·ªèi v·ªÅ News API
ask_news_api() {
    log_header "üì∞ THI·∫æT L·∫¨P NEWS CONTENT API"
    
    read -p "$(echo -e "${CYAN}B·∫°n c√≥ mu·ªën c√†i ƒë·∫∑t News Content API? (Y/n): ${NC}")" -r
    if [[ $REPLY =~ ^[Nn]$ ]]; then
        ENABLE_NEWS_API="n"
        return
    fi
    
    ENABLE_NEWS_API="y"
    
    while true; do
        read -p "$(echo -e "${CYAN}üîë ƒê·∫∑t Bearer Token cho API (√≠t nh·∫•t 20 k√Ω t·ª±): ${NC}")" NEWS_API_TOKEN
        
        if [[ ${#NEWS_API_TOKEN} -lt 20 ]]; then
            log_error "Bearer Token ph·∫£i c√≥ √≠t nh·∫•t 20 k√Ω t·ª±!"
            continue
        fi
        
        if [[ ! "$NEWS_API_TOKEN" =~ ^[a-zA-Z0-9]+$ ]]; then
            log_error "Bearer Token ch·ªâ ƒë∆∞·ª£c ch·ª©a ch·ªØ c√°i v√† s·ªë!"
            continue
        fi
        
        break
    done
}

# H·ªèi v·ªÅ Telegram backup
ask_telegram_backup() {
    log_header "üì± THI·∫æT L·∫¨P TELEGRAM BACKUP"
    
    read -p "$(echo -e "${CYAN}B·∫°n c√≥ mu·ªën thi·∫øt l·∫≠p backup qua Telegram? (y/N): ${NC}")" -r
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        ENABLE_TELEGRAM="n"
        return
    fi
    
    ENABLE_TELEGRAM="y"
    
    log_info "ƒê·ªÉ thi·∫øt l·∫≠p Telegram backup, b·∫°n c·∫ßn:"
    log_info "1. T·∫°o bot v·ªõi @BotFather v√† l·∫•y Bot Token"
    log_info "2. L·∫•y Chat ID (c√° nh√¢n ho·∫∑c nh√≥m)"
    echo ""
    
    while true; do
        read -p "$(echo -e "${CYAN}ü§ñ Nh·∫≠p Telegram Bot Token: ${NC}")" TELEGRAM_BOT_TOKEN
        if [[ -z "$TELEGRAM_BOT_TOKEN" ]]; then
            log_error "Bot Token kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng!"
            continue
        fi
        break
    done
    
    while true; do
        read -p "$(echo -e "${CYAN}üÜî Nh·∫≠p Telegram Chat ID: ${NC}")" TELEGRAM_CHAT_ID
        if [[ -z "$TELEGRAM_CHAT_ID" ]]; then
            log_error "Chat ID kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng!"
            continue
        fi
        break
    done
}

# H·ªèi v·ªÅ auto update
ask_auto_update() {
    read -p "$(echo -e "${CYAN}üîÑ B·∫°n c√≥ mu·ªën b·∫≠t t·ª± ƒë·ªông c·∫≠p nh·∫≠t? (Y/n): ${NC}")" -r
    if [[ $REPLY =~ ^[Nn]$ ]]; then
        AUTO_UPDATE="n"
    fi
}

# =============================================================================
# üîç H√ÄM KI·ªÇM TRA
# =============================================================================

# Ki·ªÉm tra DNS
check_dns() {
    log_header "üåê KI·ªÇM TRA DNS"
    
    log_info "ƒêang ki·ªÉm tra DNS cho $DOMAIN..."
    
    # L·∫•y IP c·ªßa domain
    DOMAIN_IP=$(dig +short "$DOMAIN" A | tail -n1)
    if [[ -z "$DOMAIN_IP" ]]; then
        log_error "Kh√¥ng th·ªÉ resolve domain $DOMAIN"
        log_error "Vui l√≤ng ki·ªÉm tra:"
        log_error "1. Domain ƒë√£ ƒë∆∞·ª£c ƒëƒÉng k√Ω ch∆∞a?"
        log_error "2. DNS A record ƒë√£ tr·ªè v·ªÅ IP server ch∆∞a?"
        exit 1
    fi
    
    # L·∫•y IP c·ªßa server
    SERVER_IP=$(curl -s https://api.ipify.org || curl -s http://ipv4.icanhazip.com || echo "unknown")
    
    log_info "IP c·ªßa domain $DOMAIN: $DOMAIN_IP"
    log_info "IP c·ªßa server: $SERVER_IP"
    
    if [[ "$DOMAIN_IP" != "$SERVER_IP" ]]; then
        log_warning "IP c·ªßa domain kh√¥ng kh·ªõp v·ªõi IP server!"
        log_warning "SSL certificate c√≥ th·ªÉ kh√¥ng ƒë∆∞·ª£c c·∫•p th√†nh c√¥ng."
        read -p "$(echo -e "${YELLOW}B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c? (y/N): ${NC}")" -r
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            exit 1
        fi
    else
        log_success "DNS ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng!"
    fi
}

# =============================================================================
# üíæ H√ÄM THI·∫æT L·∫¨P SWAP
# =============================================================================

setup_swap() {
    log_header "üíæ THI·∫æT L·∫¨P SWAP MEMORY"
    
    # Ki·ªÉm tra swap hi·ªán t·∫°i
    CURRENT_SWAP=$(free -h | awk '/^Swap:/ {print $2}')
    log_info "Swap hi·ªán t·∫°i: $CURRENT_SWAP"
    
    # N·∫øu ƒë√£ c√≥ swap >= 2GB th√¨ b·ªè qua
    if [[ "$CURRENT_SWAP" != "0B" ]] && [[ "$CURRENT_SWAP" != "0" ]]; then
        SWAP_SIZE_MB=$(free -m | awk '/^Swap:/ {print $2}')
        if [[ $SWAP_SIZE_MB -ge 2048 ]]; then
            log_success "Swap ƒë√£ ƒë·ªß l·ªõn ($CURRENT_SWAP), b·ªè qua thi·∫øt l·∫≠p swap."
            return
        fi
    fi
    
    # T√≠nh to√°n swap size d·ª±a tr√™n RAM
    RAM_MB=$(free -m | awk '/^Mem:/ {print $2}')
    
    if [[ $RAM_MB -le 1024 ]]; then
        SWAP_SIZE="2G"
    elif [[ $RAM_MB -le 2048 ]]; then
        SWAP_SIZE="3G"
    elif [[ $RAM_MB -le 4096 ]]; then
        SWAP_SIZE="4G"
    else
        SWAP_SIZE="4G"
    fi
    
    log_info "ƒêang t·∫°o swap file $SWAP_SIZE..."
    
    # T·∫°o swap file
    fallocate -l $SWAP_SIZE /swapfile 2>/dev/null || dd if=/dev/zero of=/swapfile bs=1M count=${SWAP_SIZE%G}000 2>/dev/null
    chmod 600 /swapfile
    mkswap /swapfile >/dev/null 2>&1
    swapon /swapfile
    
    # Th√™m v√†o fstab n·∫øu ch∆∞a c√≥
    if ! grep -q "/swapfile" /etc/fstab; then
        echo "/swapfile none swap sw 0 0" >> /etc/fstab
    fi
    
    # T·ªëi ∆∞u swap settings
    echo "vm.swappiness=10" >> /etc/sysctl.conf 2>/dev/null || true
    echo "vm.vfs_cache_pressure=50" >> /etc/sysctl.conf 2>/dev/null || true
    
    log_success "Swap $SWAP_SIZE ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p!"
}

# =============================================================================
# üê≥ H√ÄM C√ÄI ƒê·∫∂T DOCKER
# =============================================================================

install_docker() {
    log_header "‚öôÔ∏è C√ÄI ƒê·∫∂T DOCKER"
    
    if command -v docker &> /dev/null; then
        log_info "Docker ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t"
        
        # Ki·ªÉm tra Docker daemon
        if ! docker info >/dev/null 2>&1; then
            log_info "ƒêang kh·ªüi ƒë·ªông Docker daemon..."
            systemctl start docker
            systemctl enable docker
        fi
        return
    fi
    
    log_info "ƒêang c√†i ƒë·∫∑t Docker..."
    
    # C·∫≠p nh·∫≠t package list
    apt-get update -qq
    
    # C√†i ƒë·∫∑t dependencies
    apt-get install -y -qq \
        apt-transport-https \
        ca-certificates \
        curl \
        gnupg \
        lsb-release \
        software-properties-common
    
    # Th√™m Docker GPG key
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
    
    # Th√™m Docker repository
    echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
    
    # C√†i ƒë·∫∑t Docker
    apt-get update -qq
    apt-get install -y -qq docker-ce docker-ce-cli containerd.io docker-compose-plugin
    
    # C√†i ƒë·∫∑t docker-compose standalone n·∫øu c·∫ßn
    if ! command -v docker-compose &> /dev/null; then
        curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
        chmod +x /usr/local/bin/docker-compose
    fi
    
    # Kh·ªüi ƒë·ªông Docker
    systemctl start docker
    systemctl enable docker
    
    # Th√™m user v√†o docker group
    usermod -aG docker $SUDO_USER 2>/dev/null || true
    
    log_success "Docker ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t th√†nh c√¥ng!"
}

# =============================================================================
# üóëÔ∏è H√ÄM X√ìA C√ÄI ƒê·∫∂T C≈®
# =============================================================================

clean_old_installation() {
    if [[ "$CLEAN_INSTALL" != "y" ]]; then
        return
    fi
    
    log_header "‚ö†Ô∏è X√ìA C√ÄI ƒê·∫∂T C≈®"
    
    log_info "ƒêang d·ª´ng containers c≈©..."
    cd "$INSTALL_DIR" 2>/dev/null || true
    DOCKER_COMPOSE_CMD=$(get_docker_compose_cmd)
    $DOCKER_COMPOSE_CMD down 2>/dev/null || true
    
    log_info "ƒêang x√≥a th∆∞ m·ª•c c√†i ƒë·∫∑t c≈©..."
    rm -rf "$INSTALL_DIR"
    
    log_info "ƒêang x√≥a Docker volumes c≈©..."
    docker volume rm n8n_caddy_data n8n_caddy_config 2>/dev/null || true
    
    log_success "ƒê√£ x√≥a c√†i ƒë·∫∑t c≈© th√†nh c√¥ng!"
}

# =============================================================================
# üìÅ H√ÄM T·∫†O C·∫§U TR√öC TH∆Ø M·ª§C
# =============================================================================

create_directory_structure() {
    log_header "‚öôÔ∏è T·∫†O C·∫§U TR√öC TH∆Ø M·ª§C"
    
    # T·∫°o th∆∞ m·ª•c ch√≠nh
    mkdir -p "$INSTALL_DIR"
    cd "$INSTALL_DIR"
    
    # T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c
    mkdir -p files/{backup_full,temp,youtube_content_anylystic}
    mkdir -p logs
    
    if [[ "$ENABLE_NEWS_API" == "y" ]]; then
        mkdir -p news_api
    fi
    
    # Set permissions
    chmod 755 "$INSTALL_DIR"
    chmod -R 755 files/
    
    log_success "C·∫•u tr√∫c th∆∞ m·ª•c ƒë√£ ƒë∆∞·ª£c t·∫°o!"
}

# =============================================================================
# üì∞ H√ÄM T·∫†O NEWS CONTENT API
# =============================================================================

create_news_api() {
    if [[ "$ENABLE_NEWS_API" != "y" ]]; then
        return
    fi
    
    log_header "üì∞ T·∫†O NEWS CONTENT API"
    
    # L∆∞u token v√†o file ri√™ng v·ªõi permissions 600
    echo "$NEWS_API_TOKEN" > "$INSTALL_DIR/news_api_token.txt"
    chmod 600 "$INSTALL_DIR/news_api_token.txt"
    
    # T·∫°o requirements.txt
    cat > "$INSTALL_DIR/news_api/requirements.txt" << 'EOF'
fastapi==0.104.1
uvicorn[standard]==0.24.0
newspaper4k==0.9.3
user-agents==2.2.0
python-multipart==0.0.6
pydantic==2.5.0
requests==2.31.0
lxml==4.9.3
Pillow==10.1.0
nltk==3.8.1
feedparser==6.0.10
beautifulsoup4==4.12.2
python-dateutil==2.8.2
EOF

    # T·∫°o main.py v·ªõi newspaper4k ƒë√∫ng c√°ch v√† random user agent
    cat > "$INSTALL_DIR/news_api/main.py" << 'EOF'
import os
import random
import asyncio
import logging
from typing import List, Optional, Dict, Any
from datetime import datetime
import json
import re

import newspaper
from newspaper import Article, Source
import feedparser
import requests
from bs4 import BeautifulSoup
from user_agents import parse as parse_user_agent
import nltk

from fastapi import FastAPI, HTTPException, Depends, Security, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, HttpUrl, Field, validator

# Download NLTK data
try:
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
except:
    pass

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load Bearer Token from file
try:
    with open('/app/news_api_token.txt', 'r') as f:
        BEARER_TOKEN = f.read().strip()
except:
    BEARER_TOKEN = os.getenv('NEWS_API_TOKEN', 'default_token_change_me')

# Random User Agent Pool
USER_AGENTS = [
    # Chrome
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    
    # Firefox
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (X11; Linux x86_64; rv:121.0) Gecko/20100101 Firefox/121.0",
    
    # Safari
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
    "Mozilla/5.0 (iPhone; CPU iPhone OS 17_1 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Mobile/15E148 Safari/604.1",
    
    # Edge
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0"
]

def get_random_headers():
    """Generate random headers with user agent"""
    user_agent = random.choice(USER_AGENTS)
    parsed_ua = parse_user_agent(user_agent)
    
    headers = {
        'User-Agent': user_agent,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9,vi;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    # Add browser-specific headers
    if 'Chrome' in user_agent:
        headers.update({
            'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': f'"{parsed_ua.os.family}"',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1'
        })
    elif 'Firefox' in user_agent:
        headers.update({
            'Cache-Control': 'max-age=0',
        })
    
    return headers

# FastAPI app
app = FastAPI(
    title="News Content API",
    description="Advanced News Content Extraction API with Newspaper4k",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Security
security = HTTPBearer()

def verify_token(credentials: HTTPAuthorizationCredentials = Security(security)):
    """Verify Bearer Token"""
    if credentials.credentials != BEARER_TOKEN:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid authentication token",
            headers={"WWW-Authenticate": "Bearer"},
        )
    return credentials.credentials

# Pydantic models
class ArticleRequest(BaseModel):
    url: HttpUrl
    language: str = Field(default="auto", description="Language code (auto, en, vi, zh, etc.)")
    extract_images: bool = Field(default=True, description="Extract images from article")
    summarize: bool = Field(default=False, description="Generate summary using NLP")
    timeout: int = Field(default=30, ge=5, le=120, description="Request timeout in seconds")

class SourceRequest(BaseModel):
    url: HttpUrl
    max_articles: int = Field(default=10, ge=1, le=100, description="Maximum articles to extract")
    language: str = Field(default="auto", description="Language code")
    timeout: int = Field(default=60, ge=10, le=300, description="Request timeout in seconds")

class FeedRequest(BaseModel):
    url: HttpUrl
    max_articles: int = Field(default=10, ge=1, le=50, description="Maximum articles to parse")
    timeout: int = Field(default=30, ge=5, le=120, description="Request timeout in seconds")

class ArticleResponse(BaseModel):
    title: str
    content: str
    summary: Optional[str] = None
    authors: List[str]
    publish_date: Optional[datetime] = None
    top_image: Optional[str] = None
    images: List[str]
    keywords: List[str]
    language: str
    url: str
    word_count: int
    read_time_minutes: int

# Helper functions
def extract_article_content(url: str, language: str = "auto", timeout: int = 30) -> Dict[str, Any]:
    """Extract article content using newspaper4k"""
    try:
        # Get random headers
        headers = get_random_headers()
        
        # Create article with custom config
        config = newspaper.Config()
        config.browser_user_agent = headers['User-Agent']
        config.request_timeout = timeout
        config.number_threads = 1
        config.thread_timeout_seconds = timeout
        config.ignored_content_types_defaults = {}
        
        if language != "auto":
            config.language = language
        
        # Create and process article
        article = Article(str(url), config=config)
        
        # Set custom headers for requests
        article.download(input_html=None, title=None, recursion_counter=0)
        article.parse()
        
        # Try NLP processing
        try:
            article.nlp()
        except Exception as e:
            logger.warning(f"NLP processing failed: {e}")
        
        # Calculate read time (average 200 words per minute)
        word_count = len(article.text.split()) if article.text else 0
        read_time = max(1, round(word_count / 200))
        
        return {
            "title": article.title or "No title found",
            "content": article.text or "No content extracted",
            "summary": article.summary or None,
            "authors": article.authors or [],
            "publish_date": article.publish_date,
            "top_image": article.top_image or None,
            "images": list(article.images) if article.images else [],
            "keywords": article.keywords or [],
            "language": article.meta_lang or language,
            "url": str(url),
            "word_count": word_count,
            "read_time_minutes": read_time
        }
        
    except Exception as e:
        logger.error(f"Error extracting article from {url}: {e}")
        raise HTTPException(
            status_code=400,
            detail=f"Failed to extract article: {str(e)}"
        )

def extract_source_articles(url: str, max_articles: int = 10, language: str = "auto", timeout: int = 60) -> List[Dict[str, Any]]:
    """Extract multiple articles from a news source"""
    try:
        # Get random headers
        headers = get_random_headers()
        
        # Create source with custom config
        config = newspaper.Config()
        config.browser_user_agent = headers['User-Agent']
        config.request_timeout = timeout
        config.number_threads = 3
        config.thread_timeout_seconds = timeout
        
        if language != "auto":
            config.language = language
        
        # Build source
        source = Source(str(url), config=config)
        source.build()
        
        # Limit articles
        articles_to_process = source.articles[:max_articles]
        results = []
        
        for article in articles_to_process:
            try:
                article.download()
                article.parse()
                
                # Try NLP
                try:
                    article.nlp()
                except:
                    pass
                
                word_count = len(article.text.split()) if article.text else 0
                read_time = max(1, round(word_count / 200))
                
                results.append({
                    "title": article.title or "No title",
                    "content": article.text or "No content",
                    "summary": article.summary or None,
                    "authors": article.authors or [],
                    "publish_date": article.publish_date,
                    "top_image": article.top_image or None,
                    "images": list(article.images) if article.images else [],
                    "keywords": article.keywords or [],
                    "language": article.meta_lang or language,
                    "url": article.url,
                    "word_count": word_count,
                    "read_time_minutes": read_time
                })
                
            except Exception as e:
                logger.warning(f"Failed to process article {article.url}: {e}")
                continue
        
        return results
        
    except Exception as e:
        logger.error(f"Error extracting source {url}: {e}")
        raise HTTPException(
            status_code=400,
            detail=f"Failed to extract source: {str(e)}"
        )

# API Routes
@app.get("/", response_class=HTMLResponse)
async def homepage():
    """API Homepage with documentation"""
    html_content = f"""
    <!DOCTYPE html>
    <html>
    <head>
        <title>News Content API</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <style>
            body {{ font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; margin: 0; padding: 20px; background: #f5f5f5; }}
            .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
            h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}
            h2 {{ color: #34495e; margin-top: 30px; }}
            .endpoint {{ background: #ecf0f1; padding: 15px; border-radius: 5px; margin: 10px 0; }}
            .method {{ background: #3498db; color: white; padding: 5px 10px; border-radius: 3px; font-weight: bold; }}
            .method.post {{ background: #e74c3c; }}
            code {{ background: #f8f9fa; padding: 2px 5px; border-radius: 3px; font-family: 'Courier New', monospace; }}
            .warning {{ background: #fff3cd; border: 1px solid #ffeaa7; padding: 15px; border-radius: 5px; margin: 20px 0; }}
            .info {{ background: #d1ecf1; border: 1px solid #bee5eb; padding: 15px; border-radius: 5px; margin: 20px 0; }}
            .token-info {{ background: #f8d7da; border: 1px solid #f5c6cb; padding: 15px; border-radius: 5px; margin: 20px 0; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>üöÄ News Content API v2.0</h1>
            <p>Advanced News Content Extraction API powered by <strong>Newspaper4k</strong> with Random User Agent rotation.</p>
            
            <div class="token-info">
                <h3>üîê Authentication Required</h3>
                <p>All API endpoints require Bearer Token authentication.</p>
                <p><strong>Your token was set during installation.</strong></p>
                <p>Use: <code>Authorization: Bearer YOUR_TOKEN</code></p>
            </div>

            <div class="info">
                <h3>üìö Documentation</h3>
                <p>‚Ä¢ <a href="/docs" target="_blank">Swagger UI Documentation</a></p>
                <p>‚Ä¢ <a href="/redoc" target="_blank">ReDoc Documentation</a></p>
            </div>

            <h2>üìã Available Endpoints</h2>
            
            <div class="endpoint">
                <span class="method">GET</span> <code>/health</code>
                <p>Check API health status</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span> <code>/extract-article</code>
                <p>Extract content from a single article URL</p>
                <p><strong>Parameters:</strong> url, language, extract_images, summarize, timeout</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span> <code>/extract-source</code>
                <p>Extract multiple articles from a news website</p>
                <p><strong>Parameters:</strong> url, max_articles, language, timeout</p>
            </div>
            
            <div class="endpoint">
                <span class="method post">POST</span> <code>/parse-feed</code>
                <p>Parse RSS/Atom feeds</p>
                <p><strong>Parameters:</strong> url, max_articles, timeout</p>
            </div>

            <h2>üîß Change Bearer Token</h2>
            <div class="warning">
                <p><strong>Method 1:</strong> Edit docker-compose.yml</p>
                <code>cd /home/n8n && nano docker-compose.yml</code>
                <p>Find <code>NEWS_API_TOKEN</code> and change the value, then restart:</p>
                <code>docker compose restart fastapi</code>
                
                <p><strong>Method 2:</strong> One-liner command</p>
                <code>cd /home/n8n && sed -i 's/NEWS_API_TOKEN=.*/NEWS_API_TOKEN="NEW_TOKEN"/' docker-compose.yml && docker compose restart fastapi</code>
                
                <p><strong>Method 3:</strong> Environment variable</p>
                <code>docker exec -it n8n-fastapi-1 sh -c 'echo "NEW_TOKEN" > /app/news_api_token.txt'</code>
                <code>docker compose restart fastapi</code>
            </div>

            <h2>üåü Features</h2>
            <ul>
                <li>‚úÖ <strong>Newspaper4k</strong> - Latest article extraction library</li>
                <li>‚úÖ <strong>Random User Agents</strong> - Anti-detection with 10+ user agents</li>
                <li>‚úÖ <strong>Multi-language</strong> - Support 80+ languages</li>
                <li>‚úÖ <strong>Image Extraction</strong> - Get article images and top image</li>
                <li>‚úÖ <strong>NLP Processing</strong> - Keywords and summary generation</li>
                <li>‚úÖ <strong>RSS/Atom Feeds</strong> - Parse news feeds</li>
                <li>‚úÖ <strong>Source Extraction</strong> - Bulk article extraction</li>
                <li>‚úÖ <strong>Rate Limiting</strong> - Built-in protection</li>
            </ul>

            <h2>üí° Example Usage</h2>
            <div class="endpoint">
                <h4>Extract Single Article:</h4>
                <code>
curl -X POST "https://api.{DOMAIN}/extract-article" \\<br>
&nbsp;&nbsp;&nbsp;&nbsp;-H "Authorization: Bearer YOUR_TOKEN" \\<br>
&nbsp;&nbsp;&nbsp;&nbsp;-H "Content-Type: application/json" \\<br>
&nbsp;&nbsp;&nbsp;&nbsp;-d '{{"url": "https://example.com/article", "language": "en"}}'
                </code>
            </div>

            <p style="margin-top: 40px; text-align: center; color: #7f8c8d;">
                <strong>Created by Nguy·ªÖn Ng·ªçc Thi·ªán</strong><br>
                <a href="https://www.youtube.com/@kalvinthiensocial" target="_blank">YouTube Channel</a> | 
                <a href="https://www.facebook.com/Ban.Thien.Handsome/" target="_blank">Facebook</a>
            </p>
        </div>
    </body>
    </html>
    """
    return html_content.replace("{DOMAIN}", os.getenv("DOMAIN", "yourdomain.com"))

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "2.0.0",
        "features": {
            "newspaper4k": True,
            "random_user_agents": True,
            "nlp_processing": True,
            "multi_language": True,
            "rss_feeds": True
        }
    }

@app.post("/extract-article", response_model=ArticleResponse)
async def extract_article(
    request: ArticleRequest,
    token: str = Depends(verify_token)
):
    """Extract content from a single article URL"""
    result = extract_article_content(
        str(request.url),
        request.language,
        request.timeout
    )
    return ArticleResponse(**result)

@app.post("/extract-source")
async def extract_source(
    request: SourceRequest,
    token: str = Depends(verify_token)
):
    """Extract multiple articles from a news source"""
    articles = extract_source_articles(
        str(request.url),
        request.max_articles,
        request.language,
        request.timeout
    )
    
    return {
        "source_url": str(request.url),
        "total_articles": len(articles),
        "articles": articles,
        "extracted_at": datetime.now().isoformat()
    }

@app.post("/parse-feed")
async def parse_feed(
    request: FeedRequest,
    token: str = Depends(verify_token)
):
    """Parse RSS/Atom feed"""
    try:
        headers = get_random_headers()
        
        # Parse feed
        feed = feedparser.parse(str(request.url), request_headers=headers)
        
        if feed.bozo:
            raise HTTPException(
                status_code=400,
                detail="Invalid RSS/Atom feed"
            )
        
        articles = []
        entries = feed.entries[:request.max_articles]
        
        for entry in entries:
            # Extract basic info
            article_data = {
                "title": getattr(entry, 'title', 'No title'),
                "content": getattr(entry, 'summary', '') or getattr(entry, 'description', ''),
                "url": getattr(entry, 'link', ''),
                "publish_date": None,
                "authors": [],
                "word_count": 0,
                "read_time_minutes": 1
            }
            
            # Parse publish date
            if hasattr(entry, 'published_parsed') and entry.published_parsed:
                try:
                    article_data["publish_date"] = datetime(*entry.published_parsed[:6])
                except:
                    pass
            
            # Parse authors
            if hasattr(entry, 'author'):
                article_data["authors"] = [entry.author]
            
            # Calculate word count and read time
            content = article_data["content"]
            if content:
                word_count = len(content.split())
                article_data["word_count"] = word_count
                article_data["read_time_minutes"] = max(1, round(word_count / 200))
            
            articles.append(article_data)
        
        return {
            "feed_url": str(request.url),
            "feed_title": getattr(feed.feed, 'title', 'Unknown'),
            "feed_description": getattr(feed.feed, 'description', ''),
            "total_articles": len(articles),
            "articles": articles,
            "parsed_at": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Error parsing feed {request.url}: {e}")
        raise HTTPException(
            status_code=400,
            detail=f"Failed to parse feed: {str(e)}"
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
EOF

    # T·∫°o Dockerfile cho News API
    cat > "$INSTALL_DIR/news_api/Dockerfile" << 'EOF'
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libxml2-dev \
    libxslt-dev \
    libjpeg-dev \
    zlib1g-dev \
    libpng-dev \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY main.py .

# Copy token file
COPY ../news_api_token.txt /app/news_api_token.txt

# Expose port
EXPOSE 8000

# Run the application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]
EOF

    log_success "News Content API ƒë√£ ƒë∆∞·ª£c t·∫°o v·ªõi Newspaper4k v√† Random User Agent!"
}

# =============================================================================
# üê≥ H√ÄM T·∫†O N8N DOCKERFILE
# =============================================================================

create_n8n_dockerfile() {
    log_header "‚öôÔ∏è T·∫†O N8N DOCKERFILE"
    
    cat > "$INSTALL_DIR/Dockerfile" << 'EOF'
FROM n8nio/n8n:latest

USER root

# Install system dependencies
RUN apk add --no-cache \
    ffmpeg \
    python3 \
    python3-dev \
    py3-pip \
    chromium \
    chromium-chromedriver \
    curl \
    wget \
    git \
    bash \
    && rm -rf /var/cache/apk/*

# Install yt-dlp
RUN pip3 install --break-system-packages yt-dlp

# Install Puppeteer dependencies
RUN npm install -g puppeteer

# Set Chrome path for Puppeteer
ENV PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium-browser
ENV CHROME_BIN=/usr/bin/chromium-browser
ENV CHROME_PATH=/usr/bin/chromium-browser

# Create directories
RUN mkdir -p /home/node/.n8n/nodes
RUN mkdir -p /data/youtube_content_anylystic

# Set permissions
RUN chown -R node:node /home/node/.n8n
RUN chown -R node:node /data

USER node

# Set working directory
WORKDIR /home/node

# Expose port
EXPOSE 5678

# Start N8N
CMD ["n8n", "start"]
EOF

    log_success "N8N Dockerfile ƒë√£ ƒë∆∞·ª£c t·∫°o!"
}

# =============================================================================
# üê≥ H√ÄM T·∫†O DOCKER COMPOSE
# =============================================================================

create_docker_compose() {
    log_header "‚öôÔ∏è T·∫†O DOCKER COMPOSE"
    
    DOCKER_COMPOSE_CONTENT="version: '3.8'

services:
  n8n:
    build: .
    image: n8n-custom-ffmpeg:latest
    container_name: n8n-n8n-1
    restart: unless-stopped
    ports:
      - \"127.0.0.1:5678:5678\"
    environment:
      - N8N_HOST=\${N8N_HOST:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=https
      - NODE_ENV=production
      - WEBHOOK_URL=https://$DOMAIN/
      - GENERIC_TIMEZONE=Asia/Ho_Chi_Minh
      - N8N_METRICS=true
      - N8N_DIAGNOSTICS_ENABLED=false
      - N8N_VERSION_NOTIFICATIONS_ENABLED=false
      - N8N_TEMPLATES_ENABLED=true
      - N8N_ONBOARDING_FLOW_DISABLED=false
      - N8N_DIAGNOSTICS_CONFIG_ENABLED=false
      - EXECUTIONS_TIMEOUT=3600
      - EXECUTIONS_TIMEOUT_MAX=7200
      - N8N_EXECUTIONS_DATA_MAX_SIZE=500MB
      - N8N_LOG_LEVEL=info
      - N8N_LOG_OUTPUT=console,file
      - N8N_LOG_FILE_COUNT_MAX=100
      - N8N_LOG_FILE_SIZE_MAX=16m
      - N8N_USER_MANAGEMENT_DISABLED=false
      - N8N_PUBLIC_API_DISABLED=false
      - N8N_DISABLE_UI=false
      - N8N_ENCRYPTION_KEY=\${N8N_ENCRYPTION_KEY:-}
    volumes:
      - ./files:/data
      - ./database.sqlite:/home/node/.n8n/database.sqlite
      - ./encryptionKey:/home/node/.n8n/config/encryptionKey
    networks:
      - default
    depends_on:
      - caddy

  caddy:
    image: caddy:latest
    container_name: n8n-caddy-1
    restart: unless-stopped
    ports:
      - \"80:80\"
      - \"443:443\"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - default"

    if [[ "$ENABLE_NEWS_API" == "y" ]]; then
        DOCKER_COMPOSE_CONTENT="$DOCKER_COMPOSE_CONTENT

  fastapi:
    build: ./news_api
    image: news-api:latest
    container_name: n8n-fastapi-1
    restart: unless-stopped
    ports:
      - \"127.0.0.1:8000:8000\"
    environment:
      - NEWS_API_TOKEN=$NEWS_API_TOKEN
      - DOMAIN=$DOMAIN
    volumes:
      - ./news_api_token.txt:/app/news_api_token.txt:ro
    networks:
      - default"
    fi

    DOCKER_COMPOSE_CONTENT="$DOCKER_COMPOSE_CONTENT

volumes:
  caddy_data:
  caddy_config:

networks:
  default:
    driver: bridge"

    echo "$DOCKER_COMPOSE_CONTENT" > "$INSTALL_DIR/docker-compose.yml"
    
    log_success "Docker Compose ƒë√£ ƒë∆∞·ª£c t·∫°o!"
}

# =============================================================================
# üîí H√ÄM T·∫†O CADDYFILE
# =============================================================================

create_caddyfile() {
    log_header "üîí T·∫†O CADDYFILE"
    
    CADDYFILE_CONTENT="{
    email admin@$DOMAIN
    acme_ca https://acme-v02.api.letsencrypt.org/directory
}

$DOMAIN {
    reverse_proxy n8n:5678
    
    header {
        Strict-Transport-Security \"max-age=31536000; includeSubDomains\"
        X-Content-Type-Options \"nosniff\"
        X-Frame-Options \"DENY\"
        X-XSS-Protection \"1; mode=block\"
    }
    
    encode gzip
    
    log {
        output file /var/log/caddy/n8n.log
        format json
    }
}"

    if [[ "$ENABLE_NEWS_API" == "y" ]]; then
        CADDYFILE_CONTENT="$CADDYFILE_CONTENT

$API_DOMAIN {
    reverse_proxy fastapi:8000
    
    header {
        Strict-Transport-Security \"max-age=31536000; includeSubDomains\"
        X-Content-Type-Options \"nosniff\"
        X-Frame-Options \"DENY\"
        X-XSS-Protection \"1; mode=block\"
        Access-Control-Allow-Origin \"*\"
        Access-Control-Allow-Methods \"GET, POST, PUT, DELETE, OPTIONS\"
        Access-Control-Allow-Headers \"Content-Type, Authorization\"
    }
    
    encode gzip
    
    log {
        output file /var/log/caddy/api.log
        format json
    }
}"
    fi

    echo "$CADDYFILE_CONTENT" > "$INSTALL_DIR/Caddyfile"
    
    log_success "Caddyfile ƒë√£ ƒë∆∞·ª£c t·∫°o!"
}

# =============================================================================
# üíæ H√ÄM T·∫†O BACKUP SCRIPTS
# =============================================================================

create_backup_scripts() {
    log_header "üì¶ T·∫†O BACKUP SCRIPTS"
    
    # Script backup ch√≠nh
    cat > "$INSTALL_DIR/backup-workflows.sh" << 'EOF'
#!/bin/bash

# Backup N8N workflows and data
BACKUP_DIR="/home/n8n/files/backup_full"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="n8n_backup_${TIMESTAMP}.tar.gz"
LOG_FILE="$BACKUP_DIR/backup.log"

# T·∫°o th∆∞ m·ª•c backup n·∫øu ch∆∞a c√≥
mkdir -p "$BACKUP_DIR"

# Function ƒë·ªÉ ghi log
log_backup() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

log_backup "üîÑ B·∫Øt ƒë·∫ßu backup N8N..."

# T·∫°o th∆∞ m·ª•c t·∫°m
TEMP_DIR="/tmp/n8n_backup_$TIMESTAMP"
mkdir -p "$TEMP_DIR"

# Export workflows t·ª´ N8N (n·∫øu c√≥)
if [ -f "/home/n8n/database.sqlite" ]; then
    log_backup "üìã Backup database v√† workflows..."
    mkdir -p "$TEMP_DIR/workflows"
    mkdir -p "$TEMP_DIR/credentials"
    
    # Copy database
    cp "/home/n8n/database.sqlite" "$TEMP_DIR/credentials/" 2>/dev/null || true
    
    # Copy encryption key
    cp "/home/n8n/encryptionKey" "$TEMP_DIR/credentials/" 2>/dev/null || true
    
    # Copy config files
    if [ -d "/home/n8n/files" ]; then
        mkdir -p "$TEMP_DIR/config"
        cp -r "/home/n8n/files" "$TEMP_DIR/config/" 2>/dev/null || true
    fi
fi

# T·∫°o metadata
cat > "$TEMP_DIR/backup_metadata.json" << EOL
{
    "backup_date": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "version": "2.0",
    "domain": "$(cat /home/n8n/docker-compose.yml | grep N8N_HOST | cut -d'=' -f2 || echo 'unknown')",
    "backup_type": "full"
}
EOL

# T·∫°o file tar.gz
cd "$TEMP_DIR"
tar -czf "$BACKUP_DIR/$BACKUP_FILE" . 2>/dev/null

# X√≥a th∆∞ m·ª•c t·∫°m
rm -rf "$TEMP_DIR"

# Ki·ªÉm tra k·∫øt qu·∫£
if [ -f "$BACKUP_DIR/$BACKUP_FILE" ]; then
    BACKUP_SIZE=$(du -h "$BACKUP_DIR/$BACKUP_FILE" | cut -f1)
    log_backup "‚úÖ Backup th√†nh c√¥ng: $BACKUP_FILE ($BACKUP_SIZE)"
    
    # G·ª≠i th√¥ng b√°o Telegram n·∫øu ƒë∆∞·ª£c c·∫•u h√¨nh
    if [ -f "/home/n8n/telegram_config.txt" ]; then
        source "/home/n8n/telegram_config.txt"
        if [ ! -z "$TELEGRAM_BOT_TOKEN" ] && [ ! -z "$TELEGRAM_CHAT_ID" ]; then
            MESSAGE="üîÑ N8N Backup ho√†n th√†nh!%0AüìÅ File: $BACKUP_FILE%0Aüìä Size: $BACKUP_SIZE%0A‚è∞ Time: $(date '+%Y-%m-%d %H:%M:%S')"
            
            # G·ª≠i tin nh·∫Øn
            curl -s -X POST "https://api.telegram.org/bot$TELEGRAM_BOT_TOKEN/sendMessage" \
                -d chat_id="$TELEGRAM_CHAT_ID" \
                -d text="$MESSAGE" \
                -d parse_mode="HTML" >/dev/null 2>&1
            
            # G·ª≠i file n·∫øu nh·ªè h∆°n 20MB
            FILE_SIZE_MB=$(du -m "$BACKUP_DIR/$BACKUP_FILE" | cut -f1)
            if [ "$FILE_SIZE_MB" -lt 20 ]; then
                curl -s -X POST "https://api.telegram.org/bot$TELEGRAM_BOT_TOKEN/sendDocument" \
                    -F chat_id="$TELEGRAM_CHAT_ID" \
                    -F document="@$BACKUP_DIR/$BACKUP_FILE" \
                    -F caption="üì¶ N8N Backup File - $BACKUP_FILE" >/dev/null 2>&1
                log_backup "üì± ƒê√£ g·ª≠i backup file qua Telegram"
            else
                log_backup "üì± File qu√° l·ªõn ƒë·ªÉ g·ª≠i qua Telegram (>20MB)"
            fi
        fi
    fi
else
    log_backup "‚ùå Backup th·∫•t b·∫°i!"
    exit 1
fi

# X√≥a backup c≈© (gi·ªØ l·∫°i 30 b·∫£n g·∫ßn nh·∫•t)
cd "$BACKUP_DIR"
ls -t n8n_backup_*.tar.gz 2>/dev/null | tail -n +31 | xargs rm -f 2>/dev/null || true

log_backup "üßπ ƒê√£ d·ªçn d·∫πp backup c≈© (gi·ªØ l·∫°i 30 b·∫£n g·∫ßn nh·∫•t)"
log_backup "‚úÖ Backup ho√†n th√†nh!"
EOF

    # Script backup manual test
    cat > "$INSTALL_DIR/backup-manual.sh" << 'EOF'
#!/bin/bash

echo "üß™ CH·∫†Y BACKUP TEST MANUAL"
echo "=========================="

# Ch·∫°y backup script
/home/n8n/backup-workflows.sh

echo ""
echo "üìÅ DANH S√ÅCH BACKUP FILES:"
ls -lah /home/n8n/files/backup_full/*.tar.gz 2>/dev/null || echo "Kh√¥ng c√≥ backup files"

echo ""
echo "üìã LOG BACKUP G·∫¶N NH·∫§T:"
tail -10 /home/n8n/files/backup_full/backup.log 2>/dev/null || echo "Kh√¥ng c√≥ log file"
EOF

    # Script update t·ª± ƒë·ªông
    cat > "$INSTALL_DIR/update-n8n.sh" << 'EOF'
#!/bin/bash

LOG_FILE="/home/n8n/logs/update.log"
mkdir -p "/home/n8n/logs"

log_update() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

log_update "üîÑ B·∫Øt ƒë·∫ßu c·∫≠p nh·∫≠t N8N..."

cd /home/n8n

# X√°c ƒë·ªãnh Docker Compose command
if command -v docker-compose &> /dev/null; then
    DOCKER_COMPOSE="docker-compose"
elif docker compose version &> /dev/null; then
    DOCKER_COMPOSE="docker compose"
else
    log_update "‚ùå Docker Compose kh√¥ng t√¨m th·∫•y!"
    exit 1
fi

# Pull images m·ªõi
log_update "üì• ƒêang pull Docker images m·ªõi..."
$DOCKER_COMPOSE pull

# Restart containers
log_update "üîÑ ƒêang restart containers..."
$DOCKER_COMPOSE up -d

# C·∫≠p nh·∫≠t yt-dlp trong container
log_update "üì∫ ƒêang c·∫≠p nh·∫≠t yt-dlp..."
docker exec n8n-n8n-1 pip3 install --break-system-packages -U yt-dlp 2>/dev/null || true

log_update "‚úÖ C·∫≠p nh·∫≠t ho√†n th√†nh!"
EOF

    # Script troubleshoot
    cat > "$INSTALL_DIR/troubleshoot.sh" << 'EOF'
#!/bin/bash

echo "üîç N8N SYSTEM DIAGNOSTICS"
echo "========================="

# X√°c ƒë·ªãnh Docker Compose command
if command -v docker-compose &> /dev/null; then
    DOCKER_COMPOSE="docker-compose"
elif docker compose version &> /dev/null; then
    DOCKER_COMPOSE="docker compose"
else
    echo "‚ùå Docker Compose kh√¥ng t√¨m th·∫•y!"
    exit 1
fi

echo "üìç 1. Container Status:"
cd /home/n8n && $DOCKER_COMPOSE ps

echo ""
echo "üìç 2. Docker System Info:"
docker system df

echo ""
echo "üìç 3. Disk Usage:"
df -h

echo ""
echo "üìç 4. Memory Usage:"
free -h

echo ""
echo "üìç 5. N8N Logs (10 d√≤ng cu·ªëi):"
$DOCKER_COMPOSE logs --tail=10 n8n

echo ""
echo "üìç 6. Caddy Logs (10 d√≤ng cu·ªëi):"
$DOCKER_COMPOSE logs --tail=10 caddy

if [ -f "docker-compose.yml" ] && grep -q "fastapi" docker-compose.yml; then
    echo ""
    echo "üìç 7. News API Logs (10 d√≤ng cu·ªëi):"
    $DOCKER_COMPOSE logs --tail=10 fastapi
fi

echo ""
echo "üìç 8. SSL Certificate Check:"
echo "Domain: $(grep -o '[a-zA-Z0-9.-]*\.[a-zA-Z]{2,}' Caddyfile | head -1)"
openssl s_client -connect $(grep -o '[a-zA-Z0-9.-]*\.[a-zA-Z]{2,}' Caddyfile | head -1):443 -servername $(grep -o '[a-zA-Z0-9.-]*\.[a-zA-Z]{2,}' Caddyfile | head -1) 2>/dev/null | openssl x509 -noout -dates 2>/dev/null || echo "SSL ch∆∞a s·∫µn s√†ng"

echo ""
echo "üìç 9. Recent Backup Files:"
ls -lah files/backup_full/*.tar.gz 2>/dev/null | tail -5 || echo "Kh√¥ng c√≥ backup files"

echo ""
echo "üîß QUICK FIX COMMANDS:"
echo "======================"
echo "Restart all: cd /home/n8n && $DOCKER_COMPOSE restart"
echo "Rebuild all: cd /home/n8n && $DOCKER_COMPOSE down && $DOCKER_COMPOSE up -d --build"
echo "View logs: cd /home/n8n && $DOCKER_COMPOSE logs -f"
echo "Manual backup: /home/n8n/backup-manual.sh"
EOF

    # Set permissions
    chmod +x "$INSTALL_DIR"/*.sh
    
    log_success "Backup scripts ƒë√£ ƒë∆∞·ª£c t·∫°o!"
}

# =============================================================================
# üîß H√ÄM THI·∫æT L·∫¨P CRON JOBS
# =============================================================================

setup_cron_jobs() {
    if [[ "$AUTO_UPDATE" == "y" ]]; then
        # Th√™m cron job cho auto update (m·ªói 12 gi·ªù)
        (crontab -l 2>/dev/null; echo "0 */12 * * * /home/n8n/update-n8n.sh >/dev/null 2>&1") | crontab -
    fi
    
    # Th√™m cron job cho backup h√†ng ng√†y
    (crontab -l 2>/dev/null; echo "0 2 * * * /home/n8n/backup-workflows.sh >/dev/null 2>&1") | crontab -
}

# =============================================================================
# üì± H√ÄM THI·∫æT L·∫¨P TELEGRAM
# =============================================================================

setup_telegram() {
    if [[ "$ENABLE_TELEGRAM" != "y" ]]; then
        return
    fi
    
    # T·∫°o file config Telegram
    cat > "$INSTALL_DIR/telegram_config.txt" << EOF
TELEGRAM_BOT_TOKEN="$TELEGRAM_BOT_TOKEN"
TELEGRAM_CHAT_ID="$TELEGRAM_CHAT_ID"
EOF
    
    chmod 600 "$INSTALL_DIR/telegram_config.txt"
    
    # Test Telegram connection
    log_info "ƒêang test k·∫øt n·ªëi Telegram..."
    
    TEST_MESSAGE="üöÄ N8N Installation Complete!%0AüìÖ $(date '+%Y-%m-%d %H:%M:%S')%0Aüåê Domain: $DOMAIN"
    
    RESPONSE=$(curl -s -X POST "https://api.telegram.org/bot$TELEGRAM_BOT_TOKEN/sendMessage" \
        -d chat_id="$TELEGRAM_CHAT_ID" \
        -d text="$TEST_MESSAGE" \
        -d parse_mode="HTML")
    
    if echo "$RESPONSE" | grep -q '"ok":true'; then
        log_success "Telegram ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh th√†nh c√¥ng!"
    else
        log_warning "Kh√¥ng th·ªÉ g·ª≠i tin nh·∫Øn test Telegram. Vui l√≤ng ki·ªÉm tra Bot Token v√† Chat ID."
    fi
}

# =============================================================================
# üöÄ H√ÄM BUILD V√Ä KH·ªûI ƒê·ªòNG
# =============================================================================

build_and_start() {
    log_header "üöÄ BUILD V√Ä KH·ªûI ƒê·ªòNG CONTAINERS"
    
    cd "$INSTALL_DIR"
    
    # X√°c ƒë·ªãnh Docker Compose command
    DOCKER_COMPOSE_CMD=$(get_docker_compose_cmd)
    
    log_info "ƒêang build Docker images..."
    $DOCKER_COMPOSE_CMD build --no-cache
    
    log_info "ƒêang kh·ªüi ƒë·ªông c√°c container..."
    $DOCKER_COMPOSE_CMD up -d
    
    log_info "ƒê·ª£i containers kh·ªüi ƒë·ªông v√† SSL ƒë∆∞·ª£c c·∫•p (60 gi√¢y)..."
    sleep 60
    
    # Ki·ªÉm tra tr·∫°ng th√°i containers
    log_info "Ki·ªÉm tra tr·∫°ng th√°i c√°c container..."
    
    if docker ps | grep -q "n8n-n8n-1"; then
        log_success "Container n8n ƒë√£ ch·∫°y th√†nh c√¥ng."
    else
        log_error "Container n8n kh√¥ng ch·∫°y ƒë∆∞·ª£c!"
    fi
    
    if docker ps | grep -q "n8n-caddy-1"; then
        log_success "Container caddy ƒë√£ ch·∫°y th√†nh c√¥ng."
    else
        log_error "Container caddy kh√¥ng ch·∫°y ƒë∆∞·ª£c!"
    fi
    
    if [[ "$ENABLE_NEWS_API" == "y" ]] && docker ps | grep -q "n8n-fastapi-1"; then
        log_success "Container fastapi ƒë√£ ch·∫°y th√†nh c√¥ng."
    fi
}

# =============================================================================
# üîí H√ÄM KI·ªÇM TRA SSL V√Ä X·ª¨ L√ù RATE LIMIT
# =============================================================================

check_ssl_and_rate_limit() {
    log_header "üîí KI·ªÇM TRA SSL CERTIFICATE"
    
    cd "$INSTALL_DIR"
    DOCKER_COMPOSE_CMD=$(get_docker_compose_cmd)
    
    # Ki·ªÉm tra Caddy logs ƒë·ªÉ t√¨m rate limit
    CADDY_LOGS=$($DOCKER_COMPOSE_CMD logs caddy 2>/dev/null | tail -20)
    
    if echo "$CADDY_LOGS" | grep -q "rateLimited\|rate.*limit\|too many certificates"; then
        log_error "üö® PH√ÅT HI·ªÜN SSL RATE LIMIT!"
        log_error "Let's Encrypt ƒë√£ gi·ªõi h·∫°n s·ªë l∆∞·ª£ng certificate cho domain n√†y."
        echo ""
        log_warning "üìã C√ÅC GI·∫¢I PH√ÅP:"
        echo ""
        log_message "1Ô∏è‚É£ üîÑ S·ª¨ D·ª§NG STAGING SSL (Khuy·∫øn ngh·ªã)"
        log_message "   - Website s·∫Ω ho·∫°t ƒë·ªông ngay nh∆∞ng browser hi·ªÉn th·ªã 'Not Secure'"
        log_message "   - Ch·ª©c nƒÉng N8N v√† API ho·∫°t ƒë·ªông ƒë·∫ßy ƒë·ªß"
        log_message "   - C√≥ th·ªÉ chuy·ªÉn v·ªÅ production SSL sau 7 ng√†y"
        echo ""
        log_message "2Ô∏è‚É£ ‚è∞ ƒê·ª¢I 7 NG√ÄY"
        log_message "   - ƒê·ª£i ƒë·∫øn sau ng√†y $(date -d '+7 days' '+%d/%m/%Y')"
        log_message "   - Rate limit s·∫Ω ƒë∆∞·ª£c reset"
        echo ""
        log_message "3Ô∏è‚É£ üîÑ C√ÄI L·∫†I UBUNTU VPS"
        log_message "   - Backup d·ªØ li·ªáu quan tr·ªçng tr∆∞·ªõc"
        log_message "   - C√†i l·∫°i Ubuntu v√† ch·∫°y script n√†y"
        log_message "   - S·ª≠ d·ª•ng IP m·ªõi s·∫Ω kh√¥ng b·ªã rate limit"
        echo ""
        
        read -p "$(echo -e "${CYAN}B·∫°n c√≥ mu·ªën s·ª≠ d·ª•ng Staging SSL ƒë·ªÉ ti·∫øp t·ª•c? (Y/n): ${NC}")" -r
        if [[ ! $REPLY =~ ^[Nn]$ ]]; then
            setup_staging_ssl
        else
            log_warning "Vui l√≤ng ch·ªçn m·ªôt trong c√°c gi·∫£i ph√°p tr√™n v√† ch·∫°y l·∫°i script."
            exit 1
        fi
    else
        # Ki·ªÉm tra SSL certificate b√¨nh th∆∞·ªùng
        log_info "ƒêang ki·ªÉm tra SSL certificate..."
        
        sleep 30  # ƒê·ª£i th√™m ƒë·ªÉ SSL c√≥ th·ªÉ ƒë∆∞·ª£c c·∫•p
        
        if openssl s_client -connect "$DOMAIN:443" -servername "$DOMAIN" 2>/dev/null | grep -q "Verify return code: 0"; then
            log_success "SSL certificate cho $DOMAIN ƒë√£ ƒë∆∞·ª£c c·∫•p th√†nh c√¥ng!"
        else
            log_warning "SSL cho $DOMAIN c√≥ th·ªÉ ch∆∞a s·∫µn s√†ng. ƒê·ª£i th√™m v√†i ph√∫t."
        fi
        
        if [[ "$ENABLE_NEWS_API" == "y" ]]; then
            if openssl s_client -connect "$API_DOMAIN:443" -servername "$API_DOMAIN" 2>/dev/null | grep -q "Verify return code: 0"; then
                log_success "SSL certificate cho $API_DOMAIN ƒë√£ ƒë∆∞·ª£c c·∫•p th√†nh c√¥ng!"
            else
                log_warning "SSL cho $API_DOMAIN c√≥ th·ªÉ ch∆∞a s·∫µn s√†ng. ƒê·ª£i th√™m v√†i ph√∫t."
            fi
        fi
    fi
}

# =============================================================================
# üîß H√ÄM THI·∫æT L·∫¨P STAGING SSL
# =============================================================================

setup_staging_ssl() {
    log_header "üîß THI·∫æT L·∫¨P STAGING SSL"
    
    cd "$INSTALL_DIR"
    DOCKER_COMPOSE_CMD=$(get_docker_compose_cmd)
    
    log_info "ƒêang d·ª´ng containers..."
    $DOCKER_COMPOSE_CMD down
    
    log_info "ƒêang x√≥a SSL data c≈©..."
    docker volume rm n8n_caddy_data n8n_caddy_config 2>/dev/null || true
    
    log_info "ƒêang t·∫°o Caddyfile v·ªõi Let's Encrypt STAGING..."
    
    # T·∫°o Caddyfile v·ªõi staging environment
    STAGING_CADDYFILE="{
    email admin@$DOMAIN
    acme_ca https://acme-staging-v02.api.letsencrypt.org/directory
    debug
}

$DOMAIN {
    reverse_proxy n8n:5678
    
    header {
        Strict-Transport-Security \"max-age=31536000; includeSubDomains\"
        X-Content-Type-Options \"nosniff\"
        X-Frame-Options \"DENY\"
        X-XSS-Protection \"1; mode=block\"
    }
    
    encode gzip
    
    log {
        output file /var/log/caddy/n8n.log
        format json
    }
}"

    if [[ "$ENABLE_NEWS_API" == "y" ]]; then
        STAGING_CADDYFILE="$STAGING_CADDYFILE

$API_DOMAIN {
    reverse_proxy fastapi:8000
    
    header {
        Strict-Transport-Security \"max-age=31536000; includeSubDomains\"
        X-Content-Type-Options \"nosniff\"
        X-Frame-Options \"DENY\"
        X-XSS-Protection \"1; mode=block\"
        Access-Control-Allow-Origin \"*\"
        Access-Control-Allow-Methods \"GET, POST, PUT, DELETE, OPTIONS\"
        Access-Control-Allow-Headers \"Content-Type, Authorization\"
    }
    
    encode gzip
    
    log {
        output file /var/log/caddy/api.log
        format json
    }
}"
    fi

    echo "$STAGING_CADDYFILE" > "$INSTALL_DIR/Caddyfile"
    
    log_info "ƒêang kh·ªüi ƒë·ªông containers v·ªõi staging SSL..."
    $DOCKER_COMPOSE_CMD up -d
    
    log_info "ƒê·ª£i staging SSL ƒë∆∞·ª£c c·∫•p (30 gi√¢y)..."
    sleep 30
    
    log_success "üéØ STAGING SSL ƒê√É ƒê∆Ø·ª¢C THI·∫æT L·∫¨P!"
    log_warning "‚ö†Ô∏è Website s·∫Ω hi·ªÉn th·ªã c·∫£nh b√°o 'Not Secure' - ƒë√¢y l√† b√¨nh th∆∞·ªùng v·ªõi staging certificate"
    log_success "‚úÖ T·∫•t c·∫£ ch·ª©c nƒÉng N8N v√† API ho·∫°t ƒë·ªông ƒë·∫ßy ƒë·ªß"
    
    # T·∫°o script chuy·ªÉn v·ªÅ production SSL
    cat > "$INSTALL_DIR/switch-to-production-ssl.sh" << EOF
#!/bin/bash

echo "üîÑ CHUY·ªÇN V·ªÄ PRODUCTION SSL"
echo "=========================="

cd /home/n8n

# X√°c ƒë·ªãnh Docker Compose command
if command -v docker-compose &> /dev/null; then
    DOCKER_COMPOSE="docker-compose"
elif docker compose version &> /dev/null; then
    DOCKER_COMPOSE="docker compose"
else
    echo "‚ùå Docker Compose kh√¥ng t√¨m th·∫•y!"
    exit 1
fi

echo "‚èπÔ∏è ƒêang d·ª´ng containers..."
\$DOCKER_COMPOSE down

echo "üóëÔ∏è ƒêang x√≥a staging SSL data..."
docker volume rm n8n_caddy_data n8n_caddy_config 2>/dev/null || true

echo "üìù ƒêang t·∫°o production Caddyfile..."
cat > /home/n8n/Caddyfile << 'PROD_EOF'
{
    email admin@$DOMAIN
    acme_ca https://acme-v02.api.letsencrypt.org/directory
}

$DOMAIN {
    reverse_proxy n8n:5678
    
    header {
        Strict-Transport-Security "max-age=31536000; includeSubDomains"
        X-Content-Type-Options "nosniff"
        X-Frame-Options "DENY"
        X-XSS-Protection "1; mode=block"
    }
    
    encode gzip
    
    log {
        output file /var/log/caddy/n8n.log
        format json
    }
}
PROD_EOF

if [[ "$ENABLE_NEWS_API" == "y" ]]; then
cat >> /home/n8n/Caddyfile << 'PROD_EOF'

$API_DOMAIN {
    reverse_proxy fastapi:8000
    
    header {
        Strict-Transport-Security "max-age=31536000; includeSubDomains"
        X-Content-Type-Options "nosniff"
        X-Frame-Options "DENY"
        X-XSS-Protection "1; mode=block"
        Access-Control-Allow-Origin "*"
        Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS"
        Access-Control-Allow-Headers "Content-Type, Authorization"
    }
    
    encode gzip
    
    log {
        output file /var/log/caddy/api.log
        format json
    }
}
PROD_EOF
fi

echo "üöÄ ƒêang kh·ªüi ƒë·ªông v·ªõi production SSL..."
\$DOCKER_COMPOSE up -d

echo "‚úÖ ƒê√£ chuy·ªÉn v·ªÅ production SSL!"
echo "üåê Truy c·∫≠p: https://$DOMAIN"
EOF

    chmod +x "$INSTALL_DIR/switch-to-production-ssl.sh"
    
    log_info "üìù Script chuy·ªÉn v·ªÅ production SSL ƒë√£ ƒë∆∞·ª£c t·∫°o t·∫°i:"
    log_info "   /home/n8n/switch-to-production-ssl.sh"
    log_info "üïê Ch·∫°y script n√†y sau ng√†y $(date -d '+7 days' '+%d/%m/%Y') ƒë·ªÉ c√≥ production SSL"
}

# =============================================================================
# üìä H√ÄM HI·ªÇN TH·ªä K·∫æT QU·∫¢
# =============================================================================

show_final_result() {
    log_header "üéâ N8N ƒê√É ƒê∆Ø·ª¢C C√ÄI ƒê·∫∂T TH√ÄNH C√îNG!"
    
    # Th√¥ng tin truy c·∫≠p
    log_message "üåê Truy c·∫≠p N8N: https://$DOMAIN"
    
    if [[ "$ENABLE_NEWS_API" == "y" ]]; then
        log_message "üì∞ Truy c·∫≠p News API: https://$API_DOMAIN"
        log_message "üìö API Documentation: https://$API_DOMAIN/docs"
        log_message "üîë Bearer Token: $NEWS_API_TOKEN"
    fi
    
    echo ""
    
    # Th√¥ng tin h·ªá th·ªëng
    CURRENT_SWAP=$(free -h | awk '/^Swap:/ {print $2}')
    log_message "üìÅ Th∆∞ m·ª•c c√†i ƒë·∫∑t: $INSTALL_DIR"
    log_message "üîß Script ch·∫©n ƒëo√°n: $INSTALL_DIR/troubleshoot.sh"
    log_message "üß™ Test backup: $INSTALL_DIR/backup-manual.sh"
    log_message "üíæ Swap: $CURRENT_SWAP"
    
    if [[ "$AUTO_UPDATE" == "y" ]]; then
        log_message "üîÑ Auto-update: Enabled (m·ªói 12h)"
    else
        log_message "üîÑ Auto-update: Disabled"
    fi
    
    if [[ "$ENABLE_TELEGRAM" == "y" ]]; then
        log_message "üì± Telegram backup: Enabled"
    else
        log_message "üì± Telegram backup: Disabled"
    fi
    
    log_message "üíæ Backup t·ª± ƒë·ªông: H√†ng ng√†y l√∫c 2:00 AM"
    log_message "üìÇ Backup location: $INSTALL_DIR/files/backup_full/"
    
    echo ""
    
    # Th√¥ng tin t√°c gi·∫£
    log_message "üöÄ T√°c gi·∫£: Nguy·ªÖn Ng·ªçc Thi·ªán"
    log_message "üì∫ YouTube: https://www.youtube.com/@kalvinthiensocial?sub_confirmation=1"
    log_message "üì± Zalo: 08.8888.4749"
}

# =============================================================================
# üöÄ H√ÄM MAIN
# =============================================================================

main() {
    # Hi·ªÉn th·ªã header
    log_header "üöÄ SCRIPT C√ÄI ƒê·∫∂T N8N T·ª∞ ƒê·ªòNG V·ªöI FFMPEG, YT-DLP, PUPPETEER V√Ä NEWS API"
    log_message "T√°c gi·∫£: Nguy·ªÖn Ng·ªçc Thi·ªán"
    log_message "YouTube: https://www.youtube.com/@kalvinthiensocial?sub_confirmation=1"
    log_message "C·∫≠p nh·∫≠t: 28/06/2025"
    echo ""
    
    # Ki·ªÉm tra ƒëi·ªÅu ki·ªán
    check_root
    detect_os
    check_internet
    
    # Nh·∫≠p th√¥ng tin
    input_domain
    ask_clean_install
    ask_news_api
    ask_telegram_backup
    ask_auto_update
    
    # Ki·ªÉm tra DNS
    check_dns
    
    # Thi·∫øt l·∫≠p h·ªá th·ªëng
    setup_swap
    install_docker
    clean_old_installation
    
    # T·∫°o c·∫•u tr√∫c
    create_directory_structure
    create_news_api
    create_n8n_dockerfile
    create_docker_compose
    create_caddyfile
    create_backup_scripts
    
    # Thi·∫øt l·∫≠p services
    setup_cron_jobs
    setup_telegram
    
    # Build v√† kh·ªüi ƒë·ªông
    build_and_start
    
    # Ki·ªÉm tra SSL v√† x·ª≠ l√Ω rate limit
    check_ssl_and_rate_limit
    
    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    show_final_result
}

# =============================================================================
# üéØ CH·∫†Y SCRIPT
# =============================================================================

# X·ª≠ l√Ω tham s·ªë d√≤ng l·ªánh
while [[ $# -gt 0 ]]; do
    case $1 in
        --clean)
            CLEAN_INSTALL="y"
            shift
            ;;
        -d|--directory)
            INSTALL_DIR="$2"
            shift 2
            ;;
        -h|--help)
            echo "S·ª≠ d·ª•ng: $0 [OPTIONS]"
            echo "OPTIONS:"
            echo "  --clean           X√≥a c√†i ƒë·∫∑t c≈©"
            echo "  -d, --directory   Th∆∞ m·ª•c c√†i ƒë·∫∑t (m·∫∑c ƒë·ªãnh: /home/n8n)"
            echo "  -h, --help        Hi·ªÉn th·ªã tr·ª£ gi√∫p"
            exit 0
            ;;
        *)
            log_error "Tham s·ªë kh√¥ng h·ª£p l·ªá: $1"
            exit 1
            ;;
    esac
done

# Ch·∫°y main function
main "$@"
