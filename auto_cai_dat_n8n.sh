#!/bin/bash

# =============================================================================
# üöÄ SCRIPT C√ÄI ƒê·∫∂T N8N T·ª∞ ƒê·ªòNG V·ªöI FFMPEG, YT-DLP, PUPPETEER V√Ä NEWS API
# =============================================================================
# 
# T√°c gi·∫£: Nguy·ªÖn Ng·ªçc Thi·ªán
# YouTube: https://www.youtube.com/@kalvinthiensocial
# Facebook: https://www.facebook.com/Ban.Thien.Handsome/
# Zalo/Phone: 08.8888.4749
# C·∫≠p nh·∫≠t: 28/06/2025
#
# T√≠nh nƒÉng:
# - N8N v·ªõi FFmpeg, yt-dlp, Puppeteer
# - News Content API (FastAPI + Newspaper4k)
# - SSL t·ª± ƒë·ªông v·ªõi Caddy
# - Telegram Backup System
# - Smart Backup & Auto-Update
# - Rate Limit Detection & Handling
# =============================================================================

set -e

# =============================================================================
# üé® THI·∫æT L·∫¨P M√ÄU S·∫ÆC V√Ä LOGGING
# =============================================================================

# M√†u s·∫Øc d·ªÖ ƒë·ªçc tr√™n terminal ƒëen
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'    # Thay ƒë·ªïi t·ª´ xanh d∆∞∆°ng sang cyan
PURPLE='\033[0;35m'
WHITE='\033[1;37m'
NC='\033[0m'

# Logging functions
log_info() {
    echo -e "${CYAN}‚ÑπÔ∏è $1${NC}"
}

log_success() {
    echo -e "${GREEN}‚úÖ $1${NC}"
}

log_warning() {
    echo -e "${YELLOW}‚ö†Ô∏è $1${NC}"
}

log_error() {
    echo -e "${RED}‚ùå $1${NC}"
}

log_header() {
    echo ""
    echo -e "${WHITE}========================================================================${NC}"
    echo -e "${WHITE}$1${NC}"
    echo -e "${WHITE}========================================================================${NC}"
    echo ""
}

log_message() {
    echo -e "${PURPLE}üìù $1${NC}"
}

# =============================================================================
# üîß BI·∫æN TO√ÄN C·ª§C
# =============================================================================

INSTALL_DIR="/home/n8n"
DOMAIN=""
NEWS_API_ENABLED=false
NEWS_API_TOKEN=""
TELEGRAM_ENABLED=false
TELEGRAM_BOT_TOKEN=""
TELEGRAM_CHAT_ID=""
AUTO_UPDATE_ENABLED=false
CLEANUP_OLD=false

# =============================================================================
# üõ†Ô∏è C√ÅC H√ÄM TI·ªÜN √çCH
# =============================================================================

# Ki·ªÉm tra quy·ªÅn root
check_root() {
    if [[ $EUID -ne 0 ]]; then
        log_error "Script n√†y c·∫ßn ch·∫°y v·ªõi quy·ªÅn root (sudo)"
        exit 1
    fi
}

# Hi·ªÉn th·ªã banner
show_banner() {
    clear
    echo -e "${CYAN}"
    cat << "EOF"
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    üöÄ N8N AUTOMATION INSTALLER 2025 üöÄ                      ‚ïë
‚ïë                                                                              ‚ïë
‚ïë  üì∫ YouTube: https://www.youtube.com/@kalvinthiensocial                     ‚ïë
‚ïë  üìò Facebook: https://www.facebook.com/Ban.Thien.Handsome/                 ‚ïë
‚ïë  üì± Zalo: 08.8888.4749                                                      ‚ïë
‚ïë                                                                              ‚ïë
‚ïë  ‚ú® T√≠nh nƒÉng:                                                              ‚ïë
‚ïë  ü§ñ N8N + FFmpeg + yt-dlp + Puppeteer                                      ‚ïë
‚ïë  üì∞ News Content API (FastAPI + Newspaper4k)                               ‚ïë
‚ïë  üîí SSL t·ª± ƒë·ªông v·ªõi Caddy                                                   ‚ïë
‚ïë  üì± Telegram Backup System                                                  ‚ïë
‚ïë  üíæ Smart Backup & Auto-Update                                             ‚ïë
‚ïë  üö® SSL Rate Limit Detection                                               ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
EOF
    echo -e "${NC}"
}

# X·ª≠ l√Ω tham s·ªë d√≤ng l·ªánh
parse_arguments() {
    while [[ $# -gt 0 ]]; do
        case $1 in
            --clean)
                CLEANUP_OLD=true
                shift
                ;;
            -d|--directory)
                INSTALL_DIR="$2"
                shift 2
                ;;
            -h|--help)
                show_help
                exit 0
                ;;
            *)
                log_error "Tham s·ªë kh√¥ng h·ª£p l·ªá: $1"
                show_help
                exit 1
                ;;
        esac
    done
}

# Hi·ªÉn th·ªã tr·ª£ gi√∫p
show_help() {
    echo "C√°ch s·ª≠ d·ª•ng: $0 [OPTIONS]"
    echo ""
    echo "Options:"
    echo "  --clean              X√≥a c√†i ƒë·∫∑t c≈© tr∆∞·ªõc khi c√†i m·ªõi"
    echo "  -d, --directory DIR  Th∆∞ m·ª•c c√†i ƒë·∫∑t (m·∫∑c ƒë·ªãnh: /home/n8n)"
    echo "  -h, --help           Hi·ªÉn th·ªã tr·ª£ gi√∫p n√†y"
    echo ""
    echo "V√≠ d·ª•:"
    echo "  $0 --clean"
    echo "  $0 -d /custom/path"
}

# Ki·ªÉm tra h·ªá ƒëi·ªÅu h√†nh
check_os() {
    if [[ ! -f /etc/os-release ]]; then
        log_error "Kh√¥ng th·ªÉ x√°c ƒë·ªãnh h·ªá ƒëi·ªÅu h√†nh"
        exit 1
    fi
    
    . /etc/os-release
    if [[ "$ID" != "ubuntu" ]]; then
        log_warning "Script ƒë∆∞·ª£c thi·∫øt k·∫ø cho Ubuntu. H·ªá ƒëi·ªÅu h√†nh hi·ªán t·∫°i: $ID"
        read -p "B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c? (y/N): " -r
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            exit 1
        fi
    fi
}

# Ki·ªÉm tra k·∫øt n·ªëi internet
check_internet() {
    log_info "Ki·ªÉm tra k·∫øt n·ªëi internet..."
    if ! ping -c 1 google.com &> /dev/null; then
        log_error "Kh√¥ng c√≥ k·∫øt n·ªëi internet"
        exit 1
    fi
    log_success "K·∫øt n·ªëi internet OK"
}

# =============================================================================
# üìù THU TH·∫¨P TH√îNG TIN T·ª™ NG∆Ø·ªúI D√ôNG
# =============================================================================

collect_user_input() {
    log_header "üìù THU TH·∫¨P TH√îNG TIN C√ÄI ƒê·∫∂T"
    
    # Domain ch√≠nh
    while [[ -z "$DOMAIN" ]]; do
        read -p "üåê Nh·∫≠p domain ch√≠nh cho N8N (v√≠ d·ª•: n8n.example.com): " DOMAIN
        if [[ -z "$DOMAIN" ]]; then
            log_error "Domain kh√¥ng ƒë∆∞·ª£c ƒë·ªÉ tr·ªëng!"
        fi
    done
    
    # Cleanup option
    if [[ "$CLEANUP_OLD" == false ]]; then
        read -p "üóëÔ∏è X√≥a c√†i ƒë·∫∑t c≈© (n·∫øu c√≥)? (Y/n): " -r
        if [[ $REPLY =~ ^[Nn]$ ]]; then
            CLEANUP_OLD=false
        else
            CLEANUP_OLD=true
        fi
    fi
    
    # News API
    read -p "üì∞ B·∫°n c√≥ mu·ªën c√†i ƒë·∫∑t News Content API? (Y/n): " -r
    if [[ ! $REPLY =~ ^[Nn]$ ]]; then
        NEWS_API_ENABLED=true
        
        while [[ ${#NEWS_API_TOKEN} -lt 20 ]]; do
            read -p "üîë ƒê·∫∑t Bearer Token cho API (√≠t nh·∫•t 20 k√Ω t·ª±): " NEWS_API_TOKEN
            if [[ ${#NEWS_API_TOKEN} -lt 20 ]]; then
                log_error "Token ph·∫£i c√≥ √≠t nh·∫•t 20 k√Ω t·ª±!"
            fi
        done
    fi
    
    # Telegram backup
    log_info "üì± THI·∫æT L·∫¨P TELEGRAM BACKUP"
    read -p "B·∫°n c√≥ mu·ªën thi·∫øt l·∫≠p backup qua Telegram? (y/N): " -r
    if [[ $REPLY =~ ^[Yy]$ ]]; then
        TELEGRAM_ENABLED=true
        
        while [[ -z "$TELEGRAM_BOT_TOKEN" ]]; do
            read -p "ü§ñ Nh·∫≠p Telegram Bot Token: " TELEGRAM_BOT_TOKEN
        done
        
        while [[ -z "$TELEGRAM_CHAT_ID" ]]; do
            read -p "üí¨ Nh·∫≠p Telegram Chat ID: " TELEGRAM_CHAT_ID
        done
    fi
    
    # Auto update
    read -p "üîÑ B·∫°n c√≥ mu·ªën b·∫≠t t·ª± ƒë·ªông c·∫≠p nh·∫≠t? (Y/n): " -r
    if [[ ! $REPLY =~ ^[Nn]$ ]]; then
        AUTO_UPDATE_ENABLED=true
    fi
}

# =============================================================================
# üåê KI·ªÇM TRA DNS
# =============================================================================

check_dns() {
    log_header "üåê KI·ªÇM TRA DNS"
    
    log_info "ƒêang ki·ªÉm tra DNS cho $DOMAIN..."
    
    # L·∫•y IP c·ªßa domain
    DOMAIN_IP=$(dig +short "$DOMAIN" A | tail -n1)
    if [[ -z "$DOMAIN_IP" ]]; then
        log_error "Kh√¥ng th·ªÉ resolve domain $DOMAIN"
        log_error "Vui l√≤ng ki·ªÉm tra DNS settings"
        exit 1
    fi
    
    # L·∫•y IP c·ªßa server
    SERVER_IP=$(curl -s https://api.ipify.org)
    if [[ -z "$SERVER_IP" ]]; then
        log_error "Kh√¥ng th·ªÉ l·∫•y IP c·ªßa server"
        exit 1
    fi
    
    log_info "IP c·ªßa domain $DOMAIN: $DOMAIN_IP"
    log_info "IP c·ªßa server: $SERVER_IP"
    
    if [[ "$DOMAIN_IP" == "$SERVER_IP" ]]; then
        log_success "DNS ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng!"
    else
        log_error "DNS ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh ƒë√∫ng!"
        log_error "Domain $DOMAIN tr·ªè v·ªÅ $DOMAIN_IP nh∆∞ng server c√≥ IP $SERVER_IP"
        read -p "B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c? (y/N): " -r
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            exit 1
        fi
    fi
}

# =============================================================================
# üíæ THI·∫æT L·∫¨P SWAP MEMORY
# =============================================================================

setup_swap() {
    log_header "üíæ THI·∫æT L·∫¨P SWAP MEMORY"
    
    # Ki·ªÉm tra swap hi·ªán t·∫°i
    CURRENT_SWAP=$(free -h | awk '/^Swap:/ {print $2}')
    log_info "Swap hi·ªán t·∫°i: $CURRENT_SWAP"
    
    # N·∫øu ƒë√£ c√≥ swap >= 2GB th√¨ b·ªè qua
    if [[ "$CURRENT_SWAP" != "0B" ]]; then
        SWAP_SIZE_MB=$(free -m | awk '/^Swap:/ {print $2}')
        if [[ $SWAP_SIZE_MB -ge 2048 ]]; then
            log_success "Swap ƒë√£ ƒë·ªß l·ªõn ($CURRENT_SWAP)"
            return
        fi
    fi
    
    # T√≠nh to√°n swap size d·ª±a tr√™n RAM
    RAM_MB=$(free -m | awk '/^Mem:/ {print $2}')
    if [[ $RAM_MB -lt 2048 ]]; then
        SWAP_SIZE="2G"
    elif [[ $RAM_MB -lt 4096 ]]; then
        SWAP_SIZE="4G"
    else
        SWAP_SIZE="4G"
    fi
    
    log_info "ƒêang t·∫°o swap file $SWAP_SIZE..."
    
    # T·∫°o swap file
    fallocate -l $SWAP_SIZE /swapfile
    chmod 600 /swapfile
    mkswap /swapfile
    swapon /swapfile
    
    # Th√™m v√†o fstab ƒë·ªÉ persistent
    if ! grep -q "/swapfile" /etc/fstab; then
        echo "/swapfile none swap sw 0 0" >> /etc/fstab
    fi
    
    log_success "Swap $SWAP_SIZE ƒë√£ ƒë∆∞·ª£c thi·∫øt l·∫≠p!"
}

# =============================================================================
# üê≥ C√ÄI ƒê·∫∂T DOCKER
# =============================================================================

install_docker() {
    log_header "‚öôÔ∏è C√ÄI ƒê·∫∂T DOCKER"
    
    # Ki·ªÉm tra Docker ƒë√£ c√†i ch∆∞a
    if command -v docker &> /dev/null; then
        log_info "Docker ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t"
        
        # Ki·ªÉm tra Docker daemon
        if ! docker info &> /dev/null; then
            log_info "ƒêang kh·ªüi ƒë·ªông Docker daemon..."
            systemctl start docker
            systemctl enable docker
        fi
        
        # Ki·ªÉm tra Docker Compose
        if ! command -v docker-compose &> /dev/null && ! docker compose version &> /dev/null; then
            log_info "ƒêang c√†i ƒë·∫∑t Docker Compose..."
            apt update
            apt install -y docker-compose
        fi
        
        return
    fi
    
    log_info "ƒêang c√†i ƒë·∫∑t Docker..."
    
    # C·∫≠p nh·∫≠t package list
    apt update
    
    # C√†i ƒë·∫∑t dependencies
    apt install -y \
        apt-transport-https \
        ca-certificates \
        curl \
        gnupg \
        lsb-release
    
    # Th√™m Docker GPG key
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
    
    # Th√™m Docker repository
    echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
    
    # C√†i ƒë·∫∑t Docker
    apt update
    apt install -y docker-ce docker-ce-cli containerd.io docker-compose
    
    # Kh·ªüi ƒë·ªông Docker
    systemctl start docker
    systemctl enable docker
    
    # Th√™m user v√†o docker group
    usermod -aG docker $SUDO_USER 2>/dev/null || true
    
    log_success "Docker ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t th√†nh c√¥ng!"
}

# =============================================================================
# üóëÔ∏è X√ìA C√ÄI ƒê·∫∂T C≈®
# =============================================================================

cleanup_old_installation() {
    if [[ "$CLEANUP_OLD" == true ]]; then
        log_header "‚ö†Ô∏è X√ìA C√ÄI ƒê·∫∂T C≈®"
        
        log_info "ƒêang d·ª´ng containers c≈©..."
        cd "$INSTALL_DIR" 2>/dev/null || true
        
        # X√°c ƒë·ªãnh Docker Compose command
        if command -v docker-compose &> /dev/null; then
            DOCKER_COMPOSE="docker-compose"
        elif docker compose version &> /dev/null; then
            DOCKER_COMPOSE="docker compose"
        else
            DOCKER_COMPOSE="docker-compose"
        fi
        
        $DOCKER_COMPOSE down 2>/dev/null || true
        
        log_info "ƒêang x√≥a th∆∞ m·ª•c c√†i ƒë·∫∑t c≈©..."
        rm -rf "$INSTALL_DIR"
        
        log_info "ƒêang x√≥a Docker volumes c≈©..."
        docker volume rm n8n_caddy_data n8n_caddy_config 2>/dev/null || true
        
        log_success "ƒê√£ x√≥a c√†i ƒë·∫∑t c≈© th√†nh c√¥ng!"
    fi
}

# =============================================================================
# üìÅ T·∫†O C·∫§U TR√öC TH∆Ø M·ª§C
# =============================================================================

create_directory_structure() {
    log_header "‚öôÔ∏è T·∫†O C·∫§U TR√öC TH∆Ø M·ª§C"
    
    # T·∫°o th∆∞ m·ª•c ch√≠nh
    mkdir -p "$INSTALL_DIR"
    cd "$INSTALL_DIR"
    
    # T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c
    mkdir -p files/{backup_full,temp,youtube_content_anylystic}
    mkdir -p logs
    
    if [[ "$NEWS_API_ENABLED" == true ]]; then
        mkdir -p news_api
    fi
    
    # T·∫°o file token cho News API
    if [[ "$NEWS_API_ENABLED" == true ]]; then
        echo "$NEWS_API_TOKEN" > news_api_token.txt
        chmod 600 news_api_token.txt
    fi
    
    # T·∫°o file config Telegram
    if [[ "$TELEGRAM_ENABLED" == true ]]; then
        cat > telegram_config.txt << EOF
TELEGRAM_BOT_TOKEN=$TELEGRAM_BOT_TOKEN
TELEGRAM_CHAT_ID=$TELEGRAM_CHAT_ID
EOF
        chmod 600 telegram_config.txt
    fi
    
    log_success "C·∫•u tr√∫c th∆∞ m·ª•c ƒë√£ ƒë∆∞·ª£c t·∫°o!"
}

# =============================================================================
# üì∞ T·∫†O NEWS CONTENT API
# =============================================================================

create_news_api() {
    if [[ "$NEWS_API_ENABLED" == false ]]; then
        return
    fi
    
    log_header "üì∞ T·∫†O NEWS CONTENT API"
    
    cd "$INSTALL_DIR/news_api"
    
    # T·∫°o requirements.txt
    cat > requirements.txt << 'EOF'
fastapi==0.104.1
uvicorn[standard]==0.24.0
newspaper4k==0.9.3
pydantic==2.5.0
python-multipart==0.0.6
user-agents==2.2.0
requests==2.31.0
lxml==4.9.3
Pillow==10.1.0
python-dateutil==2.8.2
feedparser==6.0.10
beautifulsoup4==4.12.2
nltk==3.8.1
EOF
    
    # T·∫°o main.py v·ªõi Newspaper4k v√† Random User Agent
    cat > main.py << 'EOF'
import os
import random
import logging
from datetime import datetime
from typing import List, Optional, Dict, Any
import asyncio
from concurrent.futures import ThreadPoolExecutor

from fastapi import FastAPI, HTTPException, Depends, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from pydantic import BaseModel, HttpUrl, Field
import uvicorn
from user_agents import parse
import requests

# Import newspaper4k v·ªõi c√°ch s·ª≠ d·ª•ng ƒë√∫ng
from newspaper import Article, Config
import newspaper
import feedparser
import nltk

# Download NLTK data
try:
    nltk.download('punkt', quiet=True)
    nltk.download('stopwords', quiet=True)
except:
    pass

# Logging setup
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Random User Agents Pool
USER_AGENTS = [
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0",
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36",
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:120.0) Gecko/20100101 Firefox/120.0",
    "Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:121.0) Gecko/20100101 Firefox/121.0"
]

def get_random_headers():
    """Generate random headers with user agent"""
    user_agent = random.choice(USER_AGENTS)
    ua = parse(user_agent)
    
    headers = {
        'User-Agent': user_agent,
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9,vi;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'DNT': '1',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
    }
    
    # Add browser-specific headers
    if 'Chrome' in user_agent:
        headers.update({
            'sec-ch-ua': '"Not_A Brand";v="8", "Chromium";v="120", "Google Chrome";v="120"',
            'sec-ch-ua-mobile': '?0',
            'sec-ch-ua-platform': '"Windows"' if 'Windows' in user_agent else '"macOS"' if 'Mac' in user_agent else '"Linux"',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
        })
    
    return headers

# Load Bearer Token
try:
    with open('/app/news_api_token.txt', 'r') as f:
        BEARER_TOKEN = f.read().strip()
except FileNotFoundError:
    BEARER_TOKEN = os.getenv('NEWS_API_TOKEN', 'default-token-change-me')

# FastAPI app
app = FastAPI(
    title="News Content API",
    description="Advanced News Content Extraction API v·ªõi Newspaper4k v√† Random User Agent",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Security
security = HTTPBearer()

def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    if credentials.credentials != BEARER_TOKEN:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid authentication token",
            headers={"WWW-Authenticate": "Bearer"},
        )
    return credentials.credentials

# Pydantic models
class ArticleRequest(BaseModel):
    url: HttpUrl
    language: str = Field(default="auto", description="Language code (auto, en, vi, zh, etc.)")
    extract_images: bool = Field(default=True, description="Extract images from article")
    summarize: bool = Field(default=False, description="Generate article summary using NLP")

class SourceRequest(BaseModel):
    url: HttpUrl
    max_articles: int = Field(default=10, ge=1, le=50, description="Maximum articles to extract")
    language: str = Field(default="auto", description="Language code")

class FeedRequest(BaseModel):
    url: HttpUrl
    max_articles: int = Field(default=10, ge=1, le=50, description="Maximum articles from feed")

class ArticleResponse(BaseModel):
    title: Optional[str]
    content: Optional[str]
    summary: Optional[str]
    authors: List[str]
    publish_date: Optional[str]
    top_image: Optional[str]
    images: List[str]
    url: str
    language: Optional[str]
    word_count: int
    read_time_minutes: int
    keywords: List[str]
    meta_description: Optional[str]
    meta_keywords: Optional[str]

class SourceResponse(BaseModel):
    source_url: str
    articles: List[ArticleResponse]
    total_found: int
    extracted: int

class HealthResponse(BaseModel):
    status: str
    timestamp: str
    version: str
    features: List[str]

# Helper functions
def create_newspaper_config(language: str = "auto") -> Config:
    """Create newspaper config with random user agent"""
    config = Config()
    config.browser_user_agent = random.choice(USER_AGENTS)
    config.request_timeout = 30
    config.number_threads = 1
    config.thread_timeout_seconds = 30
    config.ignored_content_types_defaults = {}
    
    # Set language if not auto
    if language != "auto":
        config.language = language
    
    return config

def extract_article_content(url: str, language: str = "auto") -> Dict[str, Any]:
    """Extract content from a single article URL"""
    try:
        # Create config with random user agent
        config = create_newspaper_config(language)
        
        # Create article object
        article = Article(url, config=config)
        
        # Download article
        article.download()
        
        # Parse article
        article.parse()
        
        # NLP processing (optional)
        try:
            article.nlp()
        except Exception as e:
            logger.warning(f"NLP processing failed for {url}: {e}")
        
        # Calculate read time (average 200 words per minute)
        word_count = len(article.text.split()) if article.text else 0
        read_time = max(1, round(word_count / 200))
        
        # Format publish date
        publish_date = None
        if article.publish_date:
            publish_date = article.publish_date.isoformat()
        
        return {
            "title": article.title or "",
            "content": article.text or "",
            "summary": article.summary or "",
            "authors": article.authors or [],
            "publish_date": publish_date,
            "top_image": article.top_image or "",
            "images": list(article.images) or [],
            "url": url,
            "language": getattr(article, 'meta_lang', language),
            "word_count": word_count,
            "read_time_minutes": read_time,
            "keywords": article.keywords or [],
            "meta_description": getattr(article, 'meta_description', ''),
            "meta_keywords": getattr(article, 'meta_keywords', '')
        }
        
    except Exception as e:
        logger.error(f"Error extracting article {url}: {e}")
        return {
            "title": None,
            "content": None,
            "summary": None,
            "authors": [],
            "publish_date": None,
            "top_image": None,
            "images": [],
            "url": url,
            "language": language,
            "word_count": 0,
            "read_time_minutes": 0,
            "keywords": [],
            "meta_description": None,
            "meta_keywords": None,
            "error": str(e)
        }

# API Routes
@app.get("/", response_class=HTMLResponse)
async def root():
    """API Homepage v·ªõi th√¥ng tin s·ª≠ d·ª•ng"""
    html_content = """
    <!DOCTYPE html>
    <html>
    <head>
        <title>News Content API</title>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <style>
            body { font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }
            .header { background: #2563eb; color: white; padding: 20px; border-radius: 8px; margin-bottom: 20px; }
            .endpoint { background: #f8fafc; padding: 15px; border-radius: 8px; margin: 10px 0; border-left: 4px solid #2563eb; }
            .method { background: #10b981; color: white; padding: 4px 8px; border-radius: 4px; font-size: 12px; }
            .method.post { background: #f59e0b; }
            code { background: #e5e7eb; padding: 2px 4px; border-radius: 4px; }
            .auth-note { background: #fef3c7; padding: 10px; border-radius: 4px; margin: 10px 0; }
        </style>
    </head>
    <body>
        <div class="header">
            <h1>üöÄ News Content API</h1>
            <p>Advanced News Content Extraction v·ªõi Newspaper4k v√† Random User Agent</p>
        </div>
        
        <div class="auth-note">
            <strong>üîê Authentication:</strong> T·∫•t c·∫£ API calls y√™u c·∫ßu Bearer Token ƒë√£ ƒë∆∞·ª£c ƒë·∫∑t trong l√∫c c√†i ƒë·∫∑t.
            <br><code>Authorization: Bearer YOUR_TOKEN</code>
        </div>
        
        <h2>üìñ API Endpoints</h2>
        
        <div class="endpoint">
            <span class="method">GET</span> <strong>/health</strong>
            <p>Ki·ªÉm tra tr·∫°ng th√°i API</p>
        </div>
        
        <div class="endpoint">
            <span class="method post">POST</span> <strong>/extract-article</strong>
            <p>L·∫•y n·ªôi dung b√†i vi·∫øt t·ª´ URL</p>
            <code>{"url": "https://example.com/article", "language": "vi", "extract_images": true}</code>
        </div>
        
        <div class="endpoint">
            <span class="method post">POST</span> <strong>/extract-source</strong>
            <p>Crawl nhi·ªÅu b√†i vi·∫øt t·ª´ website</p>
            <code>{"url": "https://example.com", "max_articles": 10, "language": "vi"}</code>
        </div>
        
        <div class="endpoint">
            <span class="method post">POST</span> <strong>/parse-feed</strong>
            <p>Ph√¢n t√≠ch RSS feeds</p>
            <code>{"url": "https://example.com/rss.xml", "max_articles": 10}</code>
        </div>
        
        <h2>üìö Documentation</h2>
        <p>
            <a href="/docs" target="_blank">üìñ Swagger UI</a> | 
            <a href="/redoc" target="_blank">üìã ReDoc</a>
        </p>
        
        <h2>üîß ƒê·ªïi Bearer Token</h2>
        <p>ƒê·ªÉ ƒë·ªïi Bearer Token, s·ª≠ d·ª•ng m·ªôt trong c√°c c√°ch sau:</p>
        <ol>
            <li><code>cd /home/n8n && sed -i 's/NEWS_API_TOKEN=.*/NEWS_API_TOKEN="NEW_TOKEN"/' docker-compose.yml && docker compose restart fastapi</code></li>
            <li>Edit file <code>/home/n8n/docker-compose.yml</code> v√† restart service</li>
            <li>Edit file <code>/home/n8n/news_api_token.txt</code> v√† restart container</li>
        </ol>
    </body>
    </html>
    """
    return html_content

@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Health check endpoint"""
    return HealthResponse(
        status="healthy",
        timestamp=datetime.now().isoformat(),
        version="2.0.0",
        features=[
            "Article Extraction",
            "Source Crawling", 
            "RSS Feed Parsing",
            "Random User Agent",
            "Multi-language Support",
            "NLP Processing",
            "Image Extraction"
        ]
    )

@app.post("/extract-article", response_model=ArticleResponse)
async def extract_article(
    request: ArticleRequest,
    token: str = Depends(verify_token)
):
    """Extract content from a single article URL"""
    try:
        # Extract article in thread pool to avoid blocking
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor(max_workers=1) as executor:
            result = await loop.run_in_executor(
                executor, 
                extract_article_content, 
                str(request.url), 
                request.language
            )
        
        if "error" in result:
            raise HTTPException(status_code=400, detail=f"Failed to extract article: {result['error']}")
        
        return ArticleResponse(**result)
        
    except Exception as e:
        logger.error(f"Error in extract_article: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/extract-source", response_model=SourceResponse)
async def extract_source(
    request: SourceRequest,
    token: str = Depends(verify_token)
):
    """Extract multiple articles from a news source"""
    try:
        # Build source using newspaper
        config = create_newspaper_config(request.language)
        source = newspaper.build(str(request.url), config=config)
        
        # Get article URLs (limit to max_articles)
        article_urls = [article.url for article in source.articles[:request.max_articles]]
        
        # Extract articles in parallel
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor(max_workers=3) as executor:
            tasks = [
                loop.run_in_executor(executor, extract_article_content, url, request.language)
                for url in article_urls
            ]
            results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Filter successful extractions
        articles = []
        for result in results:
            if isinstance(result, dict) and "error" not in result:
                articles.append(ArticleResponse(**result))
        
        return SourceResponse(
            source_url=str(request.url),
            articles=articles,
            total_found=len(source.articles),
            extracted=len(articles)
        )
        
    except Exception as e:
        logger.error(f"Error in extract_source: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/parse-feed", response_model=SourceResponse)
async def parse_feed(
    request: FeedRequest,
    token: str = Depends(verify_token)
):
    """Parse RSS/Atom feed and extract articles"""
    try:
        # Parse feed
        headers = get_random_headers()
        response = requests.get(str(request.url), headers=headers, timeout=30)
        response.raise_for_status()
        
        feed = feedparser.parse(response.content)
        
        if not feed.entries:
            raise HTTPException(status_code=400, detail="No entries found in feed")
        
        # Get article URLs from feed entries
        article_urls = []
        for entry in feed.entries[:request.max_articles]:
            if hasattr(entry, 'link'):
                article_urls.append(entry.link)
        
        # Extract articles in parallel
        loop = asyncio.get_event_loop()
        with ThreadPoolExecutor(max_workers=3) as executor:
            tasks = [
                loop.run_in_executor(executor, extract_article_content, url, "auto")
                for url in article_urls
            ]
            results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Filter successful extractions
        articles = []
        for result in results:
            if isinstance(result, dict) and "error" not in result:
                articles.append(ArticleResponse(**result))
        
        return SourceResponse(
            source_url=str(request.url),
            articles=articles,
            total_found=len(feed.entries),
            extracted=len(articles)
        )
        
    except Exception as e:
        logger.error(f"Error in parse_feed: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        workers=1
    )
EOF
    
    # T·∫°o Dockerfile cho News API
    cat > Dockerfile << 'EOF'
FROM python:3.11-slim

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libxml2-dev \
    libxslt-dev \
    libjpeg-dev \
    zlib1g-dev \
    libpng-dev \
    curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Copy requirements and install Python packages
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY main.py .

# Copy token file from parent directory
COPY ../news_api_token.txt /app/news_api_token.txt

# Expose port
EXPOSE 8000

# Run the application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "1"]
EOF
    
    log_success "News Content API ƒë√£ ƒë∆∞·ª£c t·∫°o v·ªõi Newspaper4k v√† Random User Agent!"
}

# =============================================================================
# üê≥ T·∫†O N8N DOCKERFILE
# =============================================================================

create_n8n_dockerfile() {
    log_header "‚öôÔ∏è T·∫†O N8N DOCKERFILE"
    
    cd "$INSTALL_DIR"
    
    cat > Dockerfile << 'EOF'
FROM n8nio/n8n:latest

# Switch to root to install packages
USER root

# Install system dependencies
RUN apk add --no-cache \
    ffmpeg \
    python3 \
    python3-dev \
    py3-pip \
    chromium \
    chromium-chromedriver \
    curl \
    wget \
    git \
    bash \
    && rm -rf /var/cache/apk/*

# Install Python packages
RUN pip3 install --break-system-packages \
    yt-dlp \
    requests \
    beautifulsoup4 \
    selenium \
    pandas \
    numpy

# Set environment variables for Chromium
ENV PUPPETEER_SKIP_CHROMIUM_DOWNLOAD=true
ENV PUPPETEER_EXECUTABLE_PATH=/usr/bin/chromium-browser
ENV CHROME_BIN=/usr/bin/chromium-browser
ENV CHROME_PATH=/usr/bin/chromium-browser

# Switch back to node user
USER node

# Set working directory
WORKDIR /home/node

# Expose port
EXPOSE 5678
EOF
    
    log_success "N8N Dockerfile ƒë√£ ƒë∆∞·ª£c t·∫°o!"
}

# =============================================================================
# üê≥ T·∫†O DOCKER COMPOSE
# =============================================================================

create_docker_compose() {
    log_header "‚öôÔ∏è T·∫†O DOCKER COMPOSE"
    
    cd "$INSTALL_DIR"
    
    # T·∫°o docker-compose.yml
    cat > docker-compose.yml << EOF
services:
  n8n:
    build: .
    image: n8n-custom-ffmpeg:latest
    container_name: n8n-n8n-1
    restart: unless-stopped
    ports:
      - "127.0.0.1:5678:5678"
    environment:
      - N8N_HOST=\${N8N_HOST:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=https
      - NODE_ENV=production
      - WEBHOOK_URL=https://$DOMAIN/
      - GENERIC_TIMEZONE=Asia/Ho_Chi_Minh
      - N8N_METRICS=true
      - N8N_DIAGNOSTICS_ENABLED=false
      - N8N_VERSION_NOTIFICATIONS_ENABLED=false
      - N8N_TEMPLATES_ENABLED=true
      - N8N_ONBOARDING_FLOW_DISABLED=false
      - N8N_DIAGNOSTICS_CONFIG_ENABLED=false
      - EXECUTIONS_TIMEOUT=3600
      - EXECUTIONS_TIMEOUT_MAX=7200
      - N8N_EXECUTION_TIMEOUT=3600
      - N8N_EXECUTION_TIMEOUT_MAX=7200
      - N8N_MAX_EXECUTION_TIMEOUT=7200
      - N8N_EXECUTIONS_DATA_MAX_SIZE=500MB
      - DB_TYPE=sqlite
      - DB_SQLITE_DATABASE=/home/node/.n8n/database.sqlite
      - N8N_ENCRYPTION_KEY=\${N8N_ENCRYPTION_KEY:-$(openssl rand -base64 32)}
    volumes:
      - ./files:/home/node/files
      - ./database.sqlite:/home/node/.n8n/database.sqlite
      - ./encryptionKey:/home/node/.n8n/config
    networks:
      - default

EOF

    # Th√™m News API service n·∫øu ƒë∆∞·ª£c b·∫≠t
    if [[ "$NEWS_API_ENABLED" == true ]]; then
        cat >> docker-compose.yml << EOF
  fastapi:
    build: ./news_api
    image: news-api:latest
    container_name: n8n-fastapi-1
    restart: unless-stopped
    ports:
      - "127.0.0.1:8000:8000"
    environment:
      - NEWS_API_TOKEN=$NEWS_API_TOKEN
    volumes:
      - ./news_api:/app
      - ./news_api_token.txt:/app/news_api_token.txt:ro
    networks:
      - default

EOF
    fi

    # Th√™m Caddy service
    cat >> docker-compose.yml << EOF
  caddy:
    image: caddy:latest
    container_name: n8n-caddy-1
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
      - "443:443/udp"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - default

volumes:
  caddy_data:
  caddy_config:

networks:
  default:
    name: n8n_default
EOF
    
    log_success "Docker Compose ƒë√£ ƒë∆∞·ª£c t·∫°o!"
}

# =============================================================================
# üîí T·∫†O CADDYFILE
# =============================================================================

create_caddyfile() {
    log_header "üîí T·∫†O CADDYFILE"
    
    cd "$INSTALL_DIR"
    
    # T·∫°o Caddyfile v·ªõi SSL t·ª± ƒë·ªông
    cat > Caddyfile << EOF
{
    email admin@$DOMAIN
    acme_ca https://acme-v02.api.letsencrypt.org/directory
}

$DOMAIN {
    reverse_proxy n8n:5678
    
    header {
        Strict-Transport-Security "max-age=31536000; includeSubDomains"
        X-Content-Type-Options "nosniff"
        X-Frame-Options "DENY"
        X-XSS-Protection "1; mode=block"
    }
    
    encode gzip
    
    log {
        output file /var/log/caddy/n8n.log
        format json
    }
}
EOF

    # Th√™m API domain n·∫øu News API ƒë∆∞·ª£c b·∫≠t
    if [[ "$NEWS_API_ENABLED" == true ]]; then
        API_DOMAIN="api.$DOMAIN"
        cat >> Caddyfile << EOF

$API_DOMAIN {
    reverse_proxy fastapi:8000
    
    header {
        Strict-Transport-Security "max-age=31536000; includeSubDomains"
        X-Content-Type-Options "nosniff"
        X-Frame-Options "DENY"
        X-XSS-Protection "1; mode=block"
        Access-Control-Allow-Origin "*"
        Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS"
        Access-Control-Allow-Headers "Content-Type, Authorization"
    }
    
    encode gzip
    
    log {
        output file /var/log/caddy/api.log
        format json
    }
}
EOF
    fi
    
    log_success "Caddyfile ƒë√£ ƒë∆∞·ª£c t·∫°o!"
}

# =============================================================================
# üì¶ T·∫†O BACKUP SCRIPTS
# =============================================================================

create_backup_scripts() {
    log_header "üì¶ T·∫†O BACKUP SCRIPTS"
    
    cd "$INSTALL_DIR"
    
    # Script backup workflows
    cat > backup-workflows.sh << 'EOF'
#!/bin/bash

# Backup N8N workflows v√† credentials
BACKUP_DIR="/home/n8n/files/backup_full"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="n8n_backup_${TIMESTAMP}.tar.gz"
LOG_FILE="$BACKUP_DIR/backup.log"

# T·∫°o th∆∞ m·ª•c backup n·∫øu ch∆∞a c√≥
mkdir -p "$BACKUP_DIR"

# Function ƒë·ªÉ ghi log
log_message() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"
}

log_message "üîÑ B·∫Øt ƒë·∫ßu backup N8N..."

# T·∫°o th∆∞ m·ª•c t·∫°m
TEMP_DIR="/tmp/n8n_backup_$TIMESTAMP"
mkdir -p "$TEMP_DIR"

# Export workflows t·ª´ N8N (n·∫øu c√≥ API)
log_message "üìã Export workflows..."
mkdir -p "$TEMP_DIR/workflows"

# Backup database v√† config files
log_message "üíæ Backup database v√† config..."
mkdir -p "$TEMP_DIR/credentials"

# Copy database
if [ -f "/home/n8n/database.sqlite" ]; then
    cp "/home/n8n/database.sqlite" "$TEMP_DIR/credentials/"
    log_message "‚úÖ Database copied"
fi

# Copy encryption key
if [ -f "/home/n8n/encryptionKey" ]; then
    cp "/home/n8n/encryptionKey" "$TEMP_DIR/credentials/"
    log_message "‚úÖ Encryption key copied"
fi

# Copy config files
if [ -d "/home/n8n/files" ]; then
    cp -r "/home/n8n/files" "$TEMP_DIR/" 2>/dev/null || true
    log_message "‚úÖ Files directory copied"
fi

# T·∫°o metadata
cat > "$TEMP_DIR/backup_metadata.json" << EOL
{
    "backup_date": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "version": "2.0.0",
    "hostname": "$(hostname)",
    "backup_type": "full"
}
EOL

# T·∫°o file tar.gz
log_message "üì¶ T·∫°o archive..."
cd /tmp
tar -czf "$BACKUP_DIR/$BACKUP_FILE" "n8n_backup_$TIMESTAMP/"

# X√≥a th∆∞ m·ª•c t·∫°m
rm -rf "$TEMP_DIR"

# Ki·ªÉm tra k√≠ch th∆∞·ªõc file
BACKUP_SIZE=$(du -h "$BACKUP_DIR/$BACKUP_FILE" | cut -f1)
log_message "‚úÖ Backup ho√†n th√†nh: $BACKUP_FILE ($BACKUP_SIZE)"

# G·ª≠i qua Telegram n·∫øu ƒë∆∞·ª£c c·∫•u h√¨nh
if [ -f "/home/n8n/telegram_config.txt" ]; then
    source "/home/n8n/telegram_config.txt"
    
    if [ ! -z "$TELEGRAM_BOT_TOKEN" ] && [ ! -z "$TELEGRAM_CHAT_ID" ]; then
        # Ki·ªÉm tra k√≠ch th∆∞·ªõc file (Telegram limit 20MB)
        BACKUP_SIZE_BYTES=$(stat -f%z "$BACKUP_DIR/$BACKUP_FILE" 2>/dev/null || stat -c%s "$BACKUP_DIR/$BACKUP_FILE")
        
        MESSAGE="üîÑ N8N Backup ho√†n th√†nh!%0AüìÖ $(date)%0Aüì¶ File: $BACKUP_FILE%0Aüíæ Size: $BACKUP_SIZE"
        
        if [ $BACKUP_SIZE_BYTES -lt 20971520 ]; then
            # G·ª≠i file n·∫øu < 20MB
            curl -s -X POST "https://api.telegram.org/bot$TELEGRAM_BOT_TOKEN/sendDocument" \
                -F chat_id="$TELEGRAM_CHAT_ID" \
                -F document="@$BACKUP_DIR/$BACKUP_FILE" \
                -F caption="$MESSAGE" > /dev/null
            log_message "üì± Backup file sent to Telegram"
        else
            # Ch·ªâ g·ª≠i th√¥ng b√°o n·∫øu file qu√° l·ªõn
            curl -s -X POST "https://api.telegram.org/bot$TELEGRAM_BOT_TOKEN/sendMessage" \
                -d chat_id="$TELEGRAM_CHAT_ID" \
                -d text="$MESSAGE%0A‚ö†Ô∏è File qu√° l·ªõn ƒë·ªÉ g·ª≠i qua Telegram (>20MB)" > /dev/null
            log_message "üì± Backup notification sent to Telegram (file too large)"
        fi
    fi
fi

# X√≥a backup c≈© (gi·ªØ l·∫°i 30 b·∫£n g·∫ßn nh·∫•t)
log_message "üßπ D·ªçn d·∫πp backup c≈©..."
cd "$BACKUP_DIR"
ls -t n8n_backup_*.tar.gz | tail -n +31 | xargs -r rm
log_message "‚úÖ Backup process completed"
EOF

    chmod +x backup-workflows.sh

    # Script backup manual (ƒë·ªÉ test)
    cat > backup-manual.sh << 'EOF'
#!/bin/bash

echo "üß™ MANUAL BACKUP TEST"
echo "===================="

# Ch·∫°y backup script
/home/n8n/backup-workflows.sh

echo ""
echo "üìã BACKUP FILES:"
ls -la /home/n8n/files/backup_full/n8n_backup_*.tar.gz | tail -5

echo ""
echo "üìä BACKUP LOG (10 d√≤ng cu·ªëi):"
tail -10 /home/n8n/files/backup_full/backup.log
EOF

    chmod +x backup-manual.sh

    # Thi·∫øt l·∫≠p cron job cho backup t·ª± ƒë·ªông
    if [[ "$TELEGRAM_ENABLED" == true ]] || [[ "$AUTO_UPDATE_ENABLED" == true ]]; then
        # T·∫°o cron job backup h√†ng ng√†y l√∫c 2:00 AM
        (crontab -l 2>/dev/null; echo "0 2 * * * /home/n8n/backup-workflows.sh") | crontab -
        log_message "‚è∞ ƒê√£ thi·∫øt l·∫≠p backup t·ª± ƒë·ªông h√†ng ng√†y l√∫c 2:00 AM"
    fi

    log_success "Backup scripts ƒë√£ ƒë∆∞·ª£c t·∫°o!"
}

# =============================================================================
# üîÑ T·∫†O UPDATE SCRIPT
# =============================================================================

create_update_script() {
    if [[ "$AUTO_UPDATE_ENABLED" == false ]]; then
        return
    fi
    
    cd "$INSTALL_DIR"
    
    cat > update-n8n.sh << 'EOF'
#!/bin/bash

# Auto update N8N v√† components
LOG_FILE="/home/n8n/logs/update.log"
mkdir -p "$(dirname "$LOG_FILE")"

log_message() {
    echo "$(date '+%Y-%m-%d %H:%M:%S') - $1" | tee -a "$LOG_FILE"
}

log_message "üîÑ B·∫Øt ƒë·∫ßu auto update..."

cd /home/n8n

# X√°c ƒë·ªãnh Docker Compose command
if command -v docker-compose &> /dev/null; then
    DOCKER_COMPOSE="docker-compose"
elif docker compose version &> /dev/null; then
    DOCKER_COMPOSE="docker compose"
else
    log_message "‚ùå Docker Compose kh√¥ng t√¨m th·∫•y!"
    exit 1
fi

# Backup tr∆∞·ªõc khi update
log_message "üíæ T·∫°o backup tr∆∞·ªõc update..."
/home/n8n/backup-workflows.sh

# Pull latest images
log_message "üì• Pull latest Docker images..."
$DOCKER_COMPOSE pull

# Restart containers v·ªõi images m·ªõi
log_message "üîÑ Restart containers..."
$DOCKER_COMPOSE up -d

# Update yt-dlp trong container
log_message "üì∫ Update yt-dlp..."
docker exec n8n-n8n-1 pip3 install --break-system-packages -U yt-dlp

log_message "‚úÖ Auto update ho√†n th√†nh!"
EOF

    chmod +x update-n8n.sh
    
    # Th√™m cron job update (m·ªói 12 ti·∫øng)
    (crontab -l 2>/dev/null; echo "0 */12 * * * /home/n8n/update-n8n.sh") | crontab -
    
    log_success "Auto-update script ƒë√£ ƒë∆∞·ª£c t·∫°o!"
}

# =============================================================================
# üîç T·∫†O TROUBLESHOOT SCRIPT
# =============================================================================

create_troubleshoot_script() {
    cd "$INSTALL_DIR"
    
    cat > troubleshoot.sh << 'EOF'
#!/bin/bash

echo "üîç N8N SYSTEM DIAGNOSTICS"
echo "========================="

# X√°c ƒë·ªãnh Docker Compose command
if command -v docker-compose &> /dev/null; then
    DOCKER_COMPOSE="docker-compose"
elif docker compose version &> /dev/null; then
    DOCKER_COMPOSE="docker compose"
else
    echo "‚ùå Docker Compose kh√¥ng t√¨m th·∫•y!"
    exit 1
fi

echo "üìç 1. Container Status:"
cd /home/n8n && $DOCKER_COMPOSE ps

echo ""
echo "üìç 2. Docker System Info:"
docker system df

echo ""
echo "üìç 3. Memory Usage:"
free -h

echo ""
echo "üìç 4. Disk Usage:"
df -h /home/n8n

echo ""
echo "üìç 5. Recent Logs (N8N):"
$DOCKER_COMPOSE logs --tail=10 n8n

echo ""
echo "üìç 6. Recent Logs (Caddy):"
$DOCKER_COMPOSE logs --tail=10 caddy

if docker ps | grep -q fastapi; then
    echo ""
    echo "üìç 7. Recent Logs (FastAPI):"
    $DOCKER_COMPOSE logs --tail=10 fastapi
fi

echo ""
echo "üìç 8. Network Connectivity:"
curl -I https://google.com 2>/dev/null | head -1 || echo "‚ùå No internet connection"

echo ""
echo "üìç 9. SSL Certificate Check:"
if command -v openssl &> /dev/null; then
    echo | openssl s_client -connect $(hostname):443 -servername $(hostname) 2>/dev/null | openssl x509 -noout -dates 2>/dev/null || echo "‚ùå SSL certificate issue"
else
    echo "‚ö†Ô∏è OpenSSL not available"
fi

echo ""
echo "üìç 10. Port Status:"
netstat -tulpn | grep -E ":80|:443|:5678|:8000" || ss -tulpn | grep -E ":80|:443|:5678|:8000"
EOF

    chmod +x troubleshoot.sh
    
    log_success "Troubleshoot script ƒë√£ ƒë∆∞·ª£c t·∫°o!"
}

# =============================================================================
# üöÄ BUILD V√Ä KH·ªûI ƒê·ªòNG CONTAINERS
# =============================================================================

build_and_start() {
    log_header "üöÄ BUILD V√Ä KH·ªûI ƒê·ªòNG CONTAINERS"
    
    cd "$INSTALL_DIR"
    
    # X√°c ƒë·ªãnh Docker Compose command
    if command -v docker-compose &> /dev/null; then
        DOCKER_COMPOSE="docker-compose"
    elif docker compose version &> /dev/null; then
        DOCKER_COMPOSE="docker compose"
    else
        log_error "Docker Compose kh√¥ng t√¨m th·∫•y!"
        exit 1
    fi
    
    log_info "ƒêang build Docker images..."
    $DOCKER_COMPOSE build
    
    log_info "ƒêang kh·ªüi ƒë·ªông containers..."
    $DOCKER_COMPOSE up -d
    
    # ƒê·ª£i containers kh·ªüi ƒë·ªông
    log_info "ƒê·ª£i containers kh·ªüi ƒë·ªông (30 gi√¢y)..."
    sleep 30
    
    # Ki·ªÉm tra tr·∫°ng th√°i
    log_info "Ki·ªÉm tra tr·∫°ng th√°i containers:"
    $DOCKER_COMPOSE ps
    
    log_success "Containers ƒë√£ ƒë∆∞·ª£c kh·ªüi ƒë·ªông!"
}

# =============================================================================
# üîí KI·ªÇM TRA SSL V√Ä X·ª¨ L√ù RATE LIMIT
# =============================================================================

check_ssl_and_rate_limit() {
    log_header "üîí KI·ªÇM TRA SSL CERTIFICATE"
    
    cd "$INSTALL_DIR"
    
    # X√°c ƒë·ªãnh Docker Compose command
    if command -v docker-compose &> /dev/null; then
        DOCKER_COMPOSE="docker-compose"
    elif docker compose version &> /dev/null; then
        DOCKER_COMPOSE="docker compose"
    else
        DOCKER_COMPOSE="docker compose"
    fi
    
    log_info "ƒêang ki·ªÉm tra Caddy logs ƒë·ªÉ ph√°t hi·ªán rate limit..."
    
    # ƒê·ª£i 60 gi√¢y ƒë·ªÉ Caddy th·ª≠ l·∫•y SSL
    sleep 60
    
    # Ki·ªÉm tra logs ƒë·ªÉ t√¨m rate limit
    RATE_LIMIT_DETECTED=false
    if $DOCKER_COMPOSE logs caddy 2>/dev/null | grep -q "rateLimited\|rate.*limit\|too many certificates"; then
        RATE_LIMIT_DETECTED=true
    fi
    
    if [[ "$RATE_LIMIT_DETECTED" == true ]]; then
        log_error "üö® PH√ÅT HI·ªÜN SSL RATE LIMIT!"
        log_error "Let's Encrypt ƒë√£ ƒë·∫°t gi·ªõi h·∫°n 5 certificates/tu·∫ßn cho domain n√†y"
        echo ""
        log_warning "üìã C√ÅC GI·∫¢I PH√ÅP:"
        echo ""
        echo "1. üéØ S·ª¨ D·ª§NG STAGING SSL (KHUY·∫æN NGH·ªä):"
        echo "   - Website s·∫Ω ho·∫°t ƒë·ªông ngay l·∫≠p t·ª©c"
        echo "   - Browser s·∫Ω c·∫£nh b√°o 'Not Secure' (b√¨nh th∆∞·ªùng)"
        echo "   - T·∫•t c·∫£ ch·ª©c nƒÉng N8N v√† API ho·∫°t ƒë·ªông ƒë·∫ßy ƒë·ªß"
        echo ""
        echo "2. ‚è∞ ƒê·ª¢I 7 NG√ÄY:"
        echo "   - ƒê·ª£i ƒë·∫øn sau ng√†y $(date -d '+7 days' '+%d/%m/%Y')"
        echo "   - Rate limit s·∫Ω ƒë∆∞·ª£c reset"
        echo ""
        echo "3. üîÑ C√ÄI L·∫†I UBUNTU VPS:"
        echo "   - Backup d·ªØ li·ªáu quan tr·ªçng"
        echo "   - C√†i l·∫°i Ubuntu v√† ch·∫°y script n√†y"
        echo ""
        
        read -p "B·∫°n mu·ªën ch·ªçn gi·∫£i ph√°p n√†o? (1=Staging SSL, 2=ƒê·ª£i 7 ng√†y, 3=H∆∞·ªõng d·∫´n c√†i l·∫°i): " -r CHOICE
        
        case $CHOICE in
            1)
                log_info "üîÑ Chuy·ªÉn sang Staging SSL..."
                
                # D·ª´ng containers
                $DOCKER_COMPOSE down
                
                # X√≥a SSL data c≈©
                docker volume rm n8n_caddy_data n8n_caddy_config 2>/dev/null || true
                
                # T·∫°o Caddyfile v·ªõi staging
                cat > Caddyfile << EOF
{
    email admin@$DOMAIN
    acme_ca https://acme-staging-v02.api.letsencrypt.org/directory
    debug
}

$DOMAIN {
    reverse_proxy n8n:5678
    
    header {
        Strict-Transport-Security "max-age=31536000; includeSubDomains"
        X-Content-Type-Options "nosniff"
        X-Frame-Options "DENY"
        X-XSS-Protection "1; mode=block"
    }
    
    encode gzip
    
    log {
        output file /var/log/caddy/n8n.log
        format json
    }
}
EOF

                if [[ "$NEWS_API_ENABLED" == true ]]; then
                    API_DOMAIN="api.$DOMAIN"
                    cat >> Caddyfile << EOF

$API_DOMAIN {
    reverse_proxy fastapi:8000
    
    header {
        Strict-Transport-Security "max-age=31536000; includeSubDomains"
        X-Content-Type-Options "nosniff"
        X-Frame-Options "DENY"
        X-XSS-Protection "1; mode=block"
        Access-Control-Allow-Origin "*"
        Access-Control-Allow-Methods "GET, POST, PUT, DELETE, OPTIONS"
        Access-Control-Allow-Headers "Content-Type, Authorization"
    }
    
    encode gzip
    
    log {
        output file /var/log/caddy/api.log
        format json
    }
}
EOF
                fi
                
                # Kh·ªüi ƒë·ªông l·∫°i
                $DOCKER_COMPOSE up -d
                
                log_success "‚úÖ ƒê√£ chuy·ªÉn sang Staging SSL!"
                log_warning "‚ö†Ô∏è Browser s·∫Ω c·∫£nh b√°o 'Not Secure' - ƒë√¢y l√† b√¨nh th∆∞·ªùng v·ªõi staging certificate"
                echo ""
                log_info "üåê TRUY C·∫¨P NGAY:"
                log_info "N8N: https://$DOMAIN (click 'Advanced' -> 'Proceed to site')"
                if [[ "$NEWS_API_ENABLED" == true ]]; then
                    log_info "API: https://api.$DOMAIN/docs"
                fi
                ;;
            2)
                log_info "‚è∞ H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông th·ª≠ l·∫°i sau 7 ng√†y"
                log_info "B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng HTTP trong th·ªùi gian ch·ªù: http://$DOMAIN"
                ;;
            3)
                echo ""
                log_warning "üìã H∆Ø·ªöNG D·∫™N C√ÄI L·∫†I UBUNTU VPS:"
                echo ""
                echo "1. üíæ Backup d·ªØ li·ªáu quan tr·ªçng:"
                echo "   - Download file backup t·ª´ /home/n8n/files/backup_full/"
                echo "   - L∆∞u c√°c file config quan tr·ªçng"
                echo ""
                echo "2. üîÑ C√†i l·∫°i Ubuntu:"
                echo "   - Truy c·∫≠p control panel VPS"
                echo "   - Ch·ªçn 'Reinstall OS' ho·∫∑c 'Rebuild'"
                echo "   - Ch·ªçn Ubuntu 20.04+ LTS"
                echo ""
                echo "3. üöÄ Ch·∫°y l·∫°i script:"
                echo "   cd /tmp && curl -sSL https://raw.githubusercontent.com/KalvinThien/install-n8n-ffmpeg/main/auto_cai_dat_n8n.sh | tr -d '\r' > install_n8n.sh && chmod +x install_n8n.sh && sudo bash install_n8n.sh"
                echo ""
                echo "4. üì• Restore backup:"
                echo "   - Upload file backup"
                echo "   - Extract v√† copy files v·ªÅ v·ªã tr√≠ c≈©"
                ;;
        esac
    else
        # Ki·ªÉm tra SSL certificate
        log_info "ƒêang ki·ªÉm tra SSL certificate..."
        sleep 30
        
        if curl -I "https://$DOMAIN" &>/dev/null; then
            log_success "‚úÖ SSL Certificate ƒë√£ ƒë∆∞·ª£c c·∫•p th√†nh c√¥ng!"
        else
            log_warning "‚ö†Ô∏è SSL Certificate ch∆∞a s·∫µn s√†ng, c√≥ th·ªÉ c·∫ßn th√™m th·ªùi gian"
            log_info "B·∫°n c√≥ th·ªÉ ki·ªÉm tra logs: cd /home/n8n && docker compose logs -f caddy"
        fi
    fi
}

# =============================================================================
# üéØ HI·ªÇN TH·ªä TH√îNG TIN HO√ÄN TH√ÄNH
# =============================================================================

show_completion_info() {
    log_header "üéâ C√ÄI ƒê·∫∂T HO√ÄN TH√ÄNH!"
    
    echo -e "${GREEN}‚úÖ N8N Automation Platform ƒë√£ ƒë∆∞·ª£c c√†i ƒë·∫∑t th√†nh c√¥ng!${NC}"
    echo ""
    
    log_info "üåê TRUY C·∫¨P H·ªÜ TH·ªêNG:"
    log_info "N8N Dashboard: https://$DOMAIN"
    
    if [[ "$NEWS_API_ENABLED" == true ]]; then
        log_info "News API: https://api.$DOMAIN"
        log_info "API Documentation: https://api.$DOMAIN/docs"
    fi
    
    echo ""
    log_info "üìÅ C·∫§U TR√öC TH∆Ø M·ª§C:"
    log_info "Th∆∞ m·ª•c ch√≠nh: $INSTALL_DIR"
    log_info "Backup: $INSTALL_DIR/files/backup_full/"
    log_info "Logs: $INSTALL_DIR/logs/"
    
    echo ""
    log_info "üîß L·ªÜNH QU·∫¢N L√ù:"
    log_info "Xem tr·∫°ng th√°i: cd $INSTALL_DIR && docker compose ps"
    log_info "Xem logs: cd $INSTALL_DIR && docker compose logs -f"
    log_info "Restart: cd $INSTALL_DIR && docker compose restart"
    log_info "Ch·∫©n ƒëo√°n: $INSTALL_DIR/troubleshoot.sh"
    
    if [[ "$NEWS_API_ENABLED" == true ]]; then
        echo ""
        log_info "üîë ƒê·ªîI BEARER TOKEN:"
        log_info "Method 1: cd $INSTALL_DIR && sed -i 's/NEWS_API_TOKEN=.*/NEWS_API_TOKEN=\"NEW_TOKEN\"/' docker-compose.yml && docker compose restart fastapi"
        log_info "Method 2: Edit file $INSTALL_DIR/news_api_token.txt v√† restart container"
    fi
    
    if [[ "$TELEGRAM_ENABLED" == true ]]; then
        echo ""
        log_info "üì± TELEGRAM BACKUP:"
        log_info "Test backup: $INSTALL_DIR/backup-manual.sh"
        log_info "Auto backup: M·ªói ng√†y 2:00 AM"
    fi
    
    if [[ "$AUTO_UPDATE_ENABLED" == true ]]; then
        echo ""
        log_info "üîÑ AUTO UPDATE:"
        log_info "T·ª± ƒë·ªông: M·ªói 12 ti·∫øng"
        log_info "Manual: $INSTALL_DIR/update-n8n.sh"
    fi
    
    echo ""
    log_success "üöÄ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng s·ª≠ d·ª•ng!"
    echo ""
    log_info "üì∫ ƒê·ª´ng qu√™n SUBSCRIBE YouTube: https://www.youtube.com/@kalvinthiensocial"
    log_info "üìò Facebook: https://www.facebook.com/Ban.Thien.Handsome/"
    log_info "üì± Zalo: 08.8888.4749"
}

# =============================================================================
# üöÄ H√ÄM MAIN
# =============================================================================

main() {
    # Ki·ªÉm tra quy·ªÅn root
    check_root
    
    # Hi·ªÉn th·ªã banner
    show_banner
    
    # Parse arguments
    parse_arguments "$@"
    
    # Ki·ªÉm tra h·ªá ƒëi·ªÅu h√†nh
    check_os
    
    # Ki·ªÉm tra internet
    check_internet
    
    # Thu th·∫≠p th√¥ng tin t·ª´ ng∆∞·ªùi d√πng
    collect_user_input
    
    # Ki·ªÉm tra DNS
    check_dns
    
    # Thi·∫øt l·∫≠p swap
    setup_swap
    
    # C√†i ƒë·∫∑t Docker
    install_docker
    
    # X√≥a c√†i ƒë·∫∑t c≈©
    cleanup_old_installation
    
    # T·∫°o c·∫•u tr√∫c th∆∞ m·ª•c
    create_directory_structure
    
    # T·∫°o News API
    create_news_api
    
    # T·∫°o N8N Dockerfile
    create_n8n_dockerfile
    
    # T·∫°o Docker Compose
    create_docker_compose
    
    # T·∫°o Caddyfile
    create_caddyfile
    
    # T·∫°o backup scripts
    create_backup_scripts
    
    # T·∫°o update script
    create_update_script
    
    # T·∫°o troubleshoot script
    create_troubleshoot_script
    
    # Build v√† kh·ªüi ƒë·ªông containers
    build_and_start
    
    # Ki·ªÉm tra SSL v√† x·ª≠ l√Ω rate limit
    check_ssl_and_rate_limit
    
    # Hi·ªÉn th·ªã th√¥ng tin ho√†n th√†nh
    show_completion_info
}

# Ch·∫°y script
main "$@"
